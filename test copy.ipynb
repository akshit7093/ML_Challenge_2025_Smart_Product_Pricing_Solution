{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "398606d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b5855d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading final precomputed feature matrix for training ---\n",
      "   âœ“ Features loaded. Shape: (75000, 5054)\n",
      "   âœ“ Labels loaded. Count: 75000\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting LightGBM CPU Training (Optimized for Max Cores)\n",
      "   Folds: 20\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/20 ---\n",
      "  - Training LightGBM on all available CPU cores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CV Progress:   0%|          | 0/20 [01:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 137\u001b[0m\n\u001b[0;32m    134\u001b[0m X_final_train, y_final_train \u001b[38;5;241m=\u001b[39m load_precomputed_data(CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_final_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[43mtrain_lightgbm_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_final_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_final_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 74\u001b[0m, in \u001b[0;36mtrain_lightgbm_cpu\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     72\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     73\u001b[0m model \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlgb_params)\n\u001b[1;32m---> 74\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     84\u001b[0m oof_preds[val_idx] \u001b[38;5;241m=\u001b[39m val_preds\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1398\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    311\u001b[0m     cb(\n\u001b[0;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m         )\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4154\u001b[0m _safe_call(\n\u001b[1;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4159\u001b[0m )\n\u001b[0;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gc # <<< IMPORT GARBAGE COLLECTOR MODULE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Configuration & Setup ---\n",
    "CONFIG = {\n",
    "    'n_folds': 20,\n",
    "    'random_state': 42,\n",
    "    'data_dir': 'processed_data',\n",
    "}\n",
    "\n",
    "# --- 2. Helper Functions ---\n",
    "def smape(y_true, y_pred):\n",
    "    y_true_actual = np.expm1(y_true)\n",
    "    y_pred_actual = np.expm1(y_pred)\n",
    "    numerator = np.abs(y_pred_actual - y_true_actual)\n",
    "    denominator = (np.abs(y_true_actual) + np.abs(y_pred_actual)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "# --- 3. Main Training Pipeline (CPU-Optimized) ---\n",
    "def train_lightgbm_cpu(X, y):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸš€ Starting LightGBM CPU Training (Optimized for Max Cores)\")\n",
    "    print(f\"   Folds: {CONFIG['n_folds']}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    kf = KFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_state'])\n",
    "    \n",
    "    # LightGBM parameters for CPU\n",
    "    lgb_params = {\n",
    "        'objective': 'regression_l1',\n",
    "        'metric': 'mae',\n",
    "        'random_state': CONFIG['random_state'],\n",
    "        'n_estimators': 4000,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 50,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1,\n",
    "        'verbosity': -1,\n",
    "        \n",
    "        # --- KEY PARAMETER FOR MAX CPU USAGE ---\n",
    "        'n_jobs': -1,  # This tells LightGBM to use all available CPU cores\n",
    "    }\n",
    "\n",
    "    oof_preds = np.zeros(len(y))\n",
    "    oof_scores = []\n",
    "    best_smape = np.inf\n",
    "    model_save_path = 'best_cpu_lgbm_model.joblib'\n",
    "    best_fold = -1\n",
    "\n",
    "    # Main training loop\n",
    "    for fold, (train_idx, val_idx) in enumerate(tqdm(kf.split(X, y), total=CONFIG['n_folds'], desc=\"CV Progress\")):\n",
    "        print(f\"\\n--- Fold {fold+1}/{CONFIG['n_folds']} ---\")\n",
    "        \n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        print(\"  - Training LightGBM on all available CPU cores...\")\n",
    "        start_time = time.time()\n",
    "        model = lgb.LGBMRegressor(**lgb_params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(stopping_rounds=200, verbose=False),\n",
    "                lgb.log_evaluation(period=500)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        fold_smape = smape(y_val, val_preds)\n",
    "        oof_scores.append(fold_smape)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"    âœ“ Done in {elapsed:.1f}s. Fold SMAPE: {fold_smape:.4f}%\")\n",
    "\n",
    "        # --- Checkpoint Saving Logic ---\n",
    "        if fold_smape < best_smape:\n",
    "            best_smape = fold_smape\n",
    "            best_fold = fold + 1\n",
    "            joblib.dump(model, model_save_path)\n",
    "            print(f\"    ðŸ’¾ New best model saved (SMAPE: {best_smape:.4f}%)\")\n",
    "\n",
    "        # --- AGGRESSIVE MEMORY CLEANUP TO PREVENT CRASHES ---\n",
    "        # This is crucial when running many parallel processes\n",
    "        del X_train, X_val, y_train, y_val, model, val_preds\n",
    "        gc.collect() # Force Python to release the memory immediately\n",
    "\n",
    "    # --- Final Evaluation ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ“Š Final Cross-Validation Results (OOF)\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Mean SMAPE: {np.mean(oof_scores):.4f}% (Std: {np.std(oof_scores):.4f})\")\n",
    "    print(f\"Best model from Fold {best_fold} is saved at '{model_save_path}'\")\n",
    "\n",
    "    # --- Retrain Final Model on Full Data ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Retraining final model on 100% of data for submission...\")\n",
    "    print(\"=\"*50)\n",
    "    final_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    final_model.fit(X, y) # Train on the complete dataset\n",
    "    \n",
    "    final_model_path = 'final_lgbm_cpu_model_submission.joblib'\n",
    "    joblib.dump(final_model, final_model_path)\n",
    "    print(f\"\\nâœ… Final submission model saved as '{final_model_path}'\")\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    def load_precomputed_data(data_dir):\n",
    "        try:\n",
    "            print(\"--- Loading final precomputed feature matrix for training ---\")\n",
    "            X = load_npz(os.path.join(data_dir, 'X_processed_train.npz'))\n",
    "            y_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "            print(f\"   âœ“ Features loaded. Shape: {X.shape}\")\n",
    "            print(f\"   âœ“ Labels loaded. Count: {len(y_df)}\")\n",
    "            return X, y_df['price_log'].values\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"FATAL ERROR: Could not load precomputed files. {e}\")\n",
    "            return None, None\n",
    "\n",
    "    X_final_train, y_final_train = load_precomputed_data(CONFIG['data_dir'])\n",
    "    \n",
    "    if X_final_train is not None:\n",
    "        train_lightgbm_cpu(X_final_train, y_final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd94e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Verifying GPU setup...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 350\n",
      "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 10\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 64 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 10 dense feature groups (0.00 MB) transferred to GPU in 0.003704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 0.494681\n",
      "  âœ… GPU test PASSED!\n",
      "\n",
      "--- Loading final precomputed feature matrix for training ---\n",
      "   âœ“ Features loaded. Shape: (75000, 5054)\n",
      "   âœ“ Labels loaded. Count: 75000\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting LightGBM GPU Training (20 Folds + Memory Safe) ðŸš€\n",
      "   Folds: 20, Device: GPU\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 755896\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.003600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.708050\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.707291\n",
      "[100]\tvalid_0's l1: 0.662905\n",
      "[150]\tvalid_0's l1: 0.635091\n",
      "[200]\tvalid_0's l1: 0.616746\n",
      "[250]\tvalid_0's l1: 0.603767\n",
      "[300]\tvalid_0's l1: 0.593675\n",
      "[350]\tvalid_0's l1: 0.585741\n",
      "[400]\tvalid_0's l1: 0.578753\n",
      "[450]\tvalid_0's l1: 0.573546\n",
      "[500]\tvalid_0's l1: 0.569332\n",
      "[550]\tvalid_0's l1: 0.566251\n",
      "[600]\tvalid_0's l1: 0.563378\n",
      "[650]\tvalid_0's l1: 0.560635\n",
      "[700]\tvalid_0's l1: 0.558285\n",
      "[750]\tvalid_0's l1: 0.556181\n",
      "[800]\tvalid_0's l1: 0.554423\n",
      "[850]\tvalid_0's l1: 0.55279\n",
      "[900]\tvalid_0's l1: 0.551216\n",
      "[950]\tvalid_0's l1: 0.549821\n",
      "[1000]\tvalid_0's l1: 0.548581\n",
      "[1050]\tvalid_0's l1: 0.547563\n",
      "[1100]\tvalid_0's l1: 0.546732\n",
      "[1150]\tvalid_0's l1: 0.545922\n",
      "[1200]\tvalid_0's l1: 0.54514\n",
      "[1250]\tvalid_0's l1: 0.544255\n",
      "[1300]\tvalid_0's l1: 0.543374\n",
      "[1350]\tvalid_0's l1: 0.542586\n",
      "[1400]\tvalid_0's l1: 0.5418\n",
      "[1450]\tvalid_0's l1: 0.54096\n",
      "[1500]\tvalid_0's l1: 0.540283\n",
      "[1550]\tvalid_0's l1: 0.539582\n",
      "[1600]\tvalid_0's l1: 0.538972\n",
      "[1650]\tvalid_0's l1: 0.538413\n",
      "[1700]\tvalid_0's l1: 0.537772\n",
      "[1750]\tvalid_0's l1: 0.537191\n",
      "[1800]\tvalid_0's l1: 0.536688\n",
      "[1850]\tvalid_0's l1: 0.536222\n",
      "[1900]\tvalid_0's l1: 0.535713\n",
      "[1950]\tvalid_0's l1: 0.535197\n",
      "[2000]\tvalid_0's l1: 0.53467\n",
      "[2050]\tvalid_0's l1: 0.534204\n",
      "[2100]\tvalid_0's l1: 0.533736\n",
      "[2150]\tvalid_0's l1: 0.533262\n",
      "[2200]\tvalid_0's l1: 0.532794\n",
      "[2250]\tvalid_0's l1: 0.532418\n",
      "[2300]\tvalid_0's l1: 0.532006\n",
      "[2350]\tvalid_0's l1: 0.531648\n",
      "[2400]\tvalid_0's l1: 0.5313\n",
      "[2450]\tvalid_0's l1: 0.53095\n",
      "[2500]\tvalid_0's l1: 0.530617\n",
      "[2550]\tvalid_0's l1: 0.530377\n",
      "[2600]\tvalid_0's l1: 0.53012\n",
      "[2650]\tvalid_0's l1: 0.529905\n",
      "[2700]\tvalid_0's l1: 0.529635\n",
      "[2750]\tvalid_0's l1: 0.529354\n",
      "[2800]\tvalid_0's l1: 0.529047\n",
      "[2850]\tvalid_0's l1: 0.528859\n",
      "[2900]\tvalid_0's l1: 0.528572\n",
      "[2950]\tvalid_0's l1: 0.528332\n",
      "[3000]\tvalid_0's l1: 0.528051\n",
      "[3050]\tvalid_0's l1: 0.527842\n",
      "[3100]\tvalid_0's l1: 0.527611\n",
      "[3150]\tvalid_0's l1: 0.527352\n",
      "[3200]\tvalid_0's l1: 0.527026\n",
      "[3250]\tvalid_0's l1: 0.526748\n",
      "[3300]\tvalid_0's l1: 0.526507\n",
      "[3350]\tvalid_0's l1: 0.526304\n",
      "[3400]\tvalid_0's l1: 0.52605\n",
      "[3450]\tvalid_0's l1: 0.525873\n",
      "[3500]\tvalid_0's l1: 0.525662\n",
      "[3550]\tvalid_0's l1: 0.525461\n",
      "[3600]\tvalid_0's l1: 0.525259\n",
      "[3650]\tvalid_0's l1: 0.52505\n",
      "[3700]\tvalid_0's l1: 0.524882\n",
      "[3750]\tvalid_0's l1: 0.524679\n",
      "[3800]\tvalid_0's l1: 0.524497\n",
      "[3850]\tvalid_0's l1: 0.524334\n",
      "[3900]\tvalid_0's l1: 0.524156\n",
      "[3950]\tvalid_0's l1: 0.523994\n",
      "[4000]\tvalid_0's l1: 0.523841\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.523841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:   5%|â–Œ         | 1/20 [15:11<4:48:42, 911.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Done in 911.5s. Fold SMAPE: 52.2492%\n",
      "\n",
      "--- Fold 2/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 757010\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.002966 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.709383\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.689856\n",
      "[100]\tvalid_0's l1: 0.646956\n",
      "[150]\tvalid_0's l1: 0.621902\n",
      "[200]\tvalid_0's l1: 0.604978\n",
      "[250]\tvalid_0's l1: 0.593021\n",
      "[300]\tvalid_0's l1: 0.583974\n",
      "[350]\tvalid_0's l1: 0.576831\n",
      "[400]\tvalid_0's l1: 0.570888\n",
      "[450]\tvalid_0's l1: 0.566197\n",
      "[500]\tvalid_0's l1: 0.562307\n",
      "[550]\tvalid_0's l1: 0.559315\n",
      "[600]\tvalid_0's l1: 0.556754\n",
      "[650]\tvalid_0's l1: 0.554578\n",
      "[700]\tvalid_0's l1: 0.552576\n",
      "[750]\tvalid_0's l1: 0.550802\n",
      "[800]\tvalid_0's l1: 0.549032\n",
      "[850]\tvalid_0's l1: 0.54742\n",
      "[900]\tvalid_0's l1: 0.545898\n",
      "[950]\tvalid_0's l1: 0.54467\n",
      "[1000]\tvalid_0's l1: 0.543531\n",
      "[1050]\tvalid_0's l1: 0.542593\n",
      "[1100]\tvalid_0's l1: 0.541709\n",
      "[1150]\tvalid_0's l1: 0.540959\n",
      "[1200]\tvalid_0's l1: 0.540135\n",
      "[1250]\tvalid_0's l1: 0.539283\n",
      "[1300]\tvalid_0's l1: 0.538615\n",
      "[1350]\tvalid_0's l1: 0.537913\n",
      "[1400]\tvalid_0's l1: 0.537212\n",
      "[1450]\tvalid_0's l1: 0.536386\n",
      "[1500]\tvalid_0's l1: 0.535736\n",
      "[1550]\tvalid_0's l1: 0.535063\n",
      "[1600]\tvalid_0's l1: 0.534516\n",
      "[1650]\tvalid_0's l1: 0.533987\n",
      "[1700]\tvalid_0's l1: 0.533485\n",
      "[1750]\tvalid_0's l1: 0.532945\n",
      "[1800]\tvalid_0's l1: 0.532441\n",
      "[1850]\tvalid_0's l1: 0.531943\n",
      "[1900]\tvalid_0's l1: 0.531487\n",
      "[1950]\tvalid_0's l1: 0.531058\n",
      "[2000]\tvalid_0's l1: 0.530723\n",
      "[2050]\tvalid_0's l1: 0.530278\n",
      "[2100]\tvalid_0's l1: 0.529893\n",
      "[2150]\tvalid_0's l1: 0.529414\n",
      "[2200]\tvalid_0's l1: 0.528948\n",
      "[2250]\tvalid_0's l1: 0.5285\n",
      "[2300]\tvalid_0's l1: 0.528124\n",
      "[2350]\tvalid_0's l1: 0.527742\n",
      "[2400]\tvalid_0's l1: 0.527396\n",
      "[2450]\tvalid_0's l1: 0.527057\n",
      "[2500]\tvalid_0's l1: 0.526704\n",
      "[2550]\tvalid_0's l1: 0.526396\n",
      "[2600]\tvalid_0's l1: 0.526125\n",
      "[2650]\tvalid_0's l1: 0.525849\n",
      "[2700]\tvalid_0's l1: 0.52557\n",
      "[2750]\tvalid_0's l1: 0.525237\n",
      "[2800]\tvalid_0's l1: 0.524951\n",
      "[2850]\tvalid_0's l1: 0.524717\n",
      "[2900]\tvalid_0's l1: 0.524435\n",
      "[2950]\tvalid_0's l1: 0.524066\n",
      "[3000]\tvalid_0's l1: 0.523779\n",
      "[3050]\tvalid_0's l1: 0.523505\n",
      "[3100]\tvalid_0's l1: 0.523251\n",
      "[3150]\tvalid_0's l1: 0.523015\n",
      "[3200]\tvalid_0's l1: 0.5228\n",
      "[3250]\tvalid_0's l1: 0.522531\n",
      "[3300]\tvalid_0's l1: 0.522307\n",
      "[3350]\tvalid_0's l1: 0.522099\n",
      "[3400]\tvalid_0's l1: 0.521891\n",
      "[3450]\tvalid_0's l1: 0.521641\n",
      "[3500]\tvalid_0's l1: 0.521467\n",
      "[3550]\tvalid_0's l1: 0.521262\n",
      "[3600]\tvalid_0's l1: 0.521092\n",
      "[3650]\tvalid_0's l1: 0.520875\n",
      "[3700]\tvalid_0's l1: 0.520699\n",
      "[3750]\tvalid_0's l1: 0.520543\n",
      "[3800]\tvalid_0's l1: 0.520357\n",
      "[3850]\tvalid_0's l1: 0.52016\n",
      "[3900]\tvalid_0's l1: 0.519979\n",
      "[3950]\tvalid_0's l1: 0.519791\n",
      "[4000]\tvalid_0's l1: 0.51961\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3994]\tvalid_0's l1: 0.519592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:  10%|â–ˆ         | 2/20 [28:06<4:09:21, 831.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Done in 774.7s. Fold SMAPE: 51.7753%\n",
      "\n",
      "--- Fold 3/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 756428\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.002322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.715357\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.699166\n",
      "[100]\tvalid_0's l1: 0.657504\n",
      "[150]\tvalid_0's l1: 0.632171\n",
      "[200]\tvalid_0's l1: 0.614862\n",
      "[250]\tvalid_0's l1: 0.60147\n",
      "[300]\tvalid_0's l1: 0.591395\n",
      "[350]\tvalid_0's l1: 0.583234\n",
      "[400]\tvalid_0's l1: 0.576615\n",
      "[450]\tvalid_0's l1: 0.571054\n",
      "[500]\tvalid_0's l1: 0.566282\n",
      "[550]\tvalid_0's l1: 0.562481\n",
      "[600]\tvalid_0's l1: 0.559221\n",
      "[650]\tvalid_0's l1: 0.556492\n",
      "[700]\tvalid_0's l1: 0.554219\n",
      "[750]\tvalid_0's l1: 0.551827\n",
      "[800]\tvalid_0's l1: 0.549587\n",
      "[850]\tvalid_0's l1: 0.547644\n",
      "[900]\tvalid_0's l1: 0.545928\n",
      "[950]\tvalid_0's l1: 0.544549\n",
      "[1000]\tvalid_0's l1: 0.543246\n",
      "[1050]\tvalid_0's l1: 0.542187\n",
      "[1100]\tvalid_0's l1: 0.54123\n",
      "[1150]\tvalid_0's l1: 0.540273\n",
      "[1200]\tvalid_0's l1: 0.539286\n",
      "[1250]\tvalid_0's l1: 0.538459\n",
      "[1300]\tvalid_0's l1: 0.537522\n",
      "[1350]\tvalid_0's l1: 0.5368\n",
      "[1400]\tvalid_0's l1: 0.536108\n",
      "[1450]\tvalid_0's l1: 0.535437\n",
      "[1500]\tvalid_0's l1: 0.534859\n",
      "[1550]\tvalid_0's l1: 0.534317\n",
      "[1600]\tvalid_0's l1: 0.533676\n",
      "[1650]\tvalid_0's l1: 0.533124\n",
      "[1700]\tvalid_0's l1: 0.53255\n",
      "[1750]\tvalid_0's l1: 0.532054\n",
      "[1800]\tvalid_0's l1: 0.531553\n",
      "[1850]\tvalid_0's l1: 0.531007\n",
      "[1900]\tvalid_0's l1: 0.530545\n",
      "[1950]\tvalid_0's l1: 0.530006\n",
      "[2000]\tvalid_0's l1: 0.529601\n",
      "[2050]\tvalid_0's l1: 0.529205\n",
      "[2100]\tvalid_0's l1: 0.528757\n",
      "[2150]\tvalid_0's l1: 0.528248\n",
      "[2200]\tvalid_0's l1: 0.527904\n",
      "[2250]\tvalid_0's l1: 0.527529\n",
      "[2300]\tvalid_0's l1: 0.527168\n",
      "[2350]\tvalid_0's l1: 0.52685\n",
      "[2400]\tvalid_0's l1: 0.526514\n",
      "[2450]\tvalid_0's l1: 0.52626\n",
      "[2500]\tvalid_0's l1: 0.52593\n",
      "[2550]\tvalid_0's l1: 0.525532\n",
      "[2600]\tvalid_0's l1: 0.525245\n",
      "[2650]\tvalid_0's l1: 0.524937\n",
      "[2700]\tvalid_0's l1: 0.524633\n",
      "[2750]\tvalid_0's l1: 0.524394\n",
      "[2800]\tvalid_0's l1: 0.524131\n",
      "[2850]\tvalid_0's l1: 0.523773\n",
      "[2900]\tvalid_0's l1: 0.523492\n",
      "[2950]\tvalid_0's l1: 0.523223\n",
      "[3000]\tvalid_0's l1: 0.522985\n",
      "[3050]\tvalid_0's l1: 0.522788\n",
      "[3100]\tvalid_0's l1: 0.522437\n",
      "[3150]\tvalid_0's l1: 0.522214\n",
      "[3200]\tvalid_0's l1: 0.522028\n",
      "[3250]\tvalid_0's l1: 0.521812\n",
      "[3300]\tvalid_0's l1: 0.521644\n",
      "[3350]\tvalid_0's l1: 0.521444\n",
      "[3400]\tvalid_0's l1: 0.521302\n",
      "[3450]\tvalid_0's l1: 0.521172\n",
      "[3500]\tvalid_0's l1: 0.520919\n",
      "[3550]\tvalid_0's l1: 0.520659\n",
      "[3600]\tvalid_0's l1: 0.520477\n",
      "[3650]\tvalid_0's l1: 0.520334\n",
      "[3700]\tvalid_0's l1: 0.520124\n",
      "[3750]\tvalid_0's l1: 0.519895\n",
      "[3800]\tvalid_0's l1: 0.519762\n",
      "[3850]\tvalid_0's l1: 0.51958\n",
      "[3900]\tvalid_0's l1: 0.519428\n",
      "[3950]\tvalid_0's l1: 0.51926\n",
      "[4000]\tvalid_0's l1: 0.519064\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.519064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:  15%|â–ˆâ–Œ        | 3/20 [41:01<3:48:11, 805.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Done in 774.5s. Fold SMAPE: 52.1717%\n",
      "\n",
      "--- Fold 4/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 755962\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.001680 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.708050\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.690414\n",
      "[100]\tvalid_0's l1: 0.648021\n",
      "[150]\tvalid_0's l1: 0.622142\n",
      "[200]\tvalid_0's l1: 0.604295\n",
      "[250]\tvalid_0's l1: 0.591317\n",
      "[300]\tvalid_0's l1: 0.581938\n",
      "[350]\tvalid_0's l1: 0.574687\n",
      "[400]\tvalid_0's l1: 0.56832\n",
      "[450]\tvalid_0's l1: 0.563463\n",
      "[500]\tvalid_0's l1: 0.559629\n",
      "[550]\tvalid_0's l1: 0.555982\n",
      "[600]\tvalid_0's l1: 0.552814\n",
      "[650]\tvalid_0's l1: 0.550167\n",
      "[700]\tvalid_0's l1: 0.548089\n",
      "[750]\tvalid_0's l1: 0.546169\n",
      "[800]\tvalid_0's l1: 0.544619\n",
      "[850]\tvalid_0's l1: 0.543166\n",
      "[900]\tvalid_0's l1: 0.541969\n",
      "[950]\tvalid_0's l1: 0.540899\n",
      "[1000]\tvalid_0's l1: 0.539971\n",
      "[1050]\tvalid_0's l1: 0.538973\n",
      "[1100]\tvalid_0's l1: 0.537952\n",
      "[1150]\tvalid_0's l1: 0.537092\n",
      "[1200]\tvalid_0's l1: 0.536254\n",
      "[1250]\tvalid_0's l1: 0.535587\n",
      "[1300]\tvalid_0's l1: 0.534745\n",
      "[1350]\tvalid_0's l1: 0.533941\n",
      "[1400]\tvalid_0's l1: 0.533115\n",
      "[1450]\tvalid_0's l1: 0.532286\n",
      "[1500]\tvalid_0's l1: 0.531576\n",
      "[1550]\tvalid_0's l1: 0.530975\n",
      "[1600]\tvalid_0's l1: 0.530512\n",
      "[1650]\tvalid_0's l1: 0.529988\n",
      "[1700]\tvalid_0's l1: 0.529421\n",
      "[1750]\tvalid_0's l1: 0.528934\n",
      "[1800]\tvalid_0's l1: 0.528413\n",
      "[1850]\tvalid_0's l1: 0.527934\n",
      "[1900]\tvalid_0's l1: 0.527549\n",
      "[1950]\tvalid_0's l1: 0.527189\n",
      "[2000]\tvalid_0's l1: 0.526838\n",
      "[2050]\tvalid_0's l1: 0.526471\n",
      "[2100]\tvalid_0's l1: 0.526108\n",
      "[2150]\tvalid_0's l1: 0.525722\n",
      "[2200]\tvalid_0's l1: 0.525361\n",
      "[2250]\tvalid_0's l1: 0.52501\n",
      "[2300]\tvalid_0's l1: 0.524729\n",
      "[2350]\tvalid_0's l1: 0.524403\n",
      "[2400]\tvalid_0's l1: 0.524085\n",
      "[2450]\tvalid_0's l1: 0.523739\n",
      "[2500]\tvalid_0's l1: 0.523479\n",
      "[2550]\tvalid_0's l1: 0.523186\n",
      "[2600]\tvalid_0's l1: 0.522901\n",
      "[2650]\tvalid_0's l1: 0.52269\n",
      "[2700]\tvalid_0's l1: 0.522456\n",
      "[2750]\tvalid_0's l1: 0.522251\n",
      "[2800]\tvalid_0's l1: 0.522015\n",
      "[2850]\tvalid_0's l1: 0.52176\n",
      "[2900]\tvalid_0's l1: 0.521514\n",
      "[2950]\tvalid_0's l1: 0.521233\n",
      "[3000]\tvalid_0's l1: 0.521014\n",
      "[3050]\tvalid_0's l1: 0.520801\n",
      "[3100]\tvalid_0's l1: 0.520595\n",
      "[3150]\tvalid_0's l1: 0.520408\n",
      "[3200]\tvalid_0's l1: 0.520245\n",
      "[3250]\tvalid_0's l1: 0.519998\n",
      "[3300]\tvalid_0's l1: 0.519736\n",
      "[3350]\tvalid_0's l1: 0.519509\n",
      "[3400]\tvalid_0's l1: 0.519302\n",
      "[3450]\tvalid_0's l1: 0.519113\n",
      "[3500]\tvalid_0's l1: 0.518911\n",
      "[3550]\tvalid_0's l1: 0.518761\n",
      "[3600]\tvalid_0's l1: 0.518599\n",
      "[3650]\tvalid_0's l1: 0.518447\n",
      "[3700]\tvalid_0's l1: 0.518288\n",
      "[3750]\tvalid_0's l1: 0.518158\n",
      "[3800]\tvalid_0's l1: 0.518012\n",
      "[3850]\tvalid_0's l1: 0.517877\n",
      "[3900]\tvalid_0's l1: 0.517691\n",
      "[3950]\tvalid_0's l1: 0.517466\n",
      "[4000]\tvalid_0's l1: 0.517314\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.517314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:  20%|â–ˆâ–ˆ        | 4/20 [54:12<3:33:14, 799.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Done in 790.8s. Fold SMAPE: 51.8220%\n",
      "\n",
      "--- Fold 5/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 756372\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.002052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.708050\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.697982\n",
      "[100]\tvalid_0's l1: 0.653775\n",
      "[150]\tvalid_0's l1: 0.625445\n",
      "[200]\tvalid_0's l1: 0.605438\n",
      "[250]\tvalid_0's l1: 0.590059\n",
      "[300]\tvalid_0's l1: 0.579395\n",
      "[350]\tvalid_0's l1: 0.570846\n",
      "[400]\tvalid_0's l1: 0.56381\n",
      "[450]\tvalid_0's l1: 0.558145\n",
      "[500]\tvalid_0's l1: 0.55344\n",
      "[550]\tvalid_0's l1: 0.549295\n",
      "[600]\tvalid_0's l1: 0.545671\n",
      "[650]\tvalid_0's l1: 0.542723\n",
      "[700]\tvalid_0's l1: 0.54006\n",
      "[750]\tvalid_0's l1: 0.537611\n",
      "[800]\tvalid_0's l1: 0.535373\n",
      "[850]\tvalid_0's l1: 0.533509\n",
      "[900]\tvalid_0's l1: 0.531701\n",
      "[950]\tvalid_0's l1: 0.530104\n",
      "[1000]\tvalid_0's l1: 0.52871\n",
      "[1050]\tvalid_0's l1: 0.527409\n",
      "[1100]\tvalid_0's l1: 0.526211\n",
      "[1150]\tvalid_0's l1: 0.525279\n",
      "[1200]\tvalid_0's l1: 0.524259\n",
      "[1250]\tvalid_0's l1: 0.523114\n",
      "[1300]\tvalid_0's l1: 0.522054\n",
      "[1350]\tvalid_0's l1: 0.521244\n",
      "[1400]\tvalid_0's l1: 0.520589\n",
      "[1450]\tvalid_0's l1: 0.519955\n",
      "[1500]\tvalid_0's l1: 0.519346\n",
      "[1550]\tvalid_0's l1: 0.518726\n",
      "[1600]\tvalid_0's l1: 0.518125\n",
      "[1650]\tvalid_0's l1: 0.517462\n",
      "[1700]\tvalid_0's l1: 0.516817\n",
      "[1750]\tvalid_0's l1: 0.516153\n",
      "[1800]\tvalid_0's l1: 0.515648\n",
      "[1850]\tvalid_0's l1: 0.515125\n",
      "[1900]\tvalid_0's l1: 0.514589\n",
      "[1950]\tvalid_0's l1: 0.514108\n",
      "[2000]\tvalid_0's l1: 0.513619\n",
      "[2050]\tvalid_0's l1: 0.513242\n",
      "[2100]\tvalid_0's l1: 0.512847\n",
      "[2150]\tvalid_0's l1: 0.512443\n",
      "[2200]\tvalid_0's l1: 0.512\n",
      "[2250]\tvalid_0's l1: 0.511576\n",
      "[2300]\tvalid_0's l1: 0.511233\n",
      "[2350]\tvalid_0's l1: 0.510972\n",
      "[2400]\tvalid_0's l1: 0.510578\n",
      "[2450]\tvalid_0's l1: 0.510322\n",
      "[2500]\tvalid_0's l1: 0.510061\n",
      "[2550]\tvalid_0's l1: 0.509771\n",
      "[2600]\tvalid_0's l1: 0.509528\n",
      "[2650]\tvalid_0's l1: 0.509211\n",
      "[2700]\tvalid_0's l1: 0.509022\n",
      "[2750]\tvalid_0's l1: 0.508825\n",
      "[2800]\tvalid_0's l1: 0.508604\n",
      "[2850]\tvalid_0's l1: 0.508316\n",
      "[2900]\tvalid_0's l1: 0.507996\n",
      "[2950]\tvalid_0's l1: 0.507728\n",
      "[3000]\tvalid_0's l1: 0.507503\n",
      "[3050]\tvalid_0's l1: 0.507294\n",
      "[3100]\tvalid_0's l1: 0.50703\n",
      "[3150]\tvalid_0's l1: 0.506794\n",
      "[3200]\tvalid_0's l1: 0.50659\n",
      "[3250]\tvalid_0's l1: 0.506406\n",
      "[3300]\tvalid_0's l1: 0.506268\n",
      "[3350]\tvalid_0's l1: 0.506049\n",
      "[3400]\tvalid_0's l1: 0.505915\n",
      "[3450]\tvalid_0's l1: 0.505701\n",
      "[3500]\tvalid_0's l1: 0.505438\n",
      "[3550]\tvalid_0's l1: 0.505256\n",
      "[3600]\tvalid_0's l1: 0.505071\n",
      "[3650]\tvalid_0's l1: 0.504853\n",
      "[3700]\tvalid_0's l1: 0.504698\n",
      "[3750]\tvalid_0's l1: 0.504521\n",
      "[3800]\tvalid_0's l1: 0.504334\n",
      "[3850]\tvalid_0's l1: 0.504119\n",
      "[3900]\tvalid_0's l1: 0.503967\n",
      "[3950]\tvalid_0's l1: 0.50385\n",
      "[4000]\tvalid_0's l1: 0.503681\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.503681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [1:07:11<3:18:05, 792.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Done in 779.2s. Fold SMAPE: 50.6633%\n",
      "\n",
      "--- Fold 6/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 756107\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.001881 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.708050\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.689783\n",
      "[100]\tvalid_0's l1: 0.64611\n",
      "[150]\tvalid_0's l1: 0.618352\n",
      "[200]\tvalid_0's l1: 0.598992\n",
      "[250]\tvalid_0's l1: 0.584808\n",
      "[300]\tvalid_0's l1: 0.574721\n",
      "[350]\tvalid_0's l1: 0.567014\n",
      "[400]\tvalid_0's l1: 0.560698\n",
      "[450]\tvalid_0's l1: 0.555492\n",
      "[500]\tvalid_0's l1: 0.550973\n",
      "[550]\tvalid_0's l1: 0.547154\n",
      "[600]\tvalid_0's l1: 0.54384\n",
      "[650]\tvalid_0's l1: 0.540733\n",
      "[700]\tvalid_0's l1: 0.538123\n",
      "[750]\tvalid_0's l1: 0.535895\n",
      "[800]\tvalid_0's l1: 0.53381\n",
      "[850]\tvalid_0's l1: 0.532062\n",
      "[900]\tvalid_0's l1: 0.530548\n",
      "[950]\tvalid_0's l1: 0.52932\n",
      "[1000]\tvalid_0's l1: 0.528127\n",
      "[1050]\tvalid_0's l1: 0.527213\n",
      "[1100]\tvalid_0's l1: 0.526265\n",
      "[1150]\tvalid_0's l1: 0.525404\n",
      "[1200]\tvalid_0's l1: 0.524473\n",
      "[1250]\tvalid_0's l1: 0.52364\n",
      "[1300]\tvalid_0's l1: 0.52281\n",
      "[1350]\tvalid_0's l1: 0.522088\n",
      "[1400]\tvalid_0's l1: 0.521518\n",
      "[1450]\tvalid_0's l1: 0.52076\n",
      "[1500]\tvalid_0's l1: 0.520057\n",
      "[1550]\tvalid_0's l1: 0.519396\n",
      "[1600]\tvalid_0's l1: 0.518811\n",
      "[1650]\tvalid_0's l1: 0.518264\n",
      "[1700]\tvalid_0's l1: 0.517738\n",
      "[1750]\tvalid_0's l1: 0.517148\n",
      "[1800]\tvalid_0's l1: 0.516643\n",
      "[1850]\tvalid_0's l1: 0.516143\n",
      "[1900]\tvalid_0's l1: 0.515643\n",
      "[1950]\tvalid_0's l1: 0.515192\n",
      "[2000]\tvalid_0's l1: 0.514808\n",
      "[2050]\tvalid_0's l1: 0.514403\n",
      "[2100]\tvalid_0's l1: 0.514111\n",
      "[2150]\tvalid_0's l1: 0.513646\n",
      "[2200]\tvalid_0's l1: 0.513263\n",
      "[2250]\tvalid_0's l1: 0.512853\n",
      "[2300]\tvalid_0's l1: 0.512402\n",
      "[2350]\tvalid_0's l1: 0.511992\n",
      "[2400]\tvalid_0's l1: 0.511715\n",
      "[2450]\tvalid_0's l1: 0.511395\n",
      "[2500]\tvalid_0's l1: 0.510992\n",
      "[2550]\tvalid_0's l1: 0.510679\n",
      "[2600]\tvalid_0's l1: 0.510397\n",
      "[2650]\tvalid_0's l1: 0.510032\n",
      "[2700]\tvalid_0's l1: 0.509691\n",
      "[2750]\tvalid_0's l1: 0.509421\n",
      "[2800]\tvalid_0's l1: 0.509142\n",
      "[2850]\tvalid_0's l1: 0.50887\n",
      "[2900]\tvalid_0's l1: 0.508611\n",
      "[2950]\tvalid_0's l1: 0.508348\n",
      "[3000]\tvalid_0's l1: 0.508037\n",
      "[3050]\tvalid_0's l1: 0.507869\n",
      "[3100]\tvalid_0's l1: 0.50764\n",
      "[3150]\tvalid_0's l1: 0.50746\n",
      "[3200]\tvalid_0's l1: 0.507289\n",
      "[3250]\tvalid_0's l1: 0.507039\n",
      "[3300]\tvalid_0's l1: 0.506867\n",
      "[3350]\tvalid_0's l1: 0.506616\n",
      "[3400]\tvalid_0's l1: 0.506416\n",
      "[3450]\tvalid_0's l1: 0.506185\n",
      "[3500]\tvalid_0's l1: 0.505991\n",
      "[3550]\tvalid_0's l1: 0.505783\n",
      "[3600]\tvalid_0's l1: 0.505603\n",
      "[3650]\tvalid_0's l1: 0.505367\n",
      "[3700]\tvalid_0's l1: 0.505239\n",
      "[3750]\tvalid_0's l1: 0.505021\n",
      "[3800]\tvalid_0's l1: 0.504852\n",
      "[3850]\tvalid_0's l1: 0.504704\n",
      "[3900]\tvalid_0's l1: 0.504519\n",
      "[3950]\tvalid_0's l1: 0.504364\n",
      "[4000]\tvalid_0's l1: 0.504194\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3994]\tvalid_0's l1: 0.504188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [1:20:37<3:05:56, 796.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Done in 805.6s. Fold SMAPE: 50.7359%\n",
      "\n",
      "--- Fold 7/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 755857\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.006899 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.707550\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.688216\n",
      "[100]\tvalid_0's l1: 0.646654\n",
      "[150]\tvalid_0's l1: 0.619857\n",
      "[200]\tvalid_0's l1: 0.601094\n",
      "[250]\tvalid_0's l1: 0.588222\n",
      "[300]\tvalid_0's l1: 0.578523\n",
      "[350]\tvalid_0's l1: 0.570684\n",
      "[400]\tvalid_0's l1: 0.564857\n",
      "[450]\tvalid_0's l1: 0.559757\n",
      "[500]\tvalid_0's l1: 0.555553\n",
      "[550]\tvalid_0's l1: 0.551951\n",
      "[600]\tvalid_0's l1: 0.548732\n",
      "[650]\tvalid_0's l1: 0.546339\n",
      "[700]\tvalid_0's l1: 0.544188\n",
      "[750]\tvalid_0's l1: 0.542328\n",
      "[800]\tvalid_0's l1: 0.540585\n",
      "[850]\tvalid_0's l1: 0.539162\n",
      "[900]\tvalid_0's l1: 0.537659\n",
      "[950]\tvalid_0's l1: 0.536431\n",
      "[1000]\tvalid_0's l1: 0.535316\n",
      "[1050]\tvalid_0's l1: 0.534338\n",
      "[1100]\tvalid_0's l1: 0.533427\n",
      "[1150]\tvalid_0's l1: 0.532594\n",
      "[1200]\tvalid_0's l1: 0.531871\n",
      "[1250]\tvalid_0's l1: 0.531128\n",
      "[1300]\tvalid_0's l1: 0.530362\n",
      "[1350]\tvalid_0's l1: 0.529606\n",
      "[1400]\tvalid_0's l1: 0.528857\n",
      "[1450]\tvalid_0's l1: 0.528124\n",
      "[1500]\tvalid_0's l1: 0.527574\n",
      "[1550]\tvalid_0's l1: 0.527056\n",
      "[1600]\tvalid_0's l1: 0.52649\n",
      "[1650]\tvalid_0's l1: 0.525868\n",
      "[1700]\tvalid_0's l1: 0.525316\n",
      "[1750]\tvalid_0's l1: 0.524831\n",
      "[1800]\tvalid_0's l1: 0.524378\n",
      "[1850]\tvalid_0's l1: 0.52392\n",
      "[1900]\tvalid_0's l1: 0.523466\n",
      "[1950]\tvalid_0's l1: 0.523027\n",
      "[2000]\tvalid_0's l1: 0.522561\n",
      "[2050]\tvalid_0's l1: 0.522242\n",
      "[2100]\tvalid_0's l1: 0.521841\n",
      "[2150]\tvalid_0's l1: 0.521465\n",
      "[2200]\tvalid_0's l1: 0.521147\n",
      "[2250]\tvalid_0's l1: 0.520886\n",
      "[2300]\tvalid_0's l1: 0.520538\n",
      "[2350]\tvalid_0's l1: 0.520249\n",
      "[2400]\tvalid_0's l1: 0.519945\n",
      "[2450]\tvalid_0's l1: 0.519643\n",
      "[2500]\tvalid_0's l1: 0.519284\n",
      "[2550]\tvalid_0's l1: 0.518881\n",
      "[2600]\tvalid_0's l1: 0.518549\n",
      "[2650]\tvalid_0's l1: 0.518256\n",
      "[2700]\tvalid_0's l1: 0.518054\n",
      "[2750]\tvalid_0's l1: 0.51783\n",
      "[2800]\tvalid_0's l1: 0.517599\n",
      "[2850]\tvalid_0's l1: 0.517393\n",
      "[2900]\tvalid_0's l1: 0.517155\n",
      "[2950]\tvalid_0's l1: 0.516962\n",
      "[3000]\tvalid_0's l1: 0.516693\n",
      "[3050]\tvalid_0's l1: 0.516534\n",
      "[3100]\tvalid_0's l1: 0.516272\n",
      "[3150]\tvalid_0's l1: 0.516065\n",
      "[3200]\tvalid_0's l1: 0.515879\n",
      "[3250]\tvalid_0's l1: 0.515691\n",
      "[3300]\tvalid_0's l1: 0.515452\n",
      "[3350]\tvalid_0's l1: 0.515276\n",
      "[3400]\tvalid_0's l1: 0.515101\n",
      "[3450]\tvalid_0's l1: 0.514984\n",
      "[3500]\tvalid_0's l1: 0.514855\n",
      "[3550]\tvalid_0's l1: 0.514657\n",
      "[3600]\tvalid_0's l1: 0.514501\n",
      "[3650]\tvalid_0's l1: 0.514406\n",
      "[3700]\tvalid_0's l1: 0.514239\n",
      "[3750]\tvalid_0's l1: 0.514105\n",
      "[3800]\tvalid_0's l1: 0.513973\n",
      "[3850]\tvalid_0's l1: 0.513849\n",
      "[3900]\tvalid_0's l1: 0.513709\n",
      "[3950]\tvalid_0's l1: 0.513553\n",
      "[4000]\tvalid_0's l1: 0.513365\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.513365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [1:36:17<3:02:49, 843.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Done in 940.1s. Fold SMAPE: 51.3184%\n",
      "\n",
      "--- Fold 8/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 756364\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.002047 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.708050\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.679326\n",
      "[100]\tvalid_0's l1: 0.637148\n",
      "[150]\tvalid_0's l1: 0.610992\n",
      "[200]\tvalid_0's l1: 0.593528\n",
      "[250]\tvalid_0's l1: 0.580135\n",
      "[300]\tvalid_0's l1: 0.569943\n",
      "[350]\tvalid_0's l1: 0.562118\n",
      "[400]\tvalid_0's l1: 0.555851\n",
      "[450]\tvalid_0's l1: 0.550932\n",
      "[500]\tvalid_0's l1: 0.546737\n",
      "[550]\tvalid_0's l1: 0.543076\n",
      "[600]\tvalid_0's l1: 0.5397\n",
      "[650]\tvalid_0's l1: 0.536909\n",
      "[700]\tvalid_0's l1: 0.534444\n",
      "[750]\tvalid_0's l1: 0.532258\n",
      "[800]\tvalid_0's l1: 0.53039\n",
      "[850]\tvalid_0's l1: 0.528681\n",
      "[900]\tvalid_0's l1: 0.527063\n",
      "[950]\tvalid_0's l1: 0.525641\n",
      "[1000]\tvalid_0's l1: 0.524578\n",
      "[1050]\tvalid_0's l1: 0.523525\n",
      "[1100]\tvalid_0's l1: 0.522489\n",
      "[1150]\tvalid_0's l1: 0.521608\n",
      "[1200]\tvalid_0's l1: 0.520682\n",
      "[1250]\tvalid_0's l1: 0.51985\n",
      "[1300]\tvalid_0's l1: 0.519034\n",
      "[1350]\tvalid_0's l1: 0.518206\n",
      "[1400]\tvalid_0's l1: 0.517591\n",
      "[1450]\tvalid_0's l1: 0.516777\n",
      "[1500]\tvalid_0's l1: 0.51613\n",
      "[1550]\tvalid_0's l1: 0.515453\n",
      "[1600]\tvalid_0's l1: 0.514784\n",
      "[1650]\tvalid_0's l1: 0.514188\n",
      "[1700]\tvalid_0's l1: 0.513655\n",
      "[1750]\tvalid_0's l1: 0.513138\n",
      "[1800]\tvalid_0's l1: 0.51267\n",
      "[1850]\tvalid_0's l1: 0.512152\n",
      "[1900]\tvalid_0's l1: 0.511673\n",
      "[1950]\tvalid_0's l1: 0.511301\n",
      "[2000]\tvalid_0's l1: 0.510804\n",
      "[2050]\tvalid_0's l1: 0.510381\n",
      "[2100]\tvalid_0's l1: 0.510026\n",
      "[2150]\tvalid_0's l1: 0.50966\n",
      "[2200]\tvalid_0's l1: 0.509339\n",
      "[2250]\tvalid_0's l1: 0.509003\n",
      "[2300]\tvalid_0's l1: 0.50869\n",
      "[2350]\tvalid_0's l1: 0.508408\n",
      "[2400]\tvalid_0's l1: 0.508097\n",
      "[2450]\tvalid_0's l1: 0.507816\n",
      "[2500]\tvalid_0's l1: 0.507573\n",
      "[2550]\tvalid_0's l1: 0.507272\n",
      "[2600]\tvalid_0's l1: 0.507006\n",
      "[2650]\tvalid_0's l1: 0.506683\n",
      "[2700]\tvalid_0's l1: 0.50648\n",
      "[2750]\tvalid_0's l1: 0.50625\n",
      "[2800]\tvalid_0's l1: 0.505986\n",
      "[2850]\tvalid_0's l1: 0.505703\n",
      "[2900]\tvalid_0's l1: 0.505446\n",
      "[2950]\tvalid_0's l1: 0.505217\n",
      "[3000]\tvalid_0's l1: 0.504898\n",
      "[3050]\tvalid_0's l1: 0.5048\n",
      "[3100]\tvalid_0's l1: 0.504575\n",
      "[3150]\tvalid_0's l1: 0.504385\n",
      "[3200]\tvalid_0's l1: 0.504291\n",
      "[3250]\tvalid_0's l1: 0.504041\n",
      "[3300]\tvalid_0's l1: 0.503815\n",
      "[3350]\tvalid_0's l1: 0.503581\n",
      "[3400]\tvalid_0's l1: 0.503472\n",
      "[3450]\tvalid_0's l1: 0.503279\n",
      "[3500]\tvalid_0's l1: 0.503153\n",
      "[3550]\tvalid_0's l1: 0.502982\n",
      "[3600]\tvalid_0's l1: 0.502814\n",
      "[3650]\tvalid_0's l1: 0.502613\n",
      "[3700]\tvalid_0's l1: 0.502391\n",
      "[3750]\tvalid_0's l1: 0.502191\n",
      "[3800]\tvalid_0's l1: 0.502053\n",
      "[3850]\tvalid_0's l1: 0.501891\n",
      "[3900]\tvalid_0's l1: 0.501718\n",
      "[3950]\tvalid_0's l1: 0.501533\n",
      "[4000]\tvalid_0's l1: 0.501377\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's l1: 0.501377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [1:52:35<2:57:17, 886.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    âœ“ Done in 977.6s. Fold SMAPE: 50.1295%\n",
      "\n",
      "--- Fold 9/20 ---\n",
      "  - Data shapes: Train=(71250, 5054), Val=(3750, 5054)\n",
      "  - Sparsity: 98.56%\n",
      "  - Starting GPU training...\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 756344\n",
      "[LightGBM] [Info] Number of data points in the train set: 71250, number of used features: 5010\n",
      "[LightGBM] [Info] Using requested OpenCL platform 0 device 0\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) RaptorLake-S Mobile Graphics Controller, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 13 dense feature groups (1.09 MB) transferred to GPU in 0.002390 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 2.708050\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's l1: 0.679194\n",
      "[100]\tvalid_0's l1: 0.636769\n",
      "[150]\tvalid_0's l1: 0.612162\n",
      "[200]\tvalid_0's l1: 0.595988\n",
      "[250]\tvalid_0's l1: 0.583753\n",
      "[300]\tvalid_0's l1: 0.575151\n",
      "[350]\tvalid_0's l1: 0.568364\n",
      "[400]\tvalid_0's l1: 0.562732\n",
      "[450]\tvalid_0's l1: 0.558153\n",
      "[500]\tvalid_0's l1: 0.554291\n",
      "[550]\tvalid_0's l1: 0.550879\n",
      "[600]\tvalid_0's l1: 0.547902\n",
      "[650]\tvalid_0's l1: 0.54544\n",
      "[700]\tvalid_0's l1: 0.543291\n",
      "[750]\tvalid_0's l1: 0.541471\n",
      "[800]\tvalid_0's l1: 0.539777\n",
      "[850]\tvalid_0's l1: 0.538245\n",
      "[900]\tvalid_0's l1: 0.536838\n",
      "[950]\tvalid_0's l1: 0.535546\n",
      "[1000]\tvalid_0's l1: 0.534351\n",
      "[1050]\tvalid_0's l1: 0.533379\n",
      "[1100]\tvalid_0's l1: 0.532365\n",
      "[1150]\tvalid_0's l1: 0.531461\n",
      "[1200]\tvalid_0's l1: 0.530436\n",
      "[1250]\tvalid_0's l1: 0.529565\n",
      "[1300]\tvalid_0's l1: 0.528821\n",
      "[1350]\tvalid_0's l1: 0.527976\n",
      "[1400]\tvalid_0's l1: 0.527251\n",
      "[1450]\tvalid_0's l1: 0.526432\n",
      "[1500]\tvalid_0's l1: 0.525766\n",
      "[1550]\tvalid_0's l1: 0.525277\n",
      "[1600]\tvalid_0's l1: 0.524745\n",
      "[1650]\tvalid_0's l1: 0.524261\n",
      "[1700]\tvalid_0's l1: 0.523801\n",
      "[1750]\tvalid_0's l1: 0.523235\n",
      "[1800]\tvalid_0's l1: 0.522709\n",
      "[1850]\tvalid_0's l1: 0.522186\n",
      "[1900]\tvalid_0's l1: 0.521715\n",
      "[1950]\tvalid_0's l1: 0.521251\n",
      "[2000]\tvalid_0's l1: 0.520705\n",
      "[2050]\tvalid_0's l1: 0.520103\n",
      "[2100]\tvalid_0's l1: 0.519698\n",
      "[2150]\tvalid_0's l1: 0.519351\n",
      "[2200]\tvalid_0's l1: 0.518994\n",
      "[2250]\tvalid_0's l1: 0.518641\n",
      "[2300]\tvalid_0's l1: 0.51828\n",
      "[2350]\tvalid_0's l1: 0.517995\n",
      "[2400]\tvalid_0's l1: 0.517593\n",
      "[2450]\tvalid_0's l1: 0.517251\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, csr_matrix\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse\n",
    "import gc\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Configuration & Setup ---\n",
    "CONFIG = {\n",
    "    'n_folds': 20,\n",
    "    'random_state': 42,\n",
    "    'data_dir': 'processed_data',\n",
    "    'gpu_verbose': 1,\n",
    "    'batch_size': None,  # Set to int (e.g., 100_000) if you want to batch predictions\n",
    "}\n",
    "\n",
    "# --- 2. Helper Functions ---\n",
    "def smape(y_true, y_pred):\n",
    "    y_true_actual = np.expm1(y_true)\n",
    "    y_pred_actual = np.expm1(y_pred)\n",
    "    numerator = np.abs(y_pred_actual - y_true_actual)\n",
    "    denominator = (np.abs(y_true_actual) + np.abs(y_pred_actual)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "def batch_predict(model, X, batch_size=100_000):\n",
    "    \"\"\"Predict in batches to reduce memory pressure.\"\"\"\n",
    "    if batch_size is None or X.shape[0] <= batch_size:\n",
    "        return model.predict(X)\n",
    "    preds = []\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        batch = X[i:i + batch_size]\n",
    "        pred = model.predict(batch)\n",
    "        preds.append(pred)\n",
    "        del batch, pred\n",
    "        gc.collect()\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# --- 3. GPU-Optimized Training Pipeline with Memory Cleanup ---\n",
    "def train_lightgbm_gpu(X, y):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸš€ Starting LightGBM GPU Training (20 Folds + Memory Safe) ðŸš€\")\n",
    "    print(f\"   Folds: {CONFIG['n_folds']}, Device: GPU\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if not scipy.sparse.isspmatrix_csr(X):\n",
    "        print(\"âš ï¸ Converting to CSR sparse format for GPU compatibility...\")\n",
    "        X = csr_matrix(X)\n",
    "    \n",
    "    kf = KFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_state'])\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression_l1',\n",
    "        'metric': 'mae',\n",
    "        'random_state': CONFIG['random_state'],\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 50,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1,\n",
    "        'device': 'gpu',\n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'verbose': CONFIG['gpu_verbose'],\n",
    "    }\n",
    "\n",
    "    oof_preds = np.zeros(len(y))\n",
    "    oof_scores = []\n",
    "    models = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tqdm(kf.split(X, y), total=CONFIG['n_folds'], desc=\"Overall CV Progress\")):\n",
    "        print(f\"\\n--- Fold {fold+1}/{CONFIG['n_folds']} ---\")\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        if not scipy.sparse.isspmatrix_csr(X_train):\n",
    "            X_train = csr_matrix(X_train)\n",
    "        if not scipy.sparse.isspmatrix_csr(X_val):\n",
    "            X_val = csr_matrix(X_val)\n",
    "\n",
    "        print(f\"  - Data shapes: Train={X_train.shape}, Val={X_val.shape}\")\n",
    "        print(f\"  - Sparsity: {100 * (1 - X_train.nnz / np.prod(X_train.shape)):.2f}%\")\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train, free_raw_data=True)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data, free_raw_data=True)\n",
    "\n",
    "        print(\"  - Starting GPU training...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            model = lgb.train(\n",
    "                params,\n",
    "                train_data,\n",
    "                valid_sets=[val_data],\n",
    "                num_boost_round=4000,\n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(stopping_rounds=200, verbose=True),\n",
    "                    lgb.log_evaluation(period=50)\n",
    "                ]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ GPU Training FAILED! Error: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "        # Predict in batches if configured\n",
    "        val_preds = batch_predict(model, X_val, batch_size=CONFIG['batch_size'])\n",
    "        oof_preds[val_idx] = val_preds\n",
    "        fold_smape = smape(y_val, val_preds)\n",
    "        oof_scores.append(fold_smape)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"    âœ“ Done in {elapsed:.1f}s. Fold SMAPE: {fold_smape:.4f}%\")\n",
    "\n",
    "        models.append(model)\n",
    "\n",
    "        # --- Aggressive memory cleanup ---\n",
    "        del X_train, X_val, y_train, y_val, train_data, val_data, val_preds\n",
    "        gc.collect()\n",
    "\n",
    "    # --- Final Evaluation ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ“Š Overall Cross-Validation Results (OOF)\")\n",
    "    print(\"=\"*50)\n",
    "    mean_smape = np.mean(oof_scores)\n",
    "    std_smape = np.std(oof_scores)\n",
    "    print(f\"LGBM | Mean SMAPE: {mean_smape:.4f}% (Std: {std_smape:.4f})\")\n",
    "\n",
    "    overall_oof_smape = smape(y, oof_preds)\n",
    "    print(f\"\\nFINAL | Overall OOF SMAPE: {overall_oof_smape:.4f}%\")\n",
    "\n",
    "    # --- Retrain Final Model on Full Data ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Retraining final LightGBM model on 100% of data for submission...\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    if not scipy.sparse.isspmatrix_csr(X):\n",
    "        X = csr_matrix(X)\n",
    "\n",
    "    train_data_full = lgb.Dataset(X, label=y, free_raw_data=True)\n",
    "    final_model = lgb.train(\n",
    "        params,\n",
    "        train_data_full,\n",
    "        num_boost_round=4000,\n",
    "        callbacks=[lgb.log_evaluation(period=100)]\n",
    "    )\n",
    "\n",
    "    final_model.save_model('final_lgbm_gpu_model.txt')\n",
    "    print(\"\\nâœ… Final retrained model saved as 'final_lgbm_gpu_model.txt'\")\n",
    "\n",
    "    # Clean up final dataset\n",
    "    del train_data_full\n",
    "    gc.collect()\n",
    "\n",
    "    return models\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"ðŸ” Verifying GPU setup...\")\n",
    "    try:\n",
    "        test_data = np.random.rand(100, 10)\n",
    "        test_label = np.random.rand(100)\n",
    "        test_dataset = lgb.Dataset(test_data, label=test_label)\n",
    "        test_params = {\n",
    "            'device': 'gpu',\n",
    "            'verbose': 1,\n",
    "            'num_leaves': 4,\n",
    "            'min_data_in_leaf': 1,\n",
    "            'num_iterations': 2\n",
    "        }\n",
    "        lgb.train(test_params, test_dataset)\n",
    "        print(\"  âœ… GPU test PASSED!\")\n",
    "        del test_data, test_label, test_dataset\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ GPU test FAILED! Error: {str(e)}\")\n",
    "        exit(1)\n",
    "\n",
    "    def load_precomputed_data(data_dir):\n",
    "        try:\n",
    "            print(\"\\n--- Loading final precomputed feature matrix for training ---\")\n",
    "            X = load_npz(os.path.join(data_dir, 'X_processed_train.npz'))\n",
    "            y_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "            print(f\"   âœ“ Features loaded. Shape: {X.shape}\")\n",
    "            print(f\"   âœ“ Labels loaded. Count: {len(y_df)}\")\n",
    "            return X, y_df['price_log'].values\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"FATAL ERROR: Could not load precomputed files. {e}\")\n",
    "            return None, None\n",
    "\n",
    "    X_final_train, y_final_train = load_precomputed_data(CONFIG['data_dir'])\n",
    "\n",
    "    if X_final_train is not None:\n",
    "        models = train_lightgbm_gpu(X_final_train, y_final_train)\n",
    "        # Optional: delete models if not needed to free memory\n",
    "        del models\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f796c985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading final precomputed feature matrix for training ---\n",
      "   âœ“ Features loaded. Shape: (75000, 9370)\n",
      "   âœ“ Labels loaded. Count: 75000\n",
      "\n",
      "==================================================\n",
      "ðŸš€ Starting LightGBM Training (20 folds) ðŸš€\n",
      "   Folds: 20, Device: CUDA\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1/20 ---\n",
      "  - Training LightGBM...\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall CV Progress:   0%|          | 0/20 [00:17<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 189\u001b[0m\n\u001b[0;32m    186\u001b[0m X_final_train, y_final_train \u001b[38;5;241m=\u001b[39m load_precomputed_data(CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_dir\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_final_train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     \u001b[43mtrain_lgbm_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_final_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_final_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 89\u001b[0m, in \u001b[0;36mtrain_lgbm_only\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Train LightGBM model\u001b[39;00m\n\u001b[0;32m     88\u001b[0m     model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlgb_params)\n\u001b[1;32m---> 89\u001b[0m     \u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlgbm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA Tree Learner was not enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1398\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\engine.py:297\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 297\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    299\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:3656\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[0;32m   3649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   3650\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   3651\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3652\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   3653\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   3654\u001b[0m     )\n\u001b[0;32m   3655\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 3656\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3657\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:2590\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2585\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\n\u001b[0;32m   2586\u001b[0m                 predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices\u001b[38;5;241m=\u001b[39mused_indices\n\u001b[0;32m   2587\u001b[0m             )\n\u001b[0;32m   2588\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2589\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 2590\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2596\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   2604\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:2183\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2174\u001b[0m     _safe_call(\n\u001b[0;32m   2175\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mLGBM_DatasetCreateFromFile(\n\u001b[0;32m   2176\u001b[0m             _c_str(\u001b[38;5;28mstr\u001b[39m(data)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2180\u001b[0m         )\n\u001b[0;32m   2181\u001b[0m     )\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsr_matrix):\n\u001b[1;32m-> 2183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__init_from_csr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, scipy\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mcsc_matrix):\n\u001b[0;32m   2185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_csc(data, params_str, ref_dataset)\n",
      "File \u001b[1;32mc:\\Users\\Akshit\\anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py:2404\u001b[0m, in \u001b[0;36mDataset.__init_from_csr\u001b[1;34m(self, csr, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m   2400\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m csr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m _MAX_INT32\n\u001b[0;32m   2401\u001b[0m csr_indices \u001b[38;5;241m=\u001b[39m csr\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2403\u001b[0m _safe_call(\n\u001b[1;32m-> 2404\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_DatasetCreateFromCSR\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mptr_indptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_indptr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcsr_indices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOINTER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2417\u001b[0m )\n\u001b[0;32m   2418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, hstack\n",
    "import joblib\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# --- 1. Configuration & Setup ---\n",
    "CONFIG = {\n",
    "    'n_folds': 20,  # Changed to 20 folds\n",
    "    'random_state': 42,\n",
    "    'data_dir': 'processed_data',\n",
    "}\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# --- 2. Helper Functions ---\n",
    "def smape(y_true, y_pred):\n",
    "    y_true_actual = np.expm1(y_true)\n",
    "    y_pred_actual = np.expm1(y_pred)\n",
    "    numerator = np.abs(y_pred_actual - y_true_actual)\n",
    "    denominator = (np.abs(y_true_actual) + np.abs(y_pred_actual)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear memory after each fold\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# --- 3. Main Training and Ensembling Pipeline ---\n",
    "def train_lgbm_only(X, y):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸš€ Starting LightGBM Training (20 folds) ðŸš€\")\n",
    "    print(f\"   Folds: {CONFIG['n_folds']}, Device: {DEVICE.upper()}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    kf = KFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['random_state'])\n",
    "    \n",
    "    # LightGBM Hyperparameters with GPU settings\n",
    "    lgb_params = {\n",
    "        'objective': 'regression_l1', \n",
    "        'metric': 'mae', \n",
    "        'random_state': CONFIG['random_state'], \n",
    "        'n_estimators': 4000, \n",
    "        'learning_rate': 0.01, \n",
    "        'num_leaves': 50, \n",
    "        'subsample': 0.7, \n",
    "        'colsample_bytree': 0.7, \n",
    "        'reg_alpha': 0.1, \n",
    "        'reg_lambda': 0.1, \n",
    "        'n_jobs': -1, \n",
    "        'device': DEVICE\n",
    "    }\n",
    "\n",
    "    # Only store LightGBM model config\n",
    "    model_config = {\n",
    "        'lgbm': {'model': lgb.LGBMRegressor(**lgb_params), 'preds': np.zeros(len(y))}\n",
    "    }\n",
    "    oof_scores = {'lgbm': []}\n",
    "\n",
    "    # Wrap the KFold loop with tqdm for a master progress bar\n",
    "    for fold, (train_idx, val_idx) in enumerate(tqdm(kf.split(X, y), total=CONFIG['n_folds'], desc=\"Overall CV Progress\")):\n",
    "        print(f\"\\n--- Fold {fold+1}/{CONFIG['n_folds']} ---\")\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Train LightGBM\n",
    "        print(f\"  - Training LightGBM...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # Train LightGBM model\n",
    "            model_config['lgbm']['model'] = lgb.LGBMRegressor(**lgb_params)\n",
    "            model_config['lgbm']['model'].fit(\n",
    "                X_train, y_train, \n",
    "                eval_set=[(X_val, y_val)], \n",
    "                callbacks=[\n",
    "                    lgb.early_stopping(200, verbose=False), \n",
    "                    lgb.log_evaluation(period=500)\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        except Exception as e:\n",
    "            if \"CUDA Tree Learner was not enabled\" in str(e):\n",
    "                print(\"    âš ï¸ LightGBM GPU failed. Falling back to CPU (this will be slow)...\")\n",
    "                cpu_params = lgb_params.copy()\n",
    "                if 'device' in cpu_params:\n",
    "                    del cpu_params['device']\n",
    "                model_config['lgbm']['model'] = lgb.LGBMRegressor(**cpu_params)\n",
    "                model_config['lgbm']['model'].fit(\n",
    "                    X_train, y_train, \n",
    "                    eval_set=[(X_val, y_val)], \n",
    "                    callbacks=[\n",
    "                        lgb.early_stopping(200, verbose=False), \n",
    "                        lgb.log_evaluation(period=500)\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                print(f\"    âš ï¸ An error occurred training LightGBM: {e}. Skipping fold.\")\n",
    "                oof_scores['lgbm'].append(np.inf)  # Add a high score to indicate failure\n",
    "                # Clear memory and continue to next fold\n",
    "                del X_train, X_val, y_train, y_val\n",
    "                clear_memory()\n",
    "                continue\n",
    "\n",
    "        # Make predictions and store results\n",
    "        val_preds = model_config['lgbm']['model'].predict(X_val)\n",
    "        model_config['lgbm']['preds'][val_idx] = val_preds\n",
    "        fold_smape = smape(y_val, val_preds)\n",
    "        oof_scores['lgbm'].append(fold_smape)\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"    âœ“ Done in {elapsed:.1f}s. Fold SMAPE: {fold_smape:.4f}%\")\n",
    "        \n",
    "        # Clear memory after each fold\n",
    "        del X_train, X_val, y_train, y_val, val_preds\n",
    "        del model_config['lgbm']['model']  # Delete the trained model to free memory\n",
    "        clear_memory()\n",
    "\n",
    "    # --- Final Evaluation ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ“Š Overall Cross-Validation Results (OOF)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    scores = oof_scores['lgbm']\n",
    "    if scores:\n",
    "        print(f\"LightGBM | Mean SMAPE: {np.mean(scores):.4f}% (Std: {np.std(scores):.4f})\")\n",
    "    \n",
    "    # Calculate final OOF predictions using stored predictions\n",
    "    ensemble_smape = smape(y, model_config['lgbm']['preds'])\n",
    "    print(f\"\\n{'LIGHTGBM':<8} | Final OOF SMAPE: {ensemble_smape:.4f}%\")\n",
    "    \n",
    "    # --- Retrain Final Model ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Retraining final LightGBM model on 100% of data for submission...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        final_model = lgb.LGBMRegressor(**lgb_params)\n",
    "        final_model.fit(X, y)\n",
    "    except Exception as e:\n",
    "        if \"CUDA Tree Learner was not enabled\" in str(e):\n",
    "            print(\"    âš ï¸ GPU failed for final model. Retraining on CPU.\")\n",
    "            cpu_params = lgb_params.copy()\n",
    "            if 'device' in cpu_params:\n",
    "                del cpu_params['device']\n",
    "            final_model = lgb.LGBMRegressor(**cpu_params)\n",
    "            final_model.fit(X, y)\n",
    "        else: \n",
    "            raise e\n",
    "             \n",
    "    joblib.dump(final_model, 'final_lightgbm_model_for_submission.joblib')\n",
    "    print(\"\\nâœ… Final retrained model saved as 'final_lightgbm_model_for_submission.joblib'\")\n",
    "\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    # This assumes your full feature matrix has been saved by a master preprocessing script\n",
    "    def load_precomputed_data(data_dir):\n",
    "        try:\n",
    "            print(\"--- Loading final precomputed feature matrix for training ---\")\n",
    "            X = load_npz(os.path.join(data_dir, 'X_final_train.npz'))\n",
    "            y_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "            print(f\"   âœ“ Features loaded. Shape: {X.shape}\")\n",
    "            print(f\"   âœ“ Labels loaded. Count: {len(y_df)}\")\n",
    "            return X, y_df['price_log'].values\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"FATAL ERROR: Could not load precomputed files. {e}\")\n",
    "            print(\"Please run the final, combined preprocessing script first to generate 'X_final_train.npz' and 'y_train.csv'.\")\n",
    "            return None, None\n",
    "\n",
    "    X_final_train, y_final_train = load_precomputed_data(CONFIG['data_dir'])\n",
    "    \n",
    "    if X_final_train is not None:\n",
    "        train_lgbm_only(X_final_train, y_final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf65500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from optuna) (2.0.34)\n",
      "Requirement already satisfied: tqdm in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
      "Requirement already satisfied: tomli in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from alembic>=1.5.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\akshit\\anaconda3\\envs\\tf\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.16.5 colorlog-6.9.0 optuna-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3facab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def clean_image_url(url):\n",
    "    \"\"\"\n",
    "    Normalize and fix image URLs for Amazon data.\n",
    "    \"\"\"\n",
    "    url = str(url).strip()\n",
    "    url = url.replace(']', '').replace('(', '').replace(')', '').replace('[', '')\n",
    "    # Remove any surrounding bad characters\n",
    "    url = url.strip(' ;,\\'\"')\n",
    "    # Fix schemes and leading http(s)\n",
    "    if url.startswith('https://'):\n",
    "        return url\n",
    "    if url.startswith('http://'):\n",
    "        return 'https://' + url[7:]\n",
    "    # Some Amazon links might miss scheme\n",
    "    if url.startswith('m.media-amazon') or url.startswith('images-amazon'):\n",
    "        return 'https://' + url\n",
    "    # Catch malformed or custom patterns\n",
    "    if 'media-amazon' in url and not url.startswith('http'):\n",
    "        return 'https://' + url\n",
    "    # Final check: if still doesn't look valid, return None\n",
    "    if 'media-amazon' not in url:\n",
    "        return None\n",
    "    return url\n",
    "\n",
    "def clean_catalog_content(text):\n",
    "    \"\"\"\n",
    "    Remove HTML tags, unicode artifacts, and special characters.\n",
    "    Prefer only meaningful text for modeling.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Remove HTML-like tags\n",
    "    text = re.sub(r'<.*?>', ' ', str(text))\n",
    "    # Remove non-standard unicode and extra whitespace\n",
    "    text = re.sub(r'[\\n\\r\\t]', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,:-]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_numeric_text_features(text):\n",
    "    \"\"\"\n",
    "    Extracts key numeric or structured features from the catalog text.\n",
    "    Extend these patterns as you find more types in your dataset!\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    text_l = str(text).lower()\n",
    "    # Item Pack Quantity\n",
    "    ipq = 1\n",
    "    m_ipq = re.search(r'(item pack quantity|count|pack of|pk of|ct)\\s*[:\\-]?\\s*(\\d+)', text_l)\n",
    "    if m_ipq:\n",
    "        try:\n",
    "            ipq = int(m_ipq.group(2))\n",
    "        except:\n",
    "            ipq = 1\n",
    "    features['item_pack_quantity'] = ipq\n",
    "\n",
    "    # Extract value and unit (e.g. \"value 16.0 unit ounce\")\n",
    "    m_valunit = re.search(r'value\\s*([\\d.]+)\\s*unit\\s*([a-zA-Z]+)', text_l)\n",
    "    if m_valunit:\n",
    "        value, unit = float(m_valunit.group(1)), m_valunit.group(2)\n",
    "    else:\n",
    "        value, unit = 0.0, \"\"\n",
    "    features['value'] = value\n",
    "    features['value_unit'] = unit\n",
    "\n",
    "    # Weight-related extraction (oz, lb, g, kg)\n",
    "    weight_patterns = [\n",
    "        (r'([\\d.]+)\\s?oz', 'oz'),\n",
    "        (r'([\\d.]+)\\s?ounce', 'oz'),\n",
    "        (r'([\\d.]+)\\s?lb', 'lb'),\n",
    "        (r'([\\d.]+)\\s?pound', 'lb'),\n",
    "        (r'([\\d.]+)\\s?kg', 'kg'),\n",
    "        (r'([\\d.]+)\\s?g\\b', 'g')\n",
    "    ]\n",
    "    weight_val = 0.0\n",
    "    for pat, u in weight_patterns:\n",
    "        m_weight = re.search(pat, text_l)\n",
    "        if m_weight:\n",
    "            weight_val = float(m_weight.group(1))\n",
    "            features[f'weight_{u}'] = weight_val\n",
    "\n",
    "    # Volume-related extraction (ml, l, fl oz)\n",
    "    volume_patterns = [\n",
    "        (r'([\\d.]+)\\s?ml', 'ml'),\n",
    "        (r'([\\d.]+)\\s?l\\b', 'l'),\n",
    "        (r'([\\d.]+)\\s?fl oz', 'floz'),\n",
    "        (r'([\\d.]+)\\s?gallon', 'gallon')\n",
    "    ]\n",
    "    for pat, u in volume_patterns:\n",
    "        m_vol = re.search(pat, text_l)\n",
    "        if m_vol:\n",
    "            features[f'volume_{u}'] = float(m_vol.group(1))\n",
    "\n",
    "    # Textual stats\n",
    "    features['char_length'] = len(text)\n",
    "    features['word_count'] = len(text.split())\n",
    "    features['has_organic'] = int('organic' in text_l)\n",
    "    features['has_gourmet'] = int('gourmet' in text_l)\n",
    "    features['has_natural'] = int('natural' in text_l)\n",
    "    features['has_premium'] = int('premium' in text_l)\n",
    "    features['has_luxury'] = int('luxury' in text_l)\n",
    "    features['has_vegan'] = int('vegan' in text_l)\n",
    "    features['has_glutenfree'] = int('gluten free' in text_l or 'gluten-free' in text_l)\n",
    "\n",
    "    return features\n",
    "\n",
    "def preprocess_main(file_path, save_path=None):\n",
    "    \"\"\"\n",
    "    Full robust preprocessing: load, clean, extract features, and save.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.rename(columns=lambda x: x.strip().lower().replace(' ', '_'))\n",
    "\n",
    "    df['catalog_content'] = df['catalog_content'].fillna('')\n",
    "    df['catalog_content_clean'] = df['catalog_content'].apply(clean_catalog_content)\n",
    "    df['image_link_clean'] = df['image_link'].apply(clean_image_url)\n",
    "\n",
    "    # Numeric/structured text features:\n",
    "    struct_feats_list = df['catalog_content'].apply(extract_numeric_text_features)\n",
    "    struct_feats_df = pd.DataFrame(struct_feats_list.tolist())\n",
    "    out_df = pd.concat([df, struct_feats_df], axis=1)\n",
    "\n",
    "    # Remove samples without valid image url\n",
    "    out_df = out_df[out_df['imagelink_clean'].str.startswith('https://', na=False)]\n",
    "\n",
    "    # Remove duplicate sampleid if any\n",
    "    out_df = out_df.drop_duplicates(subset=['sampleid'])\n",
    "\n",
    "    print(\"Preprocessing complete. Head of dataframe:\")\n",
    "    print(out_df.head())\n",
    "\n",
    "    if save_path:\n",
    "        out_df.to_csv(save_path, index=False)\n",
    "        print(f\"Cleaned/preprocessed data saved to {save_path}\")\n",
    "\n",
    "    return out_df\n",
    "\n",
    "# Usage sample (Update the path as needed)\n",
    "# if __name__ == '__main__':\n",
    "#     clean_df = preprocess_main('paste.txt', save_path='cleaned_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATASET_FOLDER = '68e8d1d70b66d_student_resource\\student_resource\\dataset'\n",
    "\n",
    "# from my_preprocessing_script import preprocess_main  # Put the above script in `my_preprocessing_script.py`\n",
    "\n",
    "train_path = os.path.join(DATASET_FOLDER, 'train.csv')\n",
    "test_path = os.path.join(DATASET_FOLDER, 'test.csv')\n",
    "sample_test_path = os.path.join(DATASET_FOLDER, 'sample_test.csv')\n",
    "sample_test_out_path = os.path.join(DATASET_FOLDER, 'sample_test_out.csv')\n",
    "\n",
    "# Run and save outputs for each split\n",
    "train_clean = preprocess_main(train_path, save_path=os.path.join(DATASET_FOLDER, 'train_clean.csv'))\n",
    "test_clean = preprocess_main(test_path, save_path=os.path.join(DATASET_FOLDER, 'test_clean.csv'))\n",
    "sample_test_clean = preprocess_main(sample_test_path, save_path=os.path.join(DATASET_FOLDER, 'sample_test_clean.csv'))\n",
    "sample_test_out_clean = preprocess_main(sample_test_out_path, save_path=os.path.join(DATASET_FOLDER, 'sample_test_out_clean.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a75d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Amazon ML Challenge 2025 - Smart Product Pricing\n",
    "Data Preprocessing Pipeline\n",
    "\n",
    "This module implements a robust, error-handled preprocessing pipeline for the\n",
    "catalog_content field, designed to handle the inconsistent and semi-structured\n",
    "format found in the dataset while strictly adhering to competition constraints.\n",
    "\n",
    "Key features:\n",
    "- Comprehensive error handling with fallback mechanisms\n",
    "- Unit standardization across multiple measurement systems\n",
    "- Brand recognition with contextual analysis\n",
    "- Premium attribute detection with semantic understanding\n",
    "- Strict validation to prevent data leakage\n",
    "- Detailed logging for debugging and audit purposes\n",
    "- No external price lookup (compliance with competition rules)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import warnings\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any, Callable\n",
    "from collections import defaultdict\n",
    "from functools import wraps\n",
    "from contextlib import contextmanager\n",
    "import traceback\n",
    "import json\n",
    "from enum import Enum\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import string\n",
    "\n",
    "# ======================\n",
    "# CONFIGURATION & SETUP\n",
    "# ======================\n",
    "\n",
    "# Configure logging with detailed formatting\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(\"amazon_ml_preprocessor\")\n",
    "\n",
    "# Suppress benign warnings but keep critical ones\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pandas\")\n",
    "\n",
    "# Competition constraints validation\n",
    "MAX_MODEL_PARAMS = 8_000_000_000  # 8 billion parameters\n",
    "ALLOWED_LICENSES = [\"MIT\", \"Apache 2.0\"]\n",
    "EXTERNAL_PRICE_LOOKUP_PROHIBITED = True\n",
    "\n",
    "# Unit conversion constants\n",
    "UNIT_CONVERSIONS = {\n",
    "    # Weight units to grams\n",
    "    'oz': 28.3495, 'ounce': 28.3495, 'ounces': 28.3495,\n",
    "    'lb': 453.592, 'pound': 453.592, 'pounds': 453.592,\n",
    "    'kg': 1000.0, 'kilogram': 1000.0, 'kilograms': 1000.0,\n",
    "    'g': 1.0, 'gram': 1.0, 'grams': 1.0,\n",
    "    \n",
    "    # Volume units to milliliters\n",
    "    'fl_oz': 29.5735, 'fluid_ounce': 29.5735, 'fluid_ounces': 29.5735,\n",
    "    'ml': 1.0, 'milliliter': 1.0, 'milliliters': 1.0,\n",
    "    'l': 1000.0, 'liter': 1000.0, 'liters': 1000.0,\n",
    "    'cup': 236.588, 'cups': 236.588,\n",
    "    'pt': 473.176, 'pint': 473.176, 'pints': 473.176,\n",
    "    \n",
    "    # Count units (no conversion needed)\n",
    "    'count': 1.0, 'ct': 1.0, 'item': 1.0, 'items': 1.0, 'piece': 1.0, 'pieces': 1.0\n",
    "}\n",
    "\n",
    "# Standardized unit categories\n",
    "UNIT_CATEGORIES = {\n",
    "    'weight': ['g', 'oz', 'lb', 'kg'],\n",
    "    'volume': ['ml', 'fl_oz', 'l', 'cup', 'pt'],\n",
    "    'count': ['count', 'item']\n",
    "}\n",
    "\n",
    "# Common brand list with priority scores (higher = more premium)\n",
    "BRAND_PREMIUM_SCORES = {\n",
    "    'Campbell\\'s': 0.8, 'Kellogg\\'s': 0.7, 'Coca-Cola': 0.6, 'McCormick': 0.75,\n",
    "    'L\\'OrÃ©al': 1.2, 'Starbucks': 1.1, 'Hampton Farms': 0.9, 'Schweppes': 0.7,\n",
    "    'Del Monte': 0.65, 'Frosted Flakes': 0.6, 'Near East': 0.55, 'Taffy Town': 0.6,\n",
    "    'YumEarth': 0.7, 'PAM': 0.5, 'LÃ„RABAR': 0.85, 'Fisher Nuts': 0.75,\n",
    "    'Michaels Of Bro': 0.8, 'SWEDISH FISH': 0.6, 'Near East': 0.55, 'Jack Link\\'s': 0.7,\n",
    "    'Foods Alive': 0.65, 'R.W. Knudsen': 0.6, 'NPG': 0.5, 'Happy Birthday Cookies': 0.9\n",
    "}\n",
    "\n",
    "# Premium attribute keywords with impact scores\n",
    "PREMIUM_KEYWORDS = {\n",
    "    # Premium quality indicators\n",
    "    'organic': 0.8, 'premium': 1.0, 'gourmet': 1.2, 'artisan': 1.1, \n",
    "    'handcrafted': 1.0, 'luxury': 1.3, 'signature': 0.9, 'special reserve': 1.1,\n",
    "    'premium quality': 1.0, 'craft': 0.7, 'small batch': 0.9, 'limited edition': 1.0,\n",
    "    \n",
    "    # Health attributes\n",
    "    'gluten free': 0.6, 'non-gmo': 0.5, 'vegan': 0.7, 'keto': 0.6, \n",
    "    'dairy free': 0.5, 'sugar free': 0.4, 'kosher': 0.3, 'halal': 0.3,\n",
    "    'non dairy': 0.4, 'plant based': 0.6, 'all natural': 0.5, 'natural': 0.3,\n",
    "    \n",
    "    # Convenience features\n",
    "    'convenient': 0.3, 'easy to prepare': 0.4, 'ready in minutes': 0.5,\n",
    "    'microwave ready': 0.6, 'no refrigeration': 0.4, 'lunchbox ready': 0.5,\n",
    "    \n",
    "    # Sustainability\n",
    "    'sustainable': 0.5, 'eco friendly': 0.6, 'biodegradable': 0.4, 'recyclable': 0.3\n",
    "}\n",
    "\n",
    "# Product categories with typical price ranges (for imputation)\n",
    "PRODUCT_CATEGORIES = {\n",
    "    'beverages': {'median_price': 3.5, 'std_dev': 2.0, 'unit': 'fl_oz', 'std_unit': 'ml'},\n",
    "    'snacks': {'median_price': 2.0, 'std_dev': 1.5, 'unit': 'oz', 'std_unit': 'g'},\n",
    "    'cereal': {'median_price': 4.0, 'std_dev': 2.5, 'unit': 'oz', 'std_unit': 'g'},\n",
    "    'condiments': {'median_price': 3.0, 'std_dev': 1.8, 'unit': 'oz', 'std_unit': 'g'},\n",
    "    'baked_goods': {'median_price': 5.0, 'std_dev': 3.0, 'unit': 'count', 'std_unit': 'item'},\n",
    "    'personal_care': {'median_price': 8.0, 'std_dev': 4.0, 'unit': 'oz', 'std_unit': 'ml'},\n",
    "    'kitchenware': {'median_price': 15.0, 'std_dev': 10.0, 'unit': 'count', 'std_unit': 'item'},\n",
    "    'other': {'median_price': 4.5, 'std_dev': 3.0, 'unit': 'count', 'std_unit': 'item'}\n",
    "}\n",
    "\n",
    "# ======================\n",
    "# DECORATORS & UTILITIES\n",
    "# ======================\n",
    "\n",
    "def time_execution(func: Callable) -> Callable:\n",
    "    \"\"\"Decorator to measure and log function execution time.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        logger.debug(f\"{func.__name__} executed in {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def validate_input_data(func: Callable) -> Callable:\n",
    "    \"\"\"Decorator to validate input data structure before processing.\"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(df: pd.DataFrame, *args, **kwargs) -> Any:\n",
    "        required_columns = ['sample_id', 'catalog_content']\n",
    "        if not all(col in df.columns for col in required_columns):\n",
    "            missing = [col for col in required_columns if col not in df.columns]\n",
    "            raise ValueError(f\"Missing required columns: {missing}. Required: {required_columns}\")\n",
    "        \n",
    "        # Check for empty dataframe\n",
    "        if df.empty:\n",
    "            raise ValueError(\"Input dataframe is empty\")\n",
    "            \n",
    "        # Check for duplicate sample_ids\n",
    "        if df['sample_id'].duplicated().any():\n",
    "            logger.warning(\"Duplicate sample_id values detected. Keeping first occurrence.\")\n",
    "            df = df.drop_duplicates(subset=['sample_id'], keep='first')\n",
    "            \n",
    "        return func(df, *args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "def robust_retry(max_attempts: int = 3, delay: float = 0.5) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator for retrying operations that might fail due to transient issues.\n",
    "    \n",
    "    Args:\n",
    "        max_attempts: Maximum number of retry attempts\n",
    "        delay: Delay between attempts in seconds\n",
    "    \"\"\"\n",
    "    def decorator(func: Callable) -> Callable:\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            last_exception = None\n",
    "            for attempt in range(max_attempts):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    last_exception = e\n",
    "                    logger.warning(f\"Attempt {attempt+1}/{max_attempts} failed for {func.__name__}: {str(e)}\")\n",
    "                    if attempt < max_attempts - 1:\n",
    "                        time.sleep(delay)\n",
    "            \n",
    "            # If we get here, all attempts failed\n",
    "            logger.error(f\"All {max_attempts} attempts failed for {func.__name__}\")\n",
    "            raise RuntimeError(f\"Operation failed after {max_attempts} attempts\") from last_exception\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@contextmanager\n",
    "def temporary_silence(category: Warning = UserWarning):\n",
    "    \"\"\"Context manager to temporarily silence specific warnings.\"\"\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category)\n",
    "        yield\n",
    "\n",
    "def sanitize_string(text: str) -> str:\n",
    "    \"\"\"Clean and standardize string inputs.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Normalize unicode characters\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    \n",
    "    # Replace various dash types with standard hyphen\n",
    "    text = re.sub(r'[\\u2013\\u2014\\u2212]', '-', text)\n",
    "    \n",
    "    # Standardize quotes\n",
    "    text = re.sub(r'[\\u2018\\u2019\\u201A\\u201B\\u2032]', \"'\", text)\n",
    "    text = re.sub(r'[\\u201C\\u201D\\u201E\\u201F\\u2033]', '\"', text)\n",
    "    \n",
    "    # Remove control characters\n",
    "    text = ''.join(c for c in text if c.isprintable() or c.isspace())\n",
    "    \n",
    "    # Standardize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ======================\n",
    "# CORE PREPROCESSING\n",
    "# ======================\n",
    "\n",
    "class DataValidationError(Exception):\n",
    "    \"\"\"Custom exception for data validation failures.\"\"\"\n",
    "    pass\n",
    "\n",
    "class UnitConversionError(Exception):\n",
    "    \"\"\"Custom exception for unit conversion issues.\"\"\"\n",
    "    pass\n",
    "\n",
    "class PreprocessingStep(Enum):\n",
    "    \"\"\"Enumeration of preprocessing steps for tracking and debugging.\"\"\"\n",
    "    PARSING = \"parsing\"\n",
    "    UNIT_STANDARDIZATION = \"unit_standardization\"\n",
    "    BRAND_EXTRACTION = \"brand_extraction\"\n",
    "    PREMIUM_ATTRIBUTES = \"premium_attributes\"\n",
    "    CATEGORY_ASSIGNMENT = \"category_assignment\"\n",
    "    MISSING_VALUE_HANDLING = \"missing_value_handling\"\n",
    "    FEATURE_ENGINEERING = \"feature_engineering\"\n",
    "\n",
    "class PreprocessingContext:\n",
    "    \"\"\"Context object to track preprocessing state and metadata.\"\"\"\n",
    "    \n",
    "    def __init__(self, is_training: bool = True):\n",
    "        self.is_training = is_training\n",
    "        self.steps_completed: List[PreprocessingStep] = []\n",
    "        self.warnings: List[Dict[str, Any]] = []\n",
    "        self.errors: List[Dict[str, Any]] = []\n",
    "        self.stats: Dict[str, Any] = {\n",
    "            'total_records': 0,\n",
    "            'missing_value_count': 0,\n",
    "            'unit_conversion_failures': 0,\n",
    "            'brand_detection_count': defaultdict(int),\n",
    "            'category_distribution': defaultdict(int)\n",
    "        }\n",
    "        self.start_time = time.time()\n",
    "        self.validation_failures = 0\n",
    "        self.category_data = {}  # Will store category statistics\n",
    "    \n",
    "    def add_warning(self, step: PreprocessingStep, message: str, sample_id: Optional[int] = None):\n",
    "        \"\"\"Add a warning to the context.\"\"\"\n",
    "        self.warnings.append({\n",
    "            'step': step.value,\n",
    "            'message': message,\n",
    "            'sample_id': sample_id,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "        logger.warning(f\"[{step.value}] {message}\" + (f\" (sample_id={sample_id})\" if sample_id else \"\"))\n",
    "    \n",
    "    def add_error(self, step: PreprocessingStep, error: Exception, sample_id: Optional[int] = None):\n",
    "        \"\"\"Add an error to the context.\"\"\"\n",
    "        self.errors.append({\n",
    "            'step': step.value,\n",
    "            'error_type': type(error).__name__,\n",
    "            'message': str(error),\n",
    "            'traceback': traceback.format_exc(),\n",
    "            'sample_id': sample_id,\n",
    "            'timestamp': time.time()\n",
    "        })\n",
    "        logger.error(f\"[{step.value}] {type(error).__name__}: {str(error)}\" + \n",
    "                    (f\" (sample_id={sample_id})\" if sample_id else \"\"))\n",
    "    \n",
    "    def record_stat(self, stat_key: str, value: Any = 1):\n",
    "        \"\"\"Record a statistic or increment a counter.\"\"\"\n",
    "        if isinstance(self.stats[stat_key], dict) and not isinstance(value, dict):\n",
    "            self.stats[stat_key][value] += 1\n",
    "        elif stat_key in self.stats:\n",
    "            if isinstance(self.stats[stat_key], (int, float)):\n",
    "                self.stats[stat_key] += value\n",
    "            else:\n",
    "                self.stats[stat_key] = value\n",
    "        else:\n",
    "            self.stats[stat_key] = value\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get a summary of the preprocessing context.\"\"\"\n",
    "        return {\n",
    "            'total_time': time.time() - self.start_time,\n",
    "            'steps_completed': [step.value for step in self.steps_completed],\n",
    "            'warning_count': len(self.warnings),\n",
    "            'error_count': len(self.errors),\n",
    "            'stats': dict(self.stats)\n",
    "        }\n",
    "\n",
    "def create_preprocessing_context(df: pd.DataFrame, is_training: bool = True) -> PreprocessingContext:\n",
    "    \"\"\"Create and initialize a preprocessing context.\"\"\"\n",
    "    context = PreprocessingContext(is_training)\n",
    "    context.stats['total_records'] = len(df)\n",
    "    return context\n",
    "\n",
    "def validate_competition_constraints() -> None:\n",
    "    \"\"\"\n",
    "    Validate that our approach complies with competition constraints.\n",
    "    This is critical to avoid disqualification.\n",
    "    \"\"\"\n",
    "    # Check for prohibited external price lookup\n",
    "    if EXTERNAL_PRICE_LOOKUP_PROHIBITED:\n",
    "        logger.info(\"Confirmed: No external price lookup is being performed (compliance check)\")\n",
    "    \n",
    "    # This would be checked during model submission, but good to be aware\n",
    "    logger.info(f\"Model parameter limit: {MAX_MODEL_PARAMS/1e9} billion (must be <= 8B)\")\n",
    "    logger.info(f\"Allowed licenses: {', '.join(ALLOWED_LICENSES)}\")\n",
    "\n",
    "# ======================\n",
    "# PARSING FUNCTIONS\n",
    "# ======================\n",
    "\n",
    "@time_execution\n",
    "def parse_catalog_content(text: str, context: PreprocessingContext, \n",
    "                          sample_id: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse the semi-structured catalog_content field into structured components.\n",
    "    \n",
    "    Handles various inconsistent formatting patterns found in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        text: Raw catalog_content string\n",
    "        context: Preprocessing context for tracking issues\n",
    "        sample_id: Optional sample ID for error tracking\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with parsed components\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        context.add_warning(PreprocessingStep.PARSING, \"Empty or invalid catalog_content\", sample_id)\n",
    "        return {\n",
    "            'item_name': '',\n",
    "            'bullet_points': [],\n",
    "            'product_description': '',\n",
    "            'value': None,\n",
    "            'unit': None,\n",
    "            'raw_text': text\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        # Sanitize input text\n",
    "        text = sanitize_string(text)\n",
    "        \n",
    "        # Initialize result structure\n",
    "        result = {\n",
    "            'item_name': '',\n",
    "            'bullet_points': [],\n",
    "            'product_description': '',\n",
    "            'value': None,\n",
    "            'unit': None,\n",
    "            'raw_text': text\n",
    "        }\n",
    "        \n",
    "        # Extract item name (most reliable pattern)\n",
    "        item_name_match = re.search(r'Item Name:\\s*(.*?)(?:Bullet Point|$|Product Description|Value:)', text)\n",
    "        if item_name_match:\n",
    "            result['item_name'] = item_name_match.group(1).strip()\n",
    "            # Remove item name from text to avoid interference with other patterns\n",
    "            text = text.replace(item_name_match.group(0), '', 1)\n",
    "        else:\n",
    "            # Fallback: Try to find anything before the first structured element\n",
    "            first_structured = re.search(r'(Bullet Point|Product Description|Value:)', text)\n",
    "            if first_structured:\n",
    "                result['item_name'] = text[:first_structured.start()].strip()\n",
    "                text = text[first_structured.start():]\n",
    "            else:\n",
    "                # Last resort: take first 50 characters as item name\n",
    "                context.add_warning(PreprocessingStep.PARSING, \n",
    "                                   \"Could not properly identify item name, using fallback\", \n",
    "                                   sample_id)\n",
    "                result['item_name'] = text[:50].strip()\n",
    "        \n",
    "        # Extract bullet points with multiple pattern handling\n",
    "        bullet_points = []\n",
    "        \n",
    "        # Pattern 1: \"Bullet Point X: content\"\n",
    "        bullet_pattern1 = r'Bullet Point\\s*\\d+\\s*:\\s*(.*?)(?=(?:Bullet Point\\s*\\d+\\s*:|Product Description|Value:|$))'\n",
    "        matches1 = re.findall(bullet_pattern1, text, re.DOTALL)\n",
    "        bullet_points.extend([m.strip() for m in matches1 if m.strip()])\n",
    "        \n",
    "        # Pattern 2: \"â€¢ content\" or \"- content\"\n",
    "        bullet_pattern2 = r'(?:â€¢|-|â—|Â·)\\s*(.*?)(?=(?:â€¢|-|â—|Â·|Product Description|Value:|$))'\n",
    "        matches2 = re.findall(bullet_pattern2, text, re.DOTALL)\n",
    "        bullet_points.extend([m.strip() for m in matches2 if m.strip()])\n",
    "        \n",
    "        # Pattern 3: Numbered list \"1. content\", \"2. content\", etc.\n",
    "        bullet_pattern3 = r'\\d+\\.\\s*(.*?)(?=\\d+\\.\\s*|$)'\n",
    "        matches3 = re.findall(bullet_pattern3, text, re.DOTALL)\n",
    "        bullet_points.extend([m.strip() for m in matches3 if m.strip()])\n",
    "        \n",
    "        # Remove duplicates while preserving order\n",
    "        seen = set()\n",
    "        result['bullet_points'] = [x for x in bullet_points \n",
    "                                  if not (x in seen or seen.add(x)) and x]\n",
    "        \n",
    "        # Extract product description\n",
    "        desc_match = re.search(r'Product Description:\\s*(.*?)(?=Value:|$)', text, re.DOTALL)\n",
    "        if desc_match:\n",
    "            result['product_description'] = desc_match.group(1).strip()\n",
    "        \n",
    "        # ===== CORRECTED VALUE/UNIT EXTRACTION SECTION =====\n",
    "        # Enhanced value/unit extraction - NOW PROPERLY INSIDE THE FUNCTION\n",
    "        value_unit_patterns = [\n",
    "            # Standard pattern: \"Value: 1.5 Unit: count\"\n",
    "            r'Value:\\s*([0-9.,]+)\\s*Unit:\\s*([a-zA-Z0-9\\s]+)',\n",
    "            # Compact pattern: \"Value:1.5Unit:count\"\n",
    "            r'Value:\\s*([0-9.,]+)\\s*Unit:\\s*([a-zA-Z0-9\\s]+)',\n",
    "            # Quantity pattern: \"16 oz\", \"10 Count\"\n",
    "            r'(\\d+(?:\\.\\d+)?)\\s*(fl\\s*oz|fl_oz|fluid\\s*ounce|ounce|oz|count|ct|item|ml|g)\\b',\n",
    "            # Product description pattern: \"Product Description: ... 10.5 oz ...\"\n",
    "            r'Product\\s*Description:.*?(\\d+(?:\\.\\d+)?)\\s*(fl\\s*oz|fl_oz|fluid\\s*ounce|ounce|oz|count|ct|item|ml|g)\\b',\n",
    "            # Bullet point pattern: \"Bullet Point: ... 10.5 oz ...\"\n",
    "            r'Bullet\\s*Point.*?(\\d+(?:\\.\\d+)?)\\s*(fl\\s*oz|fl_oz|fluid\\s*ounce|ounce|oz|count|ct|item|ml|g)\\b'\n",
    "        ]\n",
    "\n",
    "        for i, pattern in enumerate(value_unit_patterns):\n",
    "            match = re.search(pattern, text, re.IGNORECASE)\n",
    "            if match:\n",
    "                groups = match.groups()\n",
    "                if len(groups) >= 2:\n",
    "                    value_str, unit_str = groups[0], groups[1]\n",
    "                    # Clean value string\n",
    "                    value_str = re.sub(r'[^\\d.]', '', value_str)\n",
    "                    try:\n",
    "                        result['value'] = float(value_str)\n",
    "                        result['unit'] = unit_str.strip()\n",
    "                        if i > 1:  # Not one of the first two standard patterns\n",
    "                            context.add_warning(PreprocessingStep.PARSING, \n",
    "                                              f\"Used pattern #{i+1} for value/unit extraction\", \n",
    "                                              sample_id)\n",
    "                        break\n",
    "                    except (ValueError, TypeError) as e:\n",
    "                        context.add_warning(PreprocessingStep.PARSING, \n",
    "                                          f\"Error converting value '{value_str}': {str(e)}\", \n",
    "                                          sample_id)\n",
    "                else:\n",
    "                    context.add_warning(PreprocessingStep.PARSING, \n",
    "                                      f\"Pattern matched but didn't capture both groups: {pattern}\", \n",
    "                                      sample_id)\n",
    "        \n",
    "        # Final validation\n",
    "        if result['value'] is not None and (result['value'] <= 0 or np.isinf(result['value'])):\n",
    "            context.add_warning(PreprocessingStep.PARSING, \n",
    "                              f\"Invalid value detected: {result['value']}\", \n",
    "                              sample_id)\n",
    "            result['value'] = None\n",
    "            \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        context.add_error(PreprocessingStep.PARSING, e, sample_id)\n",
    "        # Return minimal safe structure\n",
    "        return {\n",
    "            'item_name': '',\n",
    "            'bullet_points': [],\n",
    "            'product_description': '',\n",
    "            'value': None,\n",
    "            'unit': None,\n",
    "            'raw_text': text\n",
    "        }\n",
    "\n",
    "@time_execution\n",
    "def standardize_units(parsed_data: Dict[str, Any], context: PreprocessingContext, \n",
    "                      sample_id: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Enhanced unit standardization with better fluid/dry distinction\n",
    "    \"\"\"\n",
    "    result = parsed_data.copy()\n",
    "    \n",
    "    try:\n",
    "        # Skip if no value/unit data\n",
    "        if result['value'] is None or result['unit'] is None:\n",
    "            context.record_stat('unit_conversion_failures')\n",
    "            # Try to extract from item name as fallback\n",
    "            if 'item_name' in result:\n",
    "                quantity_match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(fl\\s*oz|fl_oz|fluid\\s*ounce|ounce|oz|count|ct|item|ml|g)', \n",
    "                                         result['item_name'], re.IGNORECASE)\n",
    "                if quantity_match:\n",
    "                    value_str, unit_str = quantity_match.groups()\n",
    "                    try:\n",
    "                        result['value'] = float(value_str)\n",
    "                        result['unit'] = unit_str.lower()\n",
    "                        context.add_warning(PreprocessingStep.UNIT_STANDARDIZATION, \n",
    "                                          f\"Extracted unit from item name: {unit_str}\", \n",
    "                                          sample_id)\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass\n",
    "            \n",
    "            if result['value'] is None or result['unit'] is None:\n",
    "                context.add_warning(PreprocessingStep.UNIT_STANDARDIZATION, \n",
    "                                  \"Missing value or unit for standardization\", \n",
    "                                  sample_id)\n",
    "                result['std_value'] = None\n",
    "                result['std_unit'] = None\n",
    "                result['unit_category'] = None\n",
    "                return result\n",
    "        \n",
    "        # Clean and normalize unit string\n",
    "        unit = str(result['unit']).lower().strip()\n",
    "        \n",
    "        # Handle fluid indicators properly\n",
    "        is_fluid = False\n",
    "        if 'fl' in unit or 'fluid' in unit:\n",
    "            is_fluid = True\n",
    "            # Remove fluid indicator to get base unit\n",
    "            unit = re.sub(r'fl\\s*[-_]?\\s*|fluid\\s+', '', unit).strip()\n",
    "        \n",
    "        # Map to standard unit format\n",
    "        std_value = None\n",
    "        std_unit = None\n",
    "        unit_category = None\n",
    "        \n",
    "        # Handle common unit variants\n",
    "        unit_map = {\n",
    "            'oz': 'oz', 'ounce': 'oz', 'ounces': 'oz',\n",
    "            'fl_oz': 'fl_oz', 'fluid_ounce': 'fl_oz', 'fluid_ounces': 'fl_oz',\n",
    "            'ml': 'ml', 'milliliter': 'ml', 'milliliters': 'ml',\n",
    "            'l': 'l', 'liter': 'l', 'liters': 'l',\n",
    "            'g': 'g', 'gram': 'g', 'grams': 'g',\n",
    "            'kg': 'kg', 'kilogram': 'kg', 'kilograms': 'kg',\n",
    "            'count': 'count', 'ct': 'count', 'item': 'count', 'items': 'count'\n",
    "        }\n",
    "        \n",
    "        # Find matching standard unit\n",
    "        base_unit = None\n",
    "        for key in unit_map:\n",
    "            if re.search(rf'\\b{key}\\b', unit):\n",
    "                base_unit = unit_map[key]\n",
    "                break\n",
    "        \n",
    "        # If no match found, try partial matches\n",
    "        if not base_unit:\n",
    "            for key in unit_map:\n",
    "                if key in unit:\n",
    "                    base_unit = unit_map[key]\n",
    "                    break\n",
    "        \n",
    "        # Process based on base unit\n",
    "        if base_unit:\n",
    "            value = float(result['value'])\n",
    "            \n",
    "            # Fluid measurements\n",
    "            if is_fluid or base_unit in ['fl_oz', 'ml', 'l']:\n",
    "                std_unit = 'ml'\n",
    "                unit_category = 'volume'\n",
    "                if base_unit == 'fl_oz' or base_unit == 'oz':\n",
    "                    std_value = value * 29.5735  # fl oz to ml\n",
    "                elif base_unit == 'ml':\n",
    "                    std_value = value\n",
    "                elif base_unit == 'l':\n",
    "                    std_value = value * 1000.0\n",
    "            \n",
    "            # Weight measurements\n",
    "            elif base_unit in ['oz', 'g', 'kg', 'lb', 'pound']:\n",
    "                std_unit = 'g'\n",
    "                unit_category = 'weight'\n",
    "                if base_unit == 'oz':\n",
    "                    std_value = value * 28.3495  # oz to g\n",
    "                elif base_unit == 'g':\n",
    "                    std_value = value\n",
    "                elif base_unit == 'kg':\n",
    "                    std_value = value * 1000.0\n",
    "                elif base_unit in ['lb', 'pound']:\n",
    "                    std_value = value * 453.592\n",
    "            \n",
    "            # Count measurements\n",
    "            elif base_unit == 'count':\n",
    "                std_unit = 'item'\n",
    "                unit_category = 'count'\n",
    "                std_value = value\n",
    "        \n",
    "        # Store results\n",
    "        result['std_value'] = std_value\n",
    "        result['std_unit'] = std_unit\n",
    "        result['unit_category'] = unit_category\n",
    "        \n",
    "        # Validate result\n",
    "        if std_value is None or std_value <= 0:\n",
    "            context.add_warning(PreprocessingStep.UNIT_STANDARDIZATION, \n",
    "                              f\"Invalid standardized value: {std_value} (unit: {unit})\", \n",
    "                              sample_id)\n",
    "            result['std_value'] = None\n",
    "            result['std_unit'] = None\n",
    "            result['unit_category'] = None\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        context.add_error(PreprocessingStep.UNIT_STANDARDIZATION, e, sample_id)\n",
    "        result['std_value'] = None\n",
    "        result['std_unit'] = None\n",
    "        result['unit_category'] = None\n",
    "        return result\n",
    "\n",
    "@time_execution\n",
    "def extract_brand_info(item_name: str, bullet_points: List[str], \n",
    "                       context: PreprocessingContext, sample_id: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract brand information from product name and bullet points.\n",
    "    \n",
    "    Uses multiple strategies to identify brand with confidence scoring.\n",
    "    \n",
    "    Args:\n",
    "        item_name: Product name string\n",
    "        bullet_points: List of bullet point strings\n",
    "        context: Preprocessing context\n",
    "        sample_id: Optional sample ID for error tracking\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with brand information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        combined_text = item_name + \" \" + \" \".join(bullet_points)\n",
    "        combined_text = sanitize_string(combined_text).lower()\n",
    "        \n",
    "        # Strategy 1: Direct brand matching\n",
    "        best_match = None\n",
    "        highest_score = 0\n",
    "        \n",
    "        for brand, score in BRAND_PREMIUM_SCORES.items():\n",
    "            brand_lower = brand.lower()\n",
    "            # Check for exact match\n",
    "            if brand_lower in combined_text:\n",
    "                # Higher score for matches in item name vs bullet points\n",
    "                position_score = 1.2 if brand_lower in item_name.lower() else 1.0\n",
    "                match_score = score * position_score\n",
    "                \n",
    "                if match_score > highest_score:\n",
    "                    highest_score = match_score\n",
    "                    best_match = brand\n",
    "        \n",
    "        # Strategy 2: Pattern-based detection for common brand formats\n",
    "        if not best_match:\n",
    "            # Look for patterns like \"Brand: X\", \"By X\", etc.\n",
    "            brand_patterns = [\n",
    "                r'brand:\\s*([a-zA-Z0-9\\s]+?)(?:,|\\.|\\s|$)',\n",
    "                r'by\\s+([a-zA-Z0-9\\s]+?)(?:,|\\.|\\s|$)',\n",
    "                r'made by\\s+([a-zA-Z0-9\\s]+?)(?:,|\\.|\\s|$)'\n",
    "            ]\n",
    "            \n",
    "            for pattern in brand_patterns:\n",
    "                match = re.search(pattern, combined_text)\n",
    "                if match:\n",
    "                    potential_brand = match.group(1).strip()\n",
    "                    # Check if this potential brand matches any known brands\n",
    "                    for brand in BRAND_PREMIUM_SCORES:\n",
    "                        if potential_brand in brand.lower():\n",
    "                            best_match = brand\n",
    "                            highest_score = BRAND_PREMIUM_SCORES[brand] * 0.8  # Lower confidence\n",
    "                            break\n",
    "                    if best_match:\n",
    "                        break\n",
    "        \n",
    "        # Strategy 3: First word detection for generic products\n",
    "        if not best_match:\n",
    "            first_word = item_name.split()[0].strip().rstrip(':,.\"\\'')\n",
    "            if len(first_word) > 2 and first_word[0].isupper():\n",
    "                # Likely a brand name (first word capitalized)\n",
    "                best_match = first_word\n",
    "                highest_score = 0.5  # Low confidence\n",
    "        \n",
    "        # Finalize results\n",
    "        if best_match:\n",
    "            context.record_stat('brand_detection_count', best_match)\n",
    "            return {\n",
    "                'brand': best_match,\n",
    "                'brand_score': highest_score,\n",
    "                'is_premium_brand': highest_score > 0.7,\n",
    "                'brand_category': 'premium' if highest_score > 0.7 else 'standard'\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'brand': 'Generic',\n",
    "                'brand_score': 0.0,\n",
    "                'is_premium_brand': False,\n",
    "                'brand_category': 'generic'\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        context.add_error(PreprocessingStep.BRAND_EXTRACTION, e, sample_id)\n",
    "        return {\n",
    "            'brand': 'Unknown',\n",
    "            'brand_score': 0.0,\n",
    "            'is_premium_brand': False,\n",
    "            'brand_category': 'unknown'\n",
    "        }\n",
    "\n",
    "@time_execution\n",
    "def detect_premium_attributes(text: str, context: PreprocessingContext, \n",
    "                              sample_id: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Detect premium attributes in product description.\n",
    "    \n",
    "    Analyzes text for keywords indicating premium quality, health attributes, etc.\n",
    "    \n",
    "    Args:\n",
    "        text: Text to analyze (item name + bullet points + description)\n",
    "        context: Preprocessing context\n",
    "        sample_id: Optional sample ID for error tracking\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with premium attribute information\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = sanitize_string(text).lower()\n",
    "        attributes = {\n",
    "            'premium_keywords': [],\n",
    "            'premium_score': 0.0,\n",
    "            'health_attributes': [],\n",
    "            'health_score': 0.0,\n",
    "            'convenience_features': [],\n",
    "            'convenience_score': 0.0,\n",
    "            'sustainability_features': [],\n",
    "            'sustainability_score': 0.0,\n",
    "            'total_premium_score': 0.0\n",
    "        }\n",
    "        \n",
    "        # Check for each keyword\n",
    "        for keyword, score in PREMIUM_KEYWORDS.items():\n",
    "            if keyword in text:\n",
    "                # Categorize the keyword\n",
    "                if keyword in ['organic', 'premium', 'gourmet', 'artisan', 'handcrafted', \n",
    "                              'luxury', 'signature', 'special reserve', 'premium quality', \n",
    "                              'craft', 'small batch', 'limited edition']:\n",
    "                    attributes['premium_keywords'].append(keyword)\n",
    "                    attributes['premium_score'] += score\n",
    "                elif keyword in ['gluten free', 'non-gmo', 'vegan', 'keto', 'dairy free', \n",
    "                                'sugar free', 'kosher', 'halal', 'non dairy', \n",
    "                                'plant based', 'all natural', 'natural']:\n",
    "                    attributes['health_attributes'].append(keyword)\n",
    "                    attributes['health_score'] += score\n",
    "                elif keyword in ['convenient', 'easy to prepare', 'ready in minutes',\n",
    "                                'microwave ready', 'no refrigeration', 'lunchbox ready']:\n",
    "                    attributes['convenience_features'].append(keyword)\n",
    "                    attributes['convenience_score'] += score\n",
    "                elif keyword in ['sustainable', 'eco friendly', 'biodegradable', 'recyclable']:\n",
    "                    attributes['sustainability_features'].append(keyword)\n",
    "                    attributes['sustainability_score'] += score\n",
    "        \n",
    "        # Calculate total score with diminishing returns\n",
    "        attributes['total_premium_score'] = (\n",
    "            min(attributes['premium_score'], 3.0) * 0.4 +\n",
    "            min(attributes['health_score'], 3.0) * 0.3 +\n",
    "            min(attributes['convenience_score'], 2.0) * 0.2 +\n",
    "            min(attributes['sustainability_score'], 2.0) * 0.1\n",
    "        )\n",
    "        \n",
    "        return attributes\n",
    "    \n",
    "    except Exception as e:\n",
    "        context.add_error(PreprocessingStep.PREMIUM_ATTRIBUTES, e, sample_id)\n",
    "        return {\n",
    "            'premium_keywords': [],\n",
    "            'premium_score': 0.0,\n",
    "            'health_attributes': [],\n",
    "            'health_score': 0.0,\n",
    "            'convenience_features': [],\n",
    "            'convenience_score': 0.0,\n",
    "            'sustainability_features': [],\n",
    "            'sustainability_score': 0.0,\n",
    "            'total_premium_score': 0.0\n",
    "        }\n",
    "\n",
    "@time_execution\n",
    "def assign_product_category(item_name: str, bullet_points: List[str], \n",
    "                            context: PreprocessingContext, sample_id: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    Assign product to a category based on name and description.\n",
    "    \n",
    "    Uses multiple strategies with confidence scoring to determine category.\n",
    "    \n",
    "    Args:\n",
    "        item_name: Product name string\n",
    "        bullet_points: List of bullet point strings\n",
    "        context: Preprocessing context\n",
    "        sample_id: Optional sample ID for error tracking\n",
    "        \n",
    "    Returns:\n",
    "        Product category string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        combined_text = item_name + \" \" + \" \".join(bullet_points)\n",
    "        combined_text = sanitize_string(combined_text).lower()\n",
    "        \n",
    "        # Category keywords with weights\n",
    "        category_keywords = {\n",
    "            'beverages': [\n",
    "                ('beverage', 1.0), ('drink', 1.0), ('soda', 1.2), ('water', 0.8),\n",
    "                ('juice', 1.0), ('coffee', 1.0), ('tea', 1.0), ('sauce', 0.5),\n",
    "                ('soup', 0.5), ('stock', 0.5), ('dashi', 0.7), ('gravy', 0.7)\n",
    "            ],\n",
    "            'snacks': [\n",
    "                ('snack', 1.0), ('candy', 1.2), ('chocolate', 1.0), ('cookie', 1.0),\n",
    "                ('cracker', 0.8), ('chip', 0.7), ('popcorn', 1.0), ('nut', 0.9),\n",
    "                ('trail mix', 1.1), ('energy bar', 1.0), ('granola', 0.8)\n",
    "            ],\n",
    "            'cereal': [\n",
    "                ('cereal', 1.5), ('flakes', 1.2), ('oat', 0.9), ('muesli', 1.0),\n",
    "                ('granola', 0.7), ('breakfast', 0.8), ('porridge', 1.0)\n",
    "            ],\n",
    "            'condiments': [\n",
    "                ('sauce', 1.0), ('gravy', 1.2), ('ketchup', 1.0), ('mustard', 1.0),\n",
    "                ('mayo', 0.8), ('dressing', 1.0), ('seasoning', 1.1), ('spice', 0.9),\n",
    "                ('salt', 0.7), ('pepper', 0.7), ('oil', 0.6)\n",
    "            ],\n",
    "            'baked_goods': [\n",
    "                ('cake', 1.0), ('muffin', 1.2), ('bread', 0.9), ('pastry', 1.0),\n",
    "                ('cookie', 0.8), ('bar', 0.7), ('pie', 0.8), ('dough', 0.7)\n",
    "            ],\n",
    "            'personal_care': [\n",
    "                ('soap', 1.0), ('shampoo', 1.2), ('lotion', 1.0), ('deodorant', 1.1),\n",
    "                ('cosmetic', 1.0), ('makeup', 0.9), ('lip', 0.8), ('skin', 0.7),\n",
    "                ('body wash', 1.2)\n",
    "            ],\n",
    "            'kitchenware': [\n",
    "                ('bowl', 1.0), ('plate', 0.9), ('utensil', 1.0), ('cookware', 1.1),\n",
    "                ('cutlery', 0.8), ('dish', 0.7), ('container', 0.9), ('jar', 0.7)\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Calculate scores for each category\n",
    "        category_scores = {category: 0.0 for category in category_keywords}\n",
    "        \n",
    "        for category, keywords in category_keywords.items():\n",
    "            for keyword, weight in keywords:\n",
    "                if keyword in combined_text:\n",
    "                    # Higher weight if keyword appears in item name\n",
    "                    position_weight = 1.2 if keyword in item_name.lower() else 1.0\n",
    "                    category_scores[category] += weight * position_weight\n",
    "        \n",
    "        # Get the category with highest score\n",
    "        best_category = max(category_scores, key=category_scores.get)\n",
    "        highest_score = category_scores[best_category]\n",
    "        \n",
    "        # If no strong match, use 'other'\n",
    "        if highest_score < 0.5:\n",
    "            best_category = 'other'\n",
    "        \n",
    "        context.record_stat('category_distribution', best_category)\n",
    "        return best_category\n",
    "    \n",
    "    except Exception as e:\n",
    "        context.add_error(PreprocessingStep.CATEGORY_ASSIGNMENT, e, sample_id)\n",
    "        return 'other'\n",
    "\n",
    "# ======================\n",
    "# MISSING VALUE HANDLING\n",
    "# ======================\n",
    "\n",
    "@time_execution\n",
    "def handle_missing_values(row: pd.Series, context: PreprocessingContext, \n",
    "                          training_data: bool = True, prices: Optional[pd.Series] = None) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Handle missing values with category-specific strategies.\n",
    "    \n",
    "    Args:\n",
    "        row: Single row of processed data\n",
    "        context: Preprocessing context\n",
    "        training_data: Whether this is training data (has price labels)\n",
    "        prices: Price series for training data (for imputation)\n",
    "        \n",
    "    Returns:\n",
    "        Row with missing values handled\n",
    "    \"\"\"\n",
    "    result = row.copy()\n",
    "    \n",
    "    try:\n",
    "        # Handle missing value/unit\n",
    "        if pd.isna(result.get('value', None)) or pd.isna(result.get('unit', None)):\n",
    "            context.record_stat('missing_value_count')\n",
    "            \n",
    "            if training_data and prices is not None and 'price' in row:\n",
    "                # For training data with price, we can calculate implied unit price\n",
    "                try:\n",
    "                    # Get category median price per standard unit\n",
    "                    category = result.get('category', 'other')\n",
    "                    category_data = context.category_data.get(category, {})\n",
    "                    \n",
    "                    if category_data and 'median_price_per_unit' in category_data:\n",
    "                        implied_value = row['price'] / category_data['median_price_per_unit']\n",
    "                        result['value'] = implied_value\n",
    "                        result['unit'] = category_data['std_unit']\n",
    "                        result['std_value'] = implied_value\n",
    "                        result['std_unit'] = category_data['std_unit']\n",
    "                        context.add_warning(PreprocessingStep.MISSING_VALUE_HANDLING,\n",
    "                                          \"Imputed value/unit from price and category data\",\n",
    "                                          row.get('sample_id', None))\n",
    "                except (KeyError, TypeError, ZeroDivisionError):\n",
    "                    pass\n",
    "            \n",
    "            # If still missing, use category defaults\n",
    "            if pd.isna(result.get('value', None)) or pd.isna(result.get('unit', None)):\n",
    "                category = result.get('category', 'other')\n",
    "                category_info = PRODUCT_CATEGORIES.get(category, PRODUCT_CATEGORIES['other'])\n",
    "                \n",
    "                # Use median quantity for the category\n",
    "                result['value'] = 1.0  # Default to single unit\n",
    "                result['unit'] = category_info['unit']\n",
    "                result['std_value'] = 1.0\n",
    "                result['std_unit'] = category_info['std_unit']\n",
    "                context.add_warning(PreprocessingStep.MISSING_VALUE_HANDLING,\n",
    "                                  f\"Used category default for missing value/unit (category: {category})\",\n",
    "                                  row.get('sample_id', None))\n",
    "        \n",
    "        # Handle missing brand\n",
    "        if not result.get('brand') or result['brand'] in ['Unknown', 'Generic']:\n",
    "            category = result.get('category', 'other')\n",
    "            \n",
    "            # For certain categories, we can infer brand from context\n",
    "            if category in ['beverages', 'snacks', 'cereal']:\n",
    "                result['brand'] = 'Generic_Food'\n",
    "                result['brand_score'] = 0.2\n",
    "                result['is_premium_brand'] = False\n",
    "                result['brand_category'] = 'generic'\n",
    "            elif category == 'personal_care':\n",
    "                result['brand'] = 'Generic_Care'\n",
    "                result['brand_score'] = 0.2\n",
    "                result['is_premium_brand'] = False\n",
    "                result['brand_category'] = 'generic'\n",
    "            \n",
    "            context.add_warning(PreprocessingStep.MISSING_VALUE_HANDLING,\n",
    "                              f\"Inferred generic brand for category: {category}\",\n",
    "                              row.get('sample_id', None))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        context.add_error(PreprocessingStep.MISSING_VALUE_HANDLING, e, row.get('sample_id', None))\n",
    "        return row  # Return original row on error\n",
    "\n",
    "# ======================\n",
    "# FEATURE ENGINEERING\n",
    "# ======================\n",
    "\n",
    "@time_execution\n",
    "def engineer_features(processed_data: pd.DataFrame, context: PreprocessingContext) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create engineered features from parsed product data.\n",
    "    \n",
    "    Args:\n",
    "        processed_data: DataFrame with parsed product data\n",
    "        context: Preprocessing context\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with engineered features\n",
    "    \"\"\"\n",
    "    result = processed_data.copy()\n",
    "    \n",
    "    try:\n",
    "        # Price per unit features (for training data only)\n",
    "        if 'price' in result.columns:\n",
    "            # Calculate price per standard unit\n",
    "            result['price_per_std_unit'] = np.nan\n",
    "            valid_mask = (result['std_value'] > 0) & ~result['std_value'].isna()\n",
    "            \n",
    "            if valid_mask.any():\n",
    "                result.loc[valid_mask, 'price_per_std_unit'] = (\n",
    "                    result.loc[valid_mask, 'price'] / result.loc[valid_mask, 'std_value']\n",
    "                )\n",
    "                \n",
    "                # Calculate category-specific price per unit statistics\n",
    "                for category in result['category'].unique():\n",
    "                    cat_mask = (result['category'] == category) & valid_mask\n",
    "                    if cat_mask.sum() > 0:\n",
    "                        cat_prices = result.loc[cat_mask, 'price_per_std_unit']\n",
    "                        context.category_data[category] = {\n",
    "                            'median_price_per_unit': cat_prices.median(),\n",
    "                            'mean_price_per_unit': cat_prices.mean(),\n",
    "                            'std_price_per_unit': cat_prices.std(),\n",
    "                            'count': len(cat_prices)\n",
    "                        }\n",
    "        \n",
    "        # Unit-based features\n",
    "        result['is_count_based'] = result['unit_category'] == 'count'\n",
    "        result['is_weight_based'] = result['unit_category'] == 'weight'\n",
    "        result['is_volume_based'] = result['unit_category'] == 'volume'\n",
    "        \n",
    "        # Brand features\n",
    "        result['brand_premium_score'] = result['brand_score']\n",
    "        result['is_premium_brand'] = result['is_premium_brand'].astype(int)\n",
    "        \n",
    "        # Premium attribute features\n",
    "        result['total_premium_score'] = result['total_premium_score']\n",
    "        result['has_health_attributes'] = result['health_attributes'].apply(lambda x: 1 if x else 0)\n",
    "        result['health_attribute_count'] = result['health_attributes'].apply(len)\n",
    "        result['premium_attribute_count'] = result['premium_keywords'].apply(len)\n",
    "        \n",
    "        # Category features\n",
    "        result = pd.get_dummies(result, columns=['category'], prefix='category')\n",
    "        \n",
    "        # Text length features\n",
    "        result['item_name_length'] = result['item_name'].apply(len)\n",
    "        result['total_bullet_points'] = result['bullet_points'].apply(len)\n",
    "        result['total_description_length'] = (\n",
    "            result['item_name'].str.len() + \n",
    "            result['bullet_points'].apply(lambda x: sum(len(p) for x in x)) +\n",
    "            result['product_description'].str.len()\n",
    "        )\n",
    "        \n",
    "        # Package size features\n",
    "        result['is_multi_pack'] = result['value'] > 1.0\n",
    "        result['package_size_log'] = np.log1p(result['value'])\n",
    "        \n",
    "        # Price-related features (for training)\n",
    "        if 'price' in result.columns:\n",
    "            # Log-transformed price (often better for regression)\n",
    "            result['log_price'] = np.log1p(result['price'])\n",
    "            \n",
    "            # Price buckets (for potential ensemble approaches)\n",
    "            result['price_bucket'] = pd.qcut(result['price'], q=10, labels=False, duplicates='drop')\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        context.add_error(PreprocessingStep.FEATURE_ENGINEERING, e)\n",
    "        return processed_data  # Return original on error\n",
    "\n",
    "# ======================\n",
    "# MAIN PREPROCESSING PIPELINE\n",
    "# ======================\n",
    "\n",
    "@validate_input_data\n",
    "@time_execution\n",
    "def preprocess_data(df: pd.DataFrame, is_training: bool = True, \n",
    "                    max_workers: int = 4) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Main preprocessing pipeline for the Amazon ML Challenge dataset.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame with at least 'sample_id' and 'catalog_content' columns\n",
    "        is_training: Whether this is training data (has price labels)\n",
    "        max_workers: Number of threads for parallel processing\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (processed DataFrame, context summary)\n",
    "    \"\"\"\n",
    "    # Validate competition constraints\n",
    "    validate_competition_constraints()\n",
    "    \n",
    "    # Create preprocessing context\n",
    "    context = create_preprocessing_context(df, is_training)\n",
    "    \n",
    "    logger.info(f\"Starting preprocessing for {len(df)} records (training={is_training})\")\n",
    "    \n",
    "    # Initialize results list\n",
    "    processed_rows = []\n",
    "    \n",
    "    # Extract prices for training data (for imputation)\n",
    "    prices = df['price'] if is_training and 'price' in df.columns else None\n",
    "    \n",
    "    # Process rows in parallel\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_idx = {\n",
    "            executor.submit(process_single_row, df.iloc[i], context, is_training, prices): i \n",
    "            for i in range(len(df))\n",
    "        }\n",
    "        \n",
    "        # Process completed tasks\n",
    "        for future in as_completed(future_to_idx):\n",
    "            idx = future_to_idx[future]\n",
    "            try:\n",
    "                processed_row = future.result()\n",
    "                processed_rows.append(processed_row)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing row {idx}: {str(e)}\")\n",
    "                # Add minimal fallback row\n",
    "                fallback_row = df.iloc[idx].copy()\n",
    "                fallback_row['processing_error'] = True\n",
    "                processed_rows.append(fallback_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    processed_df = pd.DataFrame(processed_rows)\n",
    "    \n",
    "    # Engineer additional features\n",
    "    if not processed_df.empty:\n",
    "        processed_df = engineer_features(processed_df, context)\n",
    "    \n",
    "    # Final validation\n",
    "    validate_output(processed_df, context, is_training)\n",
    "    \n",
    "    # Get summary\n",
    "    summary = context.get_summary()\n",
    "    logger.info(f\"Preprocessing completed. Warnings: {summary['warning_count']}, Errors: {summary['error_count']}\")\n",
    "    \n",
    "    return processed_df, summary\n",
    "\n",
    "@robust_retry(max_attempts=2)\n",
    "def process_single_row(row: pd.Series, context: PreprocessingContext, \n",
    "                       is_training: bool, prices: Optional[pd.Series]) -> Dict[str, Any]:\n",
    "    \"\"\"Process a single row of data with comprehensive error handling.\"\"\"\n",
    "    result = row.to_dict()\n",
    "    sample_id = row.get('sample_id', None)\n",
    "    \n",
    "    try:\n",
    "        # 1. Parse catalog_content\n",
    "        context.steps_completed.append(PreprocessingStep.PARSING)\n",
    "        parsed = parse_catalog_content(row['catalog_content'], context, sample_id)\n",
    "        result.update(parsed)\n",
    "        \n",
    "        # 2. Standardize units\n",
    "        context.steps_completed.append(PreprocessingStep.UNIT_STANDARDIZATION)\n",
    "        standardized = standardize_units(parsed, context, sample_id)\n",
    "        result.update(standardized)\n",
    "        \n",
    "        # 3. Extract brand information\n",
    "        context.steps_completed.append(PreprocessingStep.BRAND_EXTRACTION)\n",
    "        brand_info = extract_brand_info(\n",
    "            result['item_name'], \n",
    "            result['bullet_points'], \n",
    "            context, \n",
    "            sample_id\n",
    "        )\n",
    "        result.update(brand_info)\n",
    "        \n",
    "        # 4. Detect premium attributes\n",
    "        context.steps_completed.append(PreprocessingStep.PREMIUM_ATTRIBUTES)\n",
    "        combined_text = (\n",
    "            result['item_name'] + \" \" + \n",
    "            \" \".join(result['bullet_points']) + \" \" + \n",
    "            result['product_description']\n",
    "        )\n",
    "        premium_attrs = detect_premium_attributes(combined_text, context, sample_id)\n",
    "        result.update(premium_attrs)\n",
    "        \n",
    "        # 5. Assign product category\n",
    "        context.steps_completed.append(PreprocessingStep.CATEGORY_ASSIGNMENT)\n",
    "        category = assign_product_category(\n",
    "            result['item_name'], \n",
    "            result['bullet_points'], \n",
    "            context, \n",
    "            sample_id\n",
    "        )\n",
    "        result['category'] = category\n",
    "        \n",
    "        # 6. Handle missing values\n",
    "        if 'price' in row and not pd.isna(row['price']):\n",
    "            context.steps_completed.append(PreprocessingStep.MISSING_VALUE_HANDLING)\n",
    "            result_series = pd.Series(result)\n",
    "            result_series = handle_missing_values(\n",
    "                result_series, \n",
    "                context, \n",
    "                training_data=True,\n",
    "                prices=prices\n",
    "            )\n",
    "            result = result_series.to_dict()\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        context.add_error(PreprocessingStep.PARSING, e, sample_id)\n",
    "        # Return minimal safe structure\n",
    "        return {\n",
    "            'sample_id': sample_id,\n",
    "            'catalog_content': row.get('catalog_content', ''),\n",
    "            'parsing_error': True,\n",
    "            'error_message': str(e)\n",
    "        }\n",
    "\n",
    "def validate_output(df: pd.DataFrame, context: PreprocessingContext, is_training: bool) -> None:\n",
    "    \"\"\"Validate the final processed output meets requirements.\"\"\"\n",
    "    # Check for required columns - these should exist AFTER feature engineering\n",
    "    required_cols = ['sample_id', 'std_value', 'std_unit']\n",
    "    \n",
    "    # Check if we have category-related features (one-hot encoded)\n",
    "    category_features = [col for col in df.columns if col.startswith('category_')]\n",
    "    if not category_features:\n",
    "        context.add_warning(PreprocessingStep.FEATURE_ENGINEERING,\n",
    "                          \"No category one-hot encoded features were created\")\n",
    "    \n",
    "    # Check for other critical engineered features\n",
    "    critical_features = [\n",
    "        'brand_score', 'total_premium_score', 'item_name_length',\n",
    "        'is_weight_based', 'is_volume_based', 'is_count_based'\n",
    "    ]\n",
    "    \n",
    "    missing = [col for col in required_cols if col not in df.columns]\n",
    "    missing += [col for col in critical_features if col in required_cols and col not in df.columns]\n",
    "    \n",
    "    if missing:\n",
    "        raise DataValidationError(f\"Missing required columns in output: {missing}\")\n",
    "    \n",
    "    # Check for NaN in critical fields\n",
    "    critical_fields = ['std_value', 'std_unit']\n",
    "    for field in critical_fields:\n",
    "        if field in df.columns and df[field].isna().any():\n",
    "            nan_count = df[field].isna().sum()\n",
    "            context.add_warning(PreprocessingStep.PARSING, \n",
    "                              f\"{nan_count} NaN values in critical field: {field}\")\n",
    "    \n",
    "    # For training data, verify price is positive\n",
    "    if is_training and 'price' in df.columns:\n",
    "        negative_prices = (df['price'] <= 0).sum()\n",
    "        if negative_prices > 0:\n",
    "            context.validation_failures += negative_prices\n",
    "            raise DataValidationError(f\"Found {negative_prices} non-positive prices in training data\")\n",
    "    \n",
    "    # Verify row count matches input\n",
    "    if len(df) != context.stats['total_records']:\n",
    "        context.validation_failures += 1\n",
    "        raise DataValidationError(\n",
    "            f\"Row count mismatch: expected {context.stats['total_records']}, got {len(df)}\"\n",
    "        )\n",
    "\n",
    "# ======================\n",
    "# UTILITY FUNCTIONS FOR COMPETITION\n",
    "# ======================\n",
    "\n",
    "def save_preprocessed_data(df: pd.DataFrame, output_path: str, is_training: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Save preprocessed data with appropriate columns.\n",
    "    \n",
    "    Args:\n",
    "        df: Processed DataFrame\n",
    "        output_path: Path to save the output CSV\n",
    "        is_training: Whether this is training data (contains price)\n",
    "    \"\"\"\n",
    "    # Always keep sample_id\n",
    "    feature_columns = [\n",
    "        'sample_id', 'std_value', 'std_unit', 'unit_category',\n",
    "        'brand_score', 'is_premium_brand', 'total_premium_score',\n",
    "        'health_attribute_count', 'premium_attribute_count', 'is_count_based',\n",
    "        'is_weight_based', 'is_volume_based', 'item_name_length', \n",
    "        'total_bullet_points', 'is_multi_pack', 'package_size_log'\n",
    "    ]\n",
    "    \n",
    "    # Add price column if it exists (for training data)\n",
    "    if is_training and 'price' in df.columns:\n",
    "        feature_columns.insert(1, 'price')\n",
    "    \n",
    "    # Filter columns, handling missing ones gracefully\n",
    "    save_cols = [col for col in feature_columns if col in df.columns]\n",
    "    result = df[save_cols].copy()\n",
    "    \n",
    "    # Create output directory if needed\n",
    "    os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    result.to_csv(output_path, index=False)\n",
    "    logger.info(f\"Preprocessed data saved to {output_path} with {len(result)} records\")\n",
    "\n",
    "def generate_sample_submission(test_df: pd.DataFrame, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Generate a sample submission file with random but realistic prices.\n",
    "    \n",
    "    Args:\n",
    "        test_df: Test DataFrame with sample_id\n",
    "        output_path: Path to save the submission CSV\n",
    "    \"\"\"\n",
    "    # Create realistic price distribution based on training patterns\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate prices with category-based distributions\n",
    "    prices = []\n",
    "    for _, row in test_df.iterrows():\n",
    "        category = row.get('category', 'other')\n",
    "        cat_info = PRODUCT_CATEGORIES.get(category, PRODUCT_CATEGORIES['other'])\n",
    "        \n",
    "        # Generate price with category-specific parameters\n",
    "        price = max(0.1, np.random.normal(cat_info['median_price'], cat_info['std_dev']))\n",
    "        prices.append(price)\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission = pd.DataFrame({\n",
    "        'sample_id': test_df['sample_id'],\n",
    "        'price': prices\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    logger.info(f\"Sample submission generated with {len(submission)} records at {output_path}\")\n",
    "\n",
    "# ======================\n",
    "# MAIN EXECUTION\n",
    "# ======================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    try:\n",
    "        # Load sample data\n",
    "        train_df = pd.read_csv(\"68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test.csv\")\n",
    "        \n",
    "        # Preprocess training data\n",
    "        processed_train, context_summary = preprocess_data(train_df, is_training=True)\n",
    "        \n",
    "        # Save preprocessed data\n",
    "        save_preprocessed_data(processed_train, \"68e8d1d70b66d_student_resource\\student_resource\\dataset\\processed_train.csv\", is_training=True)\n",
    "        \n",
    "        # Generate sample submission for test data\n",
    "        test_df = pd.read_csv(\"68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test.csv\")\n",
    "        generate_sample_submission(test_df, \"68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test_out.csv\")\n",
    "        \n",
    "        # Save context summary for debugging\n",
    "        with open(\"preprocessing_context.json\", \"w\") as f:\n",
    "            json.dump(context_summary, f, indent=2)\n",
    "            \n",
    "        logger.info(\"Preprocessing pipeline completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.exception(\"Critical error in preprocessing pipeline\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a45882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Data Loading and Merging ---\n",
    "\n",
    "def load_and_merge_data(feature_path='sample_test.csv', output_path='sample_test_out.csv'):\n",
    "    \"\"\"\n",
    "    Loads the feature and output datasets from CSV files and merges them on 'sample_id'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Loading data...\")\n",
    "        df_features = pd.read_csv(feature_path)\n",
    "        df_output = pd.read_csv(output_path)\n",
    "        df = pd.merge(df_features, df_output, on='sample_id', how='left')\n",
    "        print(f\"Data loaded successfully. Merged dataframe shape: {df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data: {e}. Please ensure the files are in the correct directory.\")\n",
    "        return None\n",
    "\n",
    "# --- 2. NEW: Feature Extraction from Text ---\n",
    "\n",
    "def extract_structured_data(text):\n",
    "    \"\"\"\n",
    "    Extracts 'Value' and 'Unit' from the catalog_content string using regular expressions.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The raw text from the 'catalog_content' column.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: A series containing the extracted value and unit.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return pd.Series([np.nan, 'unknown'], index=['Value', 'Unit'])\n",
    "\n",
    "    # Regex to find 'Value:' followed by a number (integer or float)\n",
    "    value_match = re.search(r'Value:\\s*([\\d\\.]+)', text)\n",
    "    value = float(value_match.group(1)) if value_match else np.nan\n",
    "\n",
    "    # Regex to find 'Unit:' followed by a word\n",
    "    unit_match = re.search(r'Unit:\\s*(\\w+)', text)\n",
    "    unit = unit_match.group(1) if unit_match else 'unknown'\n",
    "    \n",
    "    return pd.Series([value, unit], index=['Value', 'Unit'])\n",
    "\n",
    "\n",
    "# --- 3. Text Cleaning and Normalization ---\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies a series of cleaning steps to a raw text string.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove HTML tags and the Value/Unit lines to avoid them being treated as features\n",
    "    text = re.sub(r'Value:.*', '', text)\n",
    "    text = re.sub(r'Unit:.*', '', text)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    \n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# --- 4. Structured Data Cleaning ---\n",
    "\n",
    "def standardize_units(unit):\n",
    "    \"\"\"\n",
    "    Standardizes unit strings to a consistent format.\n",
    "    \"\"\"\n",
    "    if not isinstance(unit, str):\n",
    "        return 'unknown'\n",
    "    \n",
    "    unit = unit.lower().strip()\n",
    "    \n",
    "    unit_map = {\n",
    "        'oz': 'ounce', 'ounces': 'ounce',\n",
    "        'fl oz': 'fl_oz', 'fz': 'fl_oz',\n",
    "        'ct': 'count',\n",
    "        'none': 'unknown'\n",
    "    }\n",
    "    \n",
    "    return unit_map.get(unit, unit)\n",
    "\n",
    "# --- 5. Main Preprocessing and Feature Engineering Pipeline ---\n",
    "\n",
    "def create_feature_pipeline(df):\n",
    "    \"\"\"\n",
    "    Creates and applies a full preprocessing pipeline to the dataframe.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None, None, None\n",
    "        \n",
    "    # --- A. NEW: Extract structured data first! ---\n",
    "    print(\"\\nExtracting 'Value' and 'Unit' from 'catalog_content'...\")\n",
    "    # This creates the 'Value' and 'Unit' columns that were previously missing.\n",
    "    extracted_data = df['catalog_content'].apply(extract_structured_data)\n",
    "    df = pd.concat([df, extracted_data], axis=1)\n",
    "    print(\"Extraction complete. DataFrame now has 'Value' and 'Unit' columns.\")\n",
    "    \n",
    "    # --- B. Prepare Target Variable (y) ---\n",
    "    df.dropna(subset=['price'], inplace=True)\n",
    "    y = np.log1p(df['price'])\n",
    "    features_df = df.drop(columns=['price', 'sample_id', 'image_link'])\n",
    "\n",
    "    # --- C. Clean and Prepare Features ---\n",
    "    print(\"\\nCleaning and preparing features...\")\n",
    "    # Now that Value/Unit are extracted, we can clean the text.\n",
    "    features_df['cleaned_catalog'] = features_df['catalog_content'].apply(clean_text)\n",
    "    features_df['Unit_standardized'] = features_df['Unit'].apply(standardize_units)\n",
    "    # The 'Value' column already exists and is numeric, so no to_numeric is needed here.\n",
    "    print(\"Feature preparation complete.\")\n",
    "    \n",
    "    # --- D. Define Scikit-Learn Preprocessing Steps ---\n",
    "    print(\"\\nDefining scikit-learn preprocessing pipelines...\")\n",
    "    numeric_features = ['Value']\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_features = ['Unit_standardized']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "    ])\n",
    "\n",
    "    text_features_col = 'cleaned_catalog'\n",
    "    text_transformer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "    # --- E. Create and Apply the Master Preprocessor ---\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('text', text_transformer, text_features_col)\n",
    "        ],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    print(\"\\nApplying the full pipeline to the data...\")\n",
    "    X = preprocessor.fit_transform(features_df)\n",
    "    \n",
    "    print(\"\\n--- Preprocessing Complete ---\")\n",
    "    print(f\"Shape of the final feature matrix X: {X.shape}\")\n",
    "    print(f\"Shape of the final target vector y: {y.shape}\")\n",
    "    \n",
    "    return X, y, preprocessor\n",
    "\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    # Step 1: Load and merge the data\n",
    "    df_merged = load_and_merge_data(feature_path='68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test.csv', output_path='68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test_out.csv')\n",
    "    \n",
    "    # Step 2: Run the full preprocessing pipeline (now with the fix)\n",
    "    X_processed, y_processed, preprocessor_fitted = create_feature_pipeline(df_merged)\n",
    "    \n",
    "    if X_processed is not None:\n",
    "        print(\"\\nâœ… Script executed successfully!\")\n",
    "        print(\"Variables `X_processed`, `y_processed`, and `preprocessor_fitted` are now ready.\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Split data for training and validation: `X_train, X_test, y_train, y_test = train_test_split(...)`\")\n",
    "        print(\"2. Train a regression model: `model.fit(X_train, y_train)`\")\n",
    "        print(\"3. Remember to inverse transform predictions: `np.expm1(model.predict(X_test))`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ccc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.sparse import save_npz # To save the sparse matrix\n",
    "import joblib # To save the fitted preprocessor\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Data Loading and Merging ---\n",
    "\n",
    "def load_and_merge_data(feature_path='sample_test.csv', output_path='sample_test_out.csv'):\n",
    "    \"\"\"\n",
    "    Loads the feature and output datasets from CSV files and merges them on 'sample_id'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Loading data...\")\n",
    "        df_features = pd.read_csv(feature_path)\n",
    "        df_output = pd.read_csv(output_path)\n",
    "        df = pd.merge(df_features, df_output, on='sample_id', how='left')\n",
    "        print(f\"Data loaded successfully. Merged dataframe shape: {df.shape}\")\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data: {e}. Please ensure the files are in the correct directory.\")\n",
    "        return None\n",
    "\n",
    "# --- 2. Feature Extraction from Text ---\n",
    "\n",
    "def extract_structured_data(text):\n",
    "    \"\"\"\n",
    "    Extracts 'Value' and 'Unit' from the catalog_content string using regular expressions.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return pd.Series([np.nan, 'unknown'], index=['Value', 'Unit'])\n",
    "\n",
    "    value_match = re.search(r'Value:\\s*([\\d\\.]+)', text)\n",
    "    value = float(value_match.group(1)) if value_match else np.nan\n",
    "\n",
    "    unit_match = re.search(r'Unit:\\s*(\\w+)', text)\n",
    "    unit = unit_match.group(1) if unit_match else 'unknown'\n",
    "    \n",
    "    return pd.Series([value, unit], index=['Value', 'Unit'])\n",
    "\n",
    "# --- 3. Text Cleaning and Normalization ---\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies a series of cleaning steps to a raw text string.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = re.sub(r'Value:.*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'Unit:.*', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'<.*?>', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    \n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# --- 4. Structured Data Cleaning ---\n",
    "\n",
    "def standardize_units(unit):\n",
    "    \"\"\"\n",
    "    Standardizes unit strings to a consistent format.\n",
    "    \"\"\"\n",
    "    if not isinstance(unit, str):\n",
    "        return 'unknown'\n",
    "    \n",
    "    unit = unit.lower().strip()\n",
    "    \n",
    "    unit_map = {\n",
    "        'oz': 'ounce', 'ounces': 'ounce',\n",
    "        'fl oz': 'fl_oz', 'fz': 'fl_oz',\n",
    "        'ct': 'count',\n",
    "        'none': 'unknown'\n",
    "    }\n",
    "    \n",
    "    return unit_map.get(unit, unit)\n",
    "\n",
    "# --- 5. Main Preprocessing and Feature Engineering Pipeline ---\n",
    "\n",
    "def create_feature_pipeline(df):\n",
    "    \"\"\"\n",
    "    Creates and applies a full preprocessing pipeline to the dataframe.\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        return None, None, None\n",
    "        \n",
    "    print(\"\\nExtracting 'Value' and 'Unit' from 'catalog_content'...\")\n",
    "    extracted_data = df['catalog_content'].apply(extract_structured_data)\n",
    "    df = pd.concat([df, extracted_data], axis=1)\n",
    "    print(\"Extraction complete.\")\n",
    "    \n",
    "    df.dropna(subset=['price'], inplace=True)\n",
    "    y = np.log1p(df['price'])\n",
    "    # Store sample_ids to align with y if needed later\n",
    "    sample_ids = df['sample_id']\n",
    "    features_df = df.drop(columns=['price', 'sample_id', 'image_link'])\n",
    "\n",
    "    print(\"\\nCleaning and preparing features...\")\n",
    "    features_df['cleaned_catalog'] = features_df['catalog_content'].apply(clean_text)\n",
    "    features_df['Unit_standardized'] = features_df['Unit'].apply(standardize_units)\n",
    "    print(\"Feature preparation complete.\")\n",
    "    \n",
    "    print(\"\\nDefining scikit-learn preprocessing pipelines...\")\n",
    "    numeric_features = ['Value']\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_features = ['Unit_standardized']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "    ])\n",
    "\n",
    "    text_features_col = 'cleaned_catalog'\n",
    "    text_transformer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features),\n",
    "            ('text', text_transformer, text_features_col)\n",
    "        ],\n",
    "        remainder='drop',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    print(\"\\nApplying the full pipeline to the data...\")\n",
    "    X = preprocessor.fit_transform(features_df)\n",
    "    \n",
    "    print(\"\\n--- Preprocessing Complete ---\")\n",
    "    print(f\"Shape of the final feature matrix X: {X.shape}\")\n",
    "    print(f\"Shape of the final target vector y: {y.shape}\")\n",
    "    \n",
    "    # Return sample_ids along with the other artifacts\n",
    "    return X, y, sample_ids, preprocessor\n",
    "\n",
    "# --- 6. Save Processed Data and Preprocessor ---\n",
    "\n",
    "def save_processed_data(X, y, ids, preprocessor, output_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Saves the processed feature matrix, target vector, and fitted preprocessor.\n",
    "\n",
    "    Args:\n",
    "        X (scipy.sparse.csr_matrix): The sparse feature matrix.\n",
    "        y (pandas.Series): The target vector.\n",
    "        ids (pandas.Series): The sample_ids corresponding to the target vector.\n",
    "        preprocessor (sklearn.compose.ColumnTransformer): The fitted preprocessor object.\n",
    "        output_dir (str): The directory to save the files in.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nSaving processed data to directory: '{output_dir}'\")\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save the sparse feature matrix\n",
    "        save_npz(os.path.join(output_dir, 'X_processed.npz'), X)\n",
    "        \n",
    "        # Save the target vector and its corresponding IDs to a CSV\n",
    "        y_df = pd.DataFrame({'sample_id': ids, 'price_log': y})\n",
    "        y_df.to_csv(os.path.join(output_dir, 'y_processed.csv'), index=False)\n",
    "        \n",
    "        # Save the fitted preprocessor object for later use on the test set\n",
    "        joblib.dump(preprocessor, os.path.join(output_dir, 'preprocessor.joblib'))\n",
    "        \n",
    "        print(\"All files saved successfully:\")\n",
    "        print(f\"- {os.path.join(output_dir, 'X_processed.npz')}\")\n",
    "        print(f\"- {os.path.join(output_dir, 'y_processed.csv')}\")\n",
    "        print(f\"- {os.path.join(output_dir, 'preprocessor.joblib')}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the data: {e}\")\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    # Step 1: Load and merge the data\n",
    "    df_merged = load_and_merge_data(feature_path='68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test.csv', output_path='68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test_out.csv')\n",
    "    \n",
    "    # Step 2: Run the full preprocessing pipeline\n",
    "    X_processed, y_processed, sample_ids_processed, preprocessor_fitted = create_feature_pipeline(df_merged)\n",
    "    \n",
    "    # Step 3: Save the results for later use\n",
    "    if X_processed is not None:\n",
    "        save_processed_data(X_processed, y_processed, sample_ids_processed, preprocessor_fitted)\n",
    "\n",
    "        print(\"\\nâœ… Script executed successfully!\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. In your training script, you can now load these files directly.\")\n",
    "        print(\"   - `from scipy.sparse import load_npz`\")\n",
    "        print(\"   - `X = load_npz('processed_data/X_processed.npz')`\")\n",
    "        print(\"   - `y_df = pd.read_csv('processed_data/y_processed.csv')`\")\n",
    "        print(\"   - `y = y_df['price_log']`\")\n",
    "        print(\"2. Train your model on this loaded data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288ee7f",
   "metadata": {},
   "source": [
    "\"extract_text_from_images.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import base64 # Required for encoding images\n",
    "import json   # Required for constructing the JSON payload\n",
    "\n",
    "# --- 1. API Interaction Function ---\n",
    "\n",
    "def get_local_vlm_description(image_url: str) -> str:\n",
    "    api_url = \"http://localhost:1234/v1/chat/completions\"\n",
    "\n",
    "    # Strict OCR-style prompt\n",
    "    prompt_text = (\n",
    "        \"Extract ONLY the exact text visible in the image. \"\n",
    "        \"Do not describe the product, do not add explanations, \"\n",
    "        \"do not summarize, and do not include anything extra. \"\n",
    "        \"Return only the raw text exactly as it appears.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(image_url, timeout=20, headers=headers)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        base64_image = base64.b64encode(response.content).decode('utf-8')\n",
    "\n",
    "        payload = {\n",
    "            \"model\": \"smolvlm2-500m-video-instruct\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt_text},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            \"max_tokens\": 250,\n",
    "            \"temperature\": 0.0  # deterministic, no creativity\n",
    "        }\n",
    "\n",
    "        api_response = requests.post(api_url, headers={\"Content-Type\": \"application/json\"}, json=payload)\n",
    "        api_response.raise_for_status()\n",
    "        response_json = api_response.json()\n",
    "\n",
    "        if 'choices' in response_json and len(response_json['choices']) > 0:\n",
    "            content = response_json['choices'][0]['message']['content']\n",
    "            return content.strip()\n",
    "        else:\n",
    "            print(f\"\\nAPI returned an unexpected response for {image_url}: {response_json}\")\n",
    "            return \"\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\nNetwork or Download Error for {image_url}: {e}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred for {image_url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    print(\"--- Starting Feature Extraction using Local LM Studio VLM ---\")\n",
    "    print(\"IMPORTANT: Ensure your LM Studio server is running with the correct model loaded.\")\n",
    "\n",
    "    # Path to your CSV file\n",
    "    CSV_PATH = '68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test.csv' \n",
    "    OUTPUT_DIR = 'processed_data'\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    print(f\"Loading CSV file: {CSV_PATH}...\")\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    df.drop_duplicates(subset=['sample_id', 'image_link'], inplace=True)\n",
    "\n",
    "    local_vlm_descriptions = []\n",
    "    print(f\"\\nGenerating descriptions for {len(df)} images via local API...\")\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        description = get_local_vlm_description(row['image_link'])\n",
    "        local_vlm_descriptions.append(description)\n",
    "\n",
    "    # Save the results\n",
    "    results_df = pd.DataFrame({\n",
    "        'sample_id': df['sample_id'],\n",
    "        'smolvlm_description': local_vlm_descriptions\n",
    "    })\n",
    "\n",
    "    output_path = os.path.join(OUTPUT_DIR, 'smolvlm_extracted_features_only.csv')\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"\\nâœ… Local VLM feature extraction complete. Descriptions saved to '{output_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293238fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Amazon ML Challenge 2025 - Image Feature Extraction\n",
      "======================================================================\n",
      "âœ… GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "   Memory: 8.6 GB\n",
      "   CUDA: 11.8\n",
      "Loading ResNet50...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded with FP16 optimization (2048D features)\n",
      "\n",
      "ðŸ“‚ Loading data...\n",
      "   Total: 150000\n",
      "ðŸ“‚ Resuming: 17312 processed\n",
      "   Remaining: 132688\n",
      "\n",
      "ðŸš€ Processing batches of 96 (ETA: ~58 min)\n",
      "   Workers: 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   7%|â–‹         | 94/1383 [19:44<4:19:00, 12.06s/it, Success=100.0%, Speed=7.6 img/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==========================================\n",
    "# GPU SETUP\n",
    "# ==========================================\n",
    "\n",
    "def setup_device():\n",
    "    \"\"\"Setup PyTorch device with optimization.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        \n",
    "        print(f\"âœ… GPU: {gpu_name}\")\n",
    "        print(f\"   Memory: {gpu_memory:.1f} GB\")\n",
    "        print(f\"   CUDA: {torch.version.cuda}\")\n",
    "        \n",
    "        # Optimization for RTX 4060\n",
    "        torch.backends.cudnn.benchmark = True  # Auto-tune convolutions\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"âš ï¸  Using CPU\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "# ==========================================\n",
    "# MODEL SETUP\n",
    "# ==========================================\n",
    "\n",
    "def setup_model(device):\n",
    "    \"\"\"Load ResNet50 optimized for inference.\"\"\"\n",
    "    print(\"Loading ResNet50...\")\n",
    "    \n",
    "    # Load pretrained model\n",
    "    model = models.resnet50(weights='IMAGENET1K_V2')\n",
    "    \n",
    "    # Remove classification head (keep features only)\n",
    "    model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "    \n",
    "    # Move to GPU and set to eval mode\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Enable mixed precision for faster inference (RTX 4060 supports this)\n",
    "    if device.type == 'cuda':\n",
    "        model = model.half()  # FP16 for 2x speedup\n",
    "        print(\"âœ… Model loaded with FP16 optimization (2048D features)\")\n",
    "    else:\n",
    "        print(\"âœ… Model loaded (2048D features)\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# IMAGE PREPROCESSING\n",
    "# ==========================================\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "def download_image(url, max_retries=3):\n",
    "    \"\"\"Download and preprocess image with retries.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url,\n",
    "                timeout=12,\n",
    "                headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Load and convert to RGB\n",
    "            img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            \n",
    "            # Apply transforms\n",
    "            return transform(img)\n",
    "            \n",
    "        except Exception:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(0.3)\n",
    "            else:\n",
    "                return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "# ==========================================\n",
    "# BATCH PROCESSING\n",
    "# ==========================================\n",
    "\n",
    "def process_batch(urls, sample_ids, model, device, max_workers=20):\n",
    "    \"\"\"Process batch with parallel downloads + GPU inference.\"\"\"\n",
    "    \n",
    "    # Parallel download\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        images = list(executor.map(download_image, urls))\n",
    "    \n",
    "    # Separate valid/invalid\n",
    "    valid_images = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for i, img in enumerate(images):\n",
    "        if img is not None:\n",
    "            valid_images.append(img)\n",
    "            valid_indices.append(i)\n",
    "    \n",
    "    # Initialize with NaN\n",
    "    features = np.full((len(urls), 2048), np.nan, dtype=np.float32)\n",
    "    \n",
    "    # GPU inference\n",
    "    if valid_images:\n",
    "        batch_tensor = torch.stack(valid_images).to(device)\n",
    "        \n",
    "        # Use FP16 if GPU\n",
    "        if device.type == 'cuda':\n",
    "            batch_tensor = batch_tensor.half()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_features = model(batch_tensor)\n",
    "            batch_features = batch_features.squeeze(-1).squeeze(-1)\n",
    "            batch_features = batch_features.float().cpu().numpy()  # Back to FP32\n",
    "        \n",
    "        # Assign features\n",
    "        for i, idx in enumerate(valid_indices):\n",
    "            features[idx] = batch_features[i]\n",
    "    \n",
    "    success = [img is not None for img in images]\n",
    "    \n",
    "    return sample_ids, features, success\n",
    "\n",
    "# ==========================================\n",
    "# CHECKPOINTING\n",
    "# ==========================================\n",
    "\n",
    "class Checkpoint:\n",
    "    \"\"\"Incremental saving with resume capability.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        self.features_file = os.path.join(output_dir, 'X_image_features.npy')\n",
    "        self.ids_file = os.path.join(output_dir, 'all_sample_ids.csv')\n",
    "    \n",
    "    def load_progress(self):\n",
    "        \"\"\"Get already processed IDs.\"\"\"\n",
    "        if os.path.exists(self.ids_file):\n",
    "            df = pd.read_csv(self.ids_file)\n",
    "            processed = set(df['sample_id'].values)\n",
    "            print(f\"ðŸ“‚ Resuming: {len(processed)} processed\")\n",
    "            return processed\n",
    "        return set()\n",
    "    \n",
    "    def save_batch(self, sample_ids, features):\n",
    "        \"\"\"Append batch.\"\"\"\n",
    "        # Features\n",
    "        if os.path.exists(self.features_file):\n",
    "            existing = np.load(self.features_file)\n",
    "            combined = np.vstack([existing, features])\n",
    "        else:\n",
    "            combined = features\n",
    "        \n",
    "        np.save(self.features_file, combined)\n",
    "        \n",
    "        # IDs\n",
    "        pd.DataFrame({'sample_id': sample_ids}).to_csv(\n",
    "            self.ids_file,\n",
    "            mode='a',\n",
    "            header=not os.path.exists(self.ids_file),\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "# ==========================================\n",
    "# MAIN PIPELINE\n",
    "# ==========================================\n",
    "\n",
    "def extract_features(\n",
    "    train_csv='dataset/train.csv',\n",
    "    test_csv='dataset/test.csv',\n",
    "    output_dir='processed_data',\n",
    "    batch_size=96,\n",
    "    max_workers=20\n",
    "):\n",
    "    \"\"\"Main extraction pipeline.\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"Amazon ML Challenge 2025 - Image Feature Extraction\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Setup\n",
    "    device = setup_device()\n",
    "    model = setup_model(device)\n",
    "    checkpoint = Checkpoint(output_dir)\n",
    "    \n",
    "    # Load data\n",
    "    print(f\"\\nðŸ“‚ Loading data...\")\n",
    "    df_train = pd.read_csv(train_csv)\n",
    "    df_test = pd.read_csv(test_csv)\n",
    "    \n",
    "    df_all = pd.concat([\n",
    "        df_train[['sample_id', 'image_link']],\n",
    "        df_test[['sample_id', 'image_link']]\n",
    "    ]).drop_duplicates(subset=['sample_id']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"   Total: {len(df_all)}\")\n",
    "    \n",
    "    # Resume\n",
    "    processed = checkpoint.load_progress()\n",
    "    df_todo = df_all[~df_all['sample_id'].isin(processed)].reset_index(drop=True)\n",
    "    \n",
    "    if df_todo.empty:\n",
    "        print(\"\\nâœ… All processed!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"   Remaining: {len(df_todo)}\\n\")\n",
    "    \n",
    "    # Process\n",
    "    num_batches = (len(df_todo) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"ðŸš€ Processing batches of {batch_size} (ETA: ~{num_batches*2.5/60:.0f} min)\")\n",
    "    print(f\"   Workers: {max_workers}\\n\")\n",
    "    \n",
    "    start = time.time()\n",
    "    stats = {'success': 0, 'failed': 0}\n",
    "    \n",
    "    pbar = tqdm(range(0, len(df_todo), batch_size), total=num_batches, desc=\"Progress\")\n",
    "    \n",
    "    for i in pbar:\n",
    "        batch_df = df_todo.iloc[i:i + batch_size]\n",
    "        \n",
    "        batch_ids, batch_features, success = process_batch(\n",
    "            batch_df['image_link'].tolist(),\n",
    "            batch_df['sample_id'].tolist(),\n",
    "            model, device, max_workers\n",
    "        )\n",
    "        \n",
    "        checkpoint.save_batch(batch_ids, batch_features)\n",
    "        \n",
    "        # Stats\n",
    "        stats['success'] += sum(success)\n",
    "        stats['failed'] += len(success) - sum(success)\n",
    "        \n",
    "        # Update progress bar\n",
    "        total = stats['success'] + stats['failed']\n",
    "        rate = stats['success'] / total * 100 if total > 0 else 0\n",
    "        speed = total / (time.time() - start)\n",
    "        pbar.set_postfix({\n",
    "            'Success': f\"{rate:.1f}%\",\n",
    "            'Speed': f\"{speed:.1f} img/s\"\n",
    "        })\n",
    "        \n",
    "        # Clear GPU cache periodically\n",
    "        if i % 50 == 0 and device.type == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"âœ… Extraction Complete!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    total = stats['success'] + stats['failed']\n",
    "    print(f\"Total: {total:,}\")\n",
    "    print(f\"Success: {stats['success']:,} ({stats['success']/total*100:.1f}%)\")\n",
    "    print(f\"Failed: {stats['failed']:,}\")\n",
    "    print(f\"Time: {elapsed/60:.1f} min\")\n",
    "    print(f\"Speed: {total/elapsed:.1f} images/sec\")\n",
    "    \n",
    "    # Impute\n",
    "    print(f\"\\nðŸ”§ Final processing...\")\n",
    "    features = np.load(checkpoint.features_file)\n",
    "    \n",
    "    if np.isnan(features).any():\n",
    "        n_missing = np.isnan(features).any(axis=1).sum()\n",
    "        print(f\"   Imputing {n_missing:,} samples...\")\n",
    "        \n",
    "        col_means = np.nanmean(features, axis=0)\n",
    "        for col in range(features.shape[1]):\n",
    "            mask = np.isnan(features[:, col])\n",
    "            features[mask, col] = col_means[col]\n",
    "        \n",
    "        np.save(checkpoint.features_file, features)\n",
    "    \n",
    "    print(f\"\\nâœ… Saved: {checkpoint.features_file}\")\n",
    "    print(f\"   Shape: {features.shape}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# RUN\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    CONFIG = {\n",
    "        'train_csv': 'dataset/train.csv',\n",
    "        'test_csv': 'dataset/test.csv',\n",
    "        'output_dir': 'processed_data',\n",
    "        'batch_size': 96,      # Optimized for RTX 4060\n",
    "        'max_workers': 20      # Max parallel downloads\n",
    "    }\n",
    "    \n",
    "    extract_features(**CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfb27b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.0+cu118\n",
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc93e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, hstack\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "# --- 1. Re-usable Components ---\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    \"\"\"A consistent cleaning function for both text sources.\"\"\"\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'<.*?>|Value:.*|Unit:.*', ' ', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# --- 2. Load and Combine All Data Sources ---\n",
    "\n",
    "def load_and_combine_all_features(data_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Loads all preprocessed features and combines them.\n",
    "    Returns the combined feature matrix and the original DataFrame with prices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"--- Loading All Preprocessed Data ---\")\n",
    "        \n",
    "        X_text_struct = load_npz(f'{data_dir}/X_processed.npz')\n",
    "        y_df = pd.read_csv(f'{data_dir}/y_processed.csv').set_index('sample_id')\n",
    "        \n",
    "        vlm_df = pd.read_csv(f'{data_dir}/smolvlm_extracted_features.csv').set_index('sample_id')\n",
    "        vlm_df = vlm_df.reindex(y_df.index).fillna('')\n",
    "        vlm_df['cleaned_vlm'] = vlm_df['smolvlm_description'].apply(clean_text)\n",
    "        \n",
    "        vlm_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
    "        X_vlm = vlm_vectorizer.fit_transform(vlm_df['cleaned_vlm'])\n",
    "        \n",
    "        X_images = np.load(f'{data_dir}/X_image_features.npy')\n",
    "        all_ids_df = pd.read_csv(f'{data_dir}/all_sample_ids.csv').set_index('sample_id')\n",
    "        image_features_df = pd.DataFrame(X_images, index=all_ids_df.index)\n",
    "        X_images_aligned = image_features_df.reindex(y_df.index).values\n",
    "        \n",
    "        X_final_combined = hstack([X_text_struct, X_vlm, X_images_aligned]).tocsr()\n",
    "\n",
    "        print(f\"âœ… Data loaded and combined successfully! Final shape: {X_final_combined.shape}\")\n",
    "        \n",
    "        # We need the original dataframe with IDs and prices for splitting and scoring\n",
    "        full_df = pd.read_csv(f'{data_dir}/y_processed.csv')\n",
    "        print(\"Vectorizing VLM text...\")\n",
    "        vlm_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
    "        # This line was changed: we fit_transform on the training data\n",
    "        X_vlm = vlm_vectorizer.fit_transform(vlm_df['cleaned_vlm'])\n",
    "        \n",
    "        # --- ADD THIS LINE ---\n",
    "        joblib.dump(vlm_vectorizer, f'{data_dir}/vlm_vectorizer.joblib')\n",
    "        print(\"Saved VLM TF-IDF vectorizer.\")\n",
    "        return X_final_combined, full_df\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data: {e}. Please ensure you have run all three preprocessing scripts first.\")\n",
    "        return None, None\n",
    "\n",
    "# --- 3. Full Train, Predict, and Evaluate Pipeline ---\n",
    "\n",
    "def run_full_pipeline(X, df):\n",
    "    \"\"\"\n",
    "    Trains on a subset, predicts on a holdout, saves a submission file, and scores it.\n",
    "    \"\"\"\n",
    "    if X is None or df is None: return\n",
    "\n",
    "    print(\"\\n--- Simulating Competition Workflow ---\")\n",
    "    \n",
    "    # --- Step 1: Split the data into a training set and a \"pretend\" test set ---\n",
    "    # We split based on the dataframe to keep track of IDs\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Get the corresponding rows from the sparse matrix X\n",
    "    X_train = X[train_df.index]\n",
    "    y_train = train_df['price_log']\n",
    "    \n",
    "    X_test = X[test_df.index]\n",
    "    # We will use this later to score our predictions\n",
    "    y_test_ground_truth_log = test_df['price_log'] \n",
    "\n",
    "    print(f\"Training on {len(train_df)} samples, predicting on {len(test_df)} samples.\")\n",
    "\n",
    "    # --- Step 2: Train the model ONLY on the training set ---\n",
    "    print(\"\\nTraining a LightGBM Regressor model...\")\n",
    "    lgbm = lgb.LGBMRegressor(\n",
    "        objective='regression_l1', metric='mae', n_estimators=1000,\n",
    "        learning_rate=0.05, num_leaves=31, random_state=42, n_jobs=-1\n",
    "    )\n",
    "    lgbm.fit(X_train, y_train, eval_set=[(X_test, y_test_ground_truth_log)], callbacks=[lgb.early_stopping(50, verbose=False)])\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- Step 3: Make predictions on the \"pretend\" test set ---\n",
    "    print(\"Making predictions on the holdout test set...\")\n",
    "    predictions_log = lgbm.predict(X_test)\n",
    "    \n",
    "    # Inverse transform to get actual prices\n",
    "    predictions_actual = np.expm1(predictions_log)\n",
    "    predictions_actual[predictions_actual < 0] = 0 # Enforce non-negative constraint\n",
    "\n",
    "    # --- Step 4: Create and save the submission CSV file ---\n",
    "    submission_df = pd.DataFrame({\n",
    "        'sample_id': test_df['sample_id'],\n",
    "        'price': predictions_actual\n",
    "    })\n",
    "    \n",
    "    submission_path = 'sample_submission.csv'\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"âœ… Submission file created at: '{submission_path}'\")\n",
    "\n",
    "    # --- Step 5: Score the submission file against the ground truth ---\n",
    "    print(\"\\n--- Scoring Submission File ---\")\n",
    "    \n",
    "    # Load the ground truth from the original file\n",
    "    ground_truth_df = pd.read_csv('68e8d1d70b66d_student_resource/student_resource/dataset/sample_test_out.csv')\n",
    "    \n",
    "    # Merge our predictions with the ground truth\n",
    "    # This mimics exactly how the competition leaderboard is calculated\n",
    "    merged_score_df = pd.merge(submission_df, ground_truth_df, on='sample_id', suffixes=('_pred', '_true'))\n",
    "    \n",
    "    if len(merged_score_df) != len(test_df):\n",
    "        print(\"Warning: The number of predictions does not match the test set size!\")\n",
    "\n",
    "    # Calculate the final SMAPE score\n",
    "    final_smape_score = smape(merged_score_df['price_true'], merged_score_df['price_pred'])\n",
    "    \n",
    "    print(\"\\n--- FINAL SIMULATED SCORE ---\")\n",
    "    print(f\"SMAPE against sample_test_out.csv: {final_smape_score:.4f}%\")\n",
    "    \n",
    "    return lgbm\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    # Load all features and the corresponding dataframe with IDs and prices\n",
    "    X_final, df_final = load_and_combine_all_features()\n",
    "    \n",
    "    # Run the full simulation\n",
    "    final_model = run_full_pipeline(X_final, df_final)\n",
    "    \n",
    "    if final_model:\n",
    "        joblib.dump(final_model, 'final_lgbm_model_for_submission.joblib')\n",
    "        print(\"\\nâœ… Final trained model saved as 'final_lgbm_model_for_submission.joblib'\")\n",
    "        print(\"You can use this model to predict on the real 'test.csv' for the competition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc77c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "import joblib\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import os # Added for path joining\n",
    "from sklearn.metrics import r2_score # Added for R-squared score\n",
    "\n",
    "# --- 1. Load All Necessary Artifacts and Helper Functions ---\n",
    "print(\"--- Loading Artifacts for Prediction ---\")\n",
    "\n",
    "# --- Helper Functions (must be identical to training) ---\n",
    "# NOTE: The SMAPE function is now defined here for scoring\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'<.*?>|Value:.*|Unit:.*', ' ', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "def extract_structured_data(text):\n",
    "    if not isinstance(text, str): return pd.Series([np.nan, 'unknown'], index=['Value', 'Unit'])\n",
    "    value_match = re.search(r'Value:\\s*([\\d\\.]+)', text)\n",
    "    value = float(value_match.group(1)) if value_match else np.nan\n",
    "    unit_match = re.search(r'Unit:\\s*(\\w+)', text)\n",
    "    unit = unit_match.group(1) if unit_match else 'unknown'\n",
    "    return pd.Series([value, unit], index=['Value', 'Unit'])\n",
    "\n",
    "def standardize_units(unit):\n",
    "    if not isinstance(unit, str): return 'unknown'\n",
    "    unit = unit.lower().strip()\n",
    "    unit_map = {'oz': 'ounce', 'ounces': 'ounce', 'fl oz': 'fl_oz', 'fz': 'fl_oz', 'ct': 'count', 'none': 'unknown'}\n",
    "    return unit_map.get(unit, unit)\n",
    "\n",
    "# --- Load Saved Objects ---\n",
    "try:\n",
    "    PREPROCESSOR_PATH = 'processed_data/preprocessor.joblib'\n",
    "    VLM_VECTORIZER_PATH = 'processed_data/vlm_vectorizer.joblib'\n",
    "    MODEL_PATH = 'final_lgbm_model_for_submission.joblib'\n",
    "    \n",
    "    preprocessor = joblib.load(PREPROCESSOR_PATH)\n",
    "    vlm_vectorizer = joblib.load(VLM_VECTORIZER_PATH)\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    print(\"âœ… All models and preprocessors loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading artifact: {e}\")\n",
    "    print(\"Please ensure you have run the full training pipeline on the complete dataset first.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Feature Engineering Function for New Data (using robust reindexing) ---\n",
    "def create_features_for_test_data(df, data_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Applies the complete feature engineering pipeline to new, unseen test data.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Applying Feature Engineering to Test Data ---\")\n",
    "    \n",
    "    df_indexed = df.set_index('sample_id')\n",
    "\n",
    "    print(\"Processing catalog content...\")\n",
    "    extracted_data = df['catalog_content'].apply(extract_structured_data)\n",
    "    df_features = pd.concat([df, extracted_data], axis=1)\n",
    "    df_features['cleaned_catalog'] = df_features['catalog_content'].apply(clean_text)\n",
    "    df_features['Unit_standardized'] = df_features['Unit'].apply(standardize_units)\n",
    "    X_text_struct = preprocessor.transform(df_features)\n",
    "\n",
    "    print(\"Processing VLM text features...\")\n",
    "    vlm_df_all = pd.read_csv(os.path.join(data_dir, 'smolvlm_extracted_features.csv')).set_index('sample_id')\n",
    "    vlm_df_aligned = vlm_df_all.reindex(df_indexed.index).fillna('')\n",
    "    vlm_df_aligned['cleaned_vlm'] = vlm_df_aligned['smolvlm_description'].apply(clean_text)\n",
    "    X_vlm = vlm_vectorizer.transform(vlm_df_aligned['cleaned_vlm'])\n",
    "\n",
    "    print(\"Processing visual features...\")\n",
    "    all_image_features = np.load(os.path.join(data_dir, 'X_image_features.npy'))\n",
    "    all_ids_df = pd.read_csv(os.path.join(data_dir, 'all_sample_ids.csv')).set_index('sample_id')\n",
    "    image_features_df = pd.DataFrame(all_image_features, index=all_ids_df.index)\n",
    "    image_features_aligned = image_features_df.reindex(df_indexed.index)\n",
    "    \n",
    "    if image_features_aligned.isnull().values.any():\n",
    "        print(\"Warning: Missing visual features for some IDs. Imputing with mean.\")\n",
    "        image_features_aligned = image_features_aligned.fillna(image_features_aligned.mean())\n",
    "    X_images_test = image_features_aligned.values\n",
    "\n",
    "    print(\"Combining all feature sets...\")\n",
    "    X_test_final = hstack([X_text_struct, X_vlm, X_images_test]).tocsr()\n",
    "    \n",
    "    if X_text_struct.shape[0] != X_images_test.shape[0]:\n",
    "         raise ValueError(f\"Row count mismatch! Text features: {X_text_struct.shape[0]}, Image features: {X_images_test.shape[0]}\")\n",
    "    \n",
    "    print(f\"âœ… Final test feature matrix created with shape: {X_test_final.shape}\")\n",
    "    return X_test_final\n",
    "\n",
    "# --- 3. Main Prediction & Evaluation Block ---\n",
    "if __name__ == '__main__':\n",
    "    # --- Define file paths for the sample data evaluation ---\n",
    "    # We will PREDICT on `sample_test.csv` and SCORE against `sample_test_out.csv`\n",
    "    TEST_DATA_PATH = '68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test.csv'\n",
    "    GROUND_TRUTH_PATH = '68e8d1d70b66d_student_resource\\student_resource\\dataset\\sample_test_out.csv'\n",
    "    SUBMISSION_FILE_PATH = 'sample_test_prediction_output.csv' # Give it a different name\n",
    "    \n",
    "    print(f\"\\nLoading SAMPLE test data from: {TEST_DATA_PATH}\")\n",
    "    test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "    \n",
    "    # --- Create features for the test data ---\n",
    "    X_test = create_features_for_test_data(test_df.copy())\n",
    "    \n",
    "    # --- Make Predictions ---\n",
    "    print(\"\\nMaking final predictions on sample data...\")\n",
    "    predictions_log = model.predict(X_test)\n",
    "    \n",
    "    predictions_actual = np.expm1(predictions_log)\n",
    "    predictions_actual[predictions_actual < 0] = 0\n",
    "\n",
    "    # --- Create and Save the Prediction File ---\n",
    "    submission_df = pd.DataFrame({\n",
    "        'sample_id': test_df['sample_id'],\n",
    "        'price': predictions_actual\n",
    "    })\n",
    "    submission_df.to_csv(SUBMISSION_FILE_PATH, index=False)\n",
    "    print(f\"Prediction file for sample data generated at: '{SUBMISSION_FILE_PATH}'\")\n",
    "    \n",
    "    # --- NEW: Score the predictions against the ground truth ---\n",
    "    print(\"\\n--- Scoring Predictions Against Ground Truth ---\")\n",
    "    try:\n",
    "        ground_truth_df = pd.read_csv(GROUND_TRUTH_PATH)\n",
    "        \n",
    "        # Merge our predictions with the true prices\n",
    "        merged_score_df = pd.merge(submission_df, ground_truth_df, on='sample_id', suffixes=('_pred', '_true'))\n",
    "        \n",
    "        if len(merged_score_df) != len(test_df):\n",
    "            print(\"Warning: Not all sample IDs could be scored.\")\n",
    "\n",
    "        # Calculate and print the final scores\n",
    "        final_smape_score = smape(merged_score_df['price_true'], merged_score_df['price_pred'])\n",
    "        final_r2_score = r2_score(merged_score_df['price_true'], merged_score_df['price_pred'])\n",
    "\n",
    "        print(\"\\n--- FINAL PERFORMANCE ON SAMPLE DATA ---\")\n",
    "        print(f\"SMAPE Score: {final_smape_score:.4f}%\")\n",
    "        print(f\"R-squared (RÂ²): {final_r2_score:.4f}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\nCould not find ground truth file at '{GROUND_TRUTH_PATH}'. Skipping scoring.\")\n",
    "        \n",
    "    print(f\"\\n\\nðŸŽ‰ SUCCESS! ðŸŽ‰\")\n",
    "    print(\"The script has successfully generated predictions and scored them.\")\n",
    "    print(\"To generate the REAL submission, change TEST_DATA_PATH to 'dataset/test.csv' and remove the scoring section.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428a1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, hstack\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBRegressor  # Changed import\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "# --- 1. Re-usable Components ---\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    \"\"\"A consistent cleaning function for both text sources.\"\"\"\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'<.*?>|Value:.*|Unit:.*', ' ', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# --- 2. Load and Combine All Data Sources ---\n",
    "\n",
    "def load_and_combine_all_features(data_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Loads all preprocessed features and combines them.\n",
    "    Returns the combined feature matrix and the original DataFrame with prices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"--- Loading All Preprocessed Data ---\")\n",
    "        \n",
    "        X_text_struct = load_npz(f'{data_dir}/X_processed.npz')\n",
    "        y_df = pd.read_csv(f'{data_dir}/y_processed.csv').set_index('sample_id')\n",
    "        \n",
    "        vlm_df = pd.read_csv(f'{data_dir}/smolvlm_extracted_features.csv').set_index('sample_id')\n",
    "        vlm_df = vlm_df.reindex(y_df.index).fillna('')\n",
    "        vlm_df['cleaned_vlm'] = vlm_df['smolvlm_description'].apply(clean_text)\n",
    "        \n",
    "        vlm_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
    "        X_vlm = vlm_vectorizer.fit_transform(vlm_df['cleaned_vlm'])\n",
    "        \n",
    "        X_images = np.load(f'{data_dir}/X_image_features.npy')\n",
    "        all_ids_df = pd.read_csv(f'{data_dir}/all_sample_ids.csv').set_index('sample_id')\n",
    "        image_features_df = pd.DataFrame(X_images, index=all_ids_df.index)\n",
    "        X_images_aligned = image_features_df.reindex(y_df.index).values\n",
    "        \n",
    "        X_final_combined = hstack([X_text_struct, X_vlm, X_images_aligned]).tocsr()\n",
    "\n",
    "        print(f\"âœ… Data loaded and combined successfully! Final shape: {X_final_combined.shape}\")\n",
    "        \n",
    "        # We need the original dataframe with IDs and prices for splitting and scoring\n",
    "        full_df = pd.read_csv(f'{data_dir}/y_processed.csv')\n",
    "        print(\"Vectorizing VLM text...\")\n",
    "        vlm_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
    "        # This line was changed: we fit_transform on the training data\n",
    "        X_vlm = vlm_vectorizer.fit_transform(vlm_df['cleaned_vlm'])\n",
    "        \n",
    "        # --- ADD THIS LINE ---\n",
    "        joblib.dump(vlm_vectorizer, f'{data_dir}/vlm_vectorizer.joblib')\n",
    "        print(\"Saved VLM TF-IDF vectorizer.\")\n",
    "        return X_final_combined, full_df\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data: {e}. Please ensure you have run all three preprocessing scripts first.\")\n",
    "        return None, None\n",
    "\n",
    "# --- 3. Full Train, Predict, and Evaluate Pipeline ---\n",
    "\n",
    "def run_full_pipeline(X, df):\n",
    "    \"\"\"\n",
    "    Trains on a subset, predicts on a holdout, saves a submission file, and scores it.\n",
    "    \"\"\"\n",
    "    if X is None or df is None: return\n",
    "\n",
    "    print(\"\\n--- Simulating Competition Workflow ---\")\n",
    "    \n",
    "    # --- Step 1: Split the data into a training set and a \"pretend\" test set ---\n",
    "    # We split based on the dataframe to keep track of IDs\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Get the corresponding rows from the sparse matrix X\n",
    "    X_train = X[train_df.index]\n",
    "    y_train = train_df['price_log']\n",
    "    \n",
    "    X_test = X[test_df.index]\n",
    "    # We will use this later to score our predictions\n",
    "    y_test_ground_truth_log = test_df['price_log'] \n",
    "\n",
    "    print(f\"Training on {len(train_df)} samples, predicting on {len(test_df)} samples.\")\n",
    "\n",
    "    # --- Step 2: Train the model ONLY on the training set ---\n",
    "    print(\"\\nTraining an XGBoost Regressor model...\")\n",
    "    xgb_model = XGBRegressor(\n",
    "        objective='reg:absoluteerror',  # Matches LightGBM's regression_l1 for MAE\n",
    "        eval_metric='mae', \n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05, \n",
    "        max_depth=6,  # Approximates num_leaves=31\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test_ground_truth_log)], callbacks=[early_stopping_rounds=50, verbose=False])  # Adjusted for XGBoost callbacks\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- Step 3: Make predictions on the \"pretend\" test set ---\n",
    "    print(\"Making predictions on the holdout test set...\")\n",
    "    predictions_log = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Inverse transform to get actual prices\n",
    "    predictions_actual = np.expm1(predictions_log)\n",
    "    predictions_actual[predictions_actual < 0] = 0 # Enforce non-negative constraint\n",
    "\n",
    "    # --- Step 4: Create and save the submission CSV file ---\n",
    "    submission_df = pd.DataFrame({\n",
    "        'sample_id': test_df['sample_id'],\n",
    "        'price': predictions_actual\n",
    "    })\n",
    "    \n",
    "    submission_path = 'sample_submission_xgb.csv'\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"âœ… Submission file created at: '{submission_path}'\")\n",
    "\n",
    "    # --- Step 5: Score the submission file against the ground truth ---\n",
    "    print(\"\\n--- Scoring Submission File ---\")\n",
    "    \n",
    "    # Load the ground truth from the original file\n",
    "    ground_truth_df = pd.read_csv('68e8d1d70b66d_student_resource/student_resource/dataset/sample_test_out.csv')\n",
    "    \n",
    "    # Merge our predictions with the ground truth\n",
    "    # This mimics exactly how the competition leaderboard is calculated\n",
    "    merged_score_df = pd.merge(submission_df, ground_truth_df, on='sample_id', suffixes=('_pred', '_true'))\n",
    "    \n",
    "    if len(merged_score_df) != len(test_df):\n",
    "        print(\"Warning: The number of predictions does not match the test set size!\")\n",
    "\n",
    "    # Calculate the final SMAPE score\n",
    "    final_smape_score = smape(merged_score_df['price_true'], merged_score_df['price_pred'])\n",
    "    \n",
    "    print(\"\\n--- FINAL SIMULATED SCORE ---\")\n",
    "    print(f\"SMAPE against sample_test_out.csv: {final_smape_score:.4f}%\")\n",
    "    \n",
    "    return xgb_model\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    # Load all features and the corresponding dataframe with IDs and prices\n",
    "    X_final, df_final = load_and_combine_all_features()\n",
    "    \n",
    "    # Run the full simulation\n",
    "    final_model = run_full_pipeline(X_final, df_final)\n",
    "    \n",
    "    if final_model:\n",
    "        joblib.dump(final_model, 'final_xgb_model_for_submission.joblib')\n",
    "        print(\"\\nâœ… Final trained model saved as 'final_xgb_model_for_submission.joblib'\")\n",
    "        print(\"You can use this model to predict on the real 'test.csv' for the competition.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050ca2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778910ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, hstack\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBRegressor  # Changed import for XGBoost\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "# --- 1. Re-usable Components ---\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    \"\"\"A consistent cleaning function for both text sources.\"\"\"\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'<.*?>|Value:.*|Unit:.*', ' ', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# --- 2. Load and Combine All Data Sources ---\n",
    "\n",
    "def load_and_combine_all_features(data_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Loads all preprocessed features and combines them.\n",
    "    Returns the combined feature matrix and the original DataFrame with prices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"--- Loading All Preprocessed Data ---\")\n",
    "        \n",
    "        X_text_struct = load_npz(f'{data_dir}/X_processed.npz')\n",
    "        y_df = pd.read_csv(f'{data_dir}/y_processed.csv').set_index('sample_id')\n",
    "        \n",
    "        vlm_df = pd.read_csv(f'{data_dir}/smolvlm_extracted_features.csv').set_index('sample_id')\n",
    "        vlm_df = vlm_df.reindex(y_df.index).fillna('')\n",
    "        vlm_df['cleaned_vlm'] = vlm_df['smolvlm_description'].apply(clean_text)\n",
    "        \n",
    "        vlm_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
    "        X_vlm = vlm_vectorizer.fit_transform(vlm_df['cleaned_vlm'])\n",
    "        \n",
    "        X_images = np.load(f'{data_dir}/X_image_features.npy')\n",
    "        all_ids_df = pd.read_csv(f'{data_dir}/all_sample_ids.csv').set_index('sample_id')\n",
    "        image_features_df = pd.DataFrame(X_images, index=all_ids_df.index)\n",
    "        X_images_aligned = image_features_df.reindex(y_df.index).values\n",
    "        \n",
    "        X_final_combined = hstack([X_text_struct, X_vlm, X_images_aligned]).tocsr()\n",
    "\n",
    "        print(f\"âœ… Data loaded and combined successfully! Final shape: {X_final_combined.shape}\")\n",
    "        \n",
    "        # We need the original dataframe with IDs and prices for splitting and scoring\n",
    "        full_df = pd.read_csv(f'{data_dir}/y_processed.csv')\n",
    "        print(\"Vectorizing VLM text...\")\n",
    "        vlm_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
    "        # This line was changed: we fit_transform on the training data\n",
    "        X_vlm = vlm_vectorizer.fit_transform(vlm_df['cleaned_vlm'])\n",
    "        \n",
    "        # --- ADD THIS LINE ---\n",
    "        joblib.dump(vlm_vectorizer, f'{data_dir}/vlm_vectorizer.joblib')\n",
    "        print(\"Saved VLM TF-IDF vectorizer.\")\n",
    "        return X_final_combined, full_df\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data: {e}. Please ensure you have run all three preprocessing scripts first.\")\n",
    "        return None, None\n",
    "\n",
    "# --- 3. Full Train, Predict, and Evaluate Pipeline ---\n",
    "\n",
    "def run_full_pipeline(X, df):\n",
    "    \"\"\"\n",
    "    Trains on a subset, predicts on a holdout, saves a submission file, and scores it.\n",
    "    \"\"\"\n",
    "    if X is None or df is None: return\n",
    "\n",
    "    print(\"\\n--- Simulating Competition Workflow ---\")\n",
    "    \n",
    "    # --- Step 1: Split the data into a training set and a \"pretend\" test set ---\n",
    "    # We split based on the dataframe to keep track of IDs\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Get the corresponding rows from the sparse matrix X\n",
    "    X_train = X[train_df.index]\n",
    "    y_train = train_df['price_log']\n",
    "    \n",
    "    X_test = X[test_df.index]\n",
    "    # We will use this later to score our predictions\n",
    "    y_test_ground_truth_log = test_df['price_log'] \n",
    "\n",
    "    print(f\"Training on {len(train_df)} samples, predicting on {len(test_df)} samples.\")\n",
    "\n",
    "    # --- Step 2: Train the model ONLY on the training set ---\n",
    "    print(\"\\nTraining an XGBoost Regressor model...\")\n",
    "    xgb_model = XGBRegressor(\n",
    "        objective='reg:absoluteerror',  # Matches LightGBM's regression_l1 for MAE\n",
    "        eval_metric='mae', \n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05, \n",
    "        max_depth=6,  # Approximates num_leaves=31\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train, \n",
    "                  eval_set=[(X_test, y_test_ground_truth_log)], \n",
    "                  early_stopping_rounds=50, \n",
    "                  verbose=False)  # Fixed: Direct arguments to fit(), no callbacks list\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- Step 3: Make predictions on the \"pretend\" test set ---\n",
    "    print(\"Making predictions on the holdout test set...\")\n",
    "    predictions_log = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Inverse transform to get actual prices\n",
    "    predictions_actual = np.expm1(predictions_log)\n",
    "    predictions_actual[predictions_actual < 0] = 0 # Enforce non-negative constraint\n",
    "\n",
    "    # --- Step 4: Create and save the submission CSV file ---\n",
    "    submission_df = pd.DataFrame({\n",
    "        'sample_id': test_df['sample_id'],\n",
    "        'price': predictions_actual\n",
    "    })\n",
    "    \n",
    "    submission_path = 'sample_submission.csv'\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"âœ… Submission file created at: '{submission_path}'\")\n",
    "\n",
    "    # --- Step 5: Score the submission file against the ground truth ---\n",
    "    print(\"\\n--- Scoring Submission File ---\")\n",
    "    \n",
    "    # Load the ground truth from the original file\n",
    "    ground_truth_df = pd.read_csv('68e8d1d70b66d_student_resource/student_resource/dataset/sample_test_out.csv')\n",
    "    \n",
    "    # Merge our predictions with the ground truth\n",
    "    # This mimics exactly how the competition leaderboard is calculated\n",
    "    merged_score_df = pd.merge(submission_df, ground_truth_df, on='sample_id', suffixes=('_pred', '_true'))\n",
    "    \n",
    "    if len(merged_score_df) != len(test_df):\n",
    "        print(\"Warning: The number of predictions does not match the test set size!\")\n",
    "\n",
    "    # Calculate the final SMAPE score\n",
    "    final_smape_score = smape(merged_score_df['price_true'], merged_score_df['price_pred'])\n",
    "    \n",
    "    print(\"\\n--- FINAL SIMULATED SCORE ---\")\n",
    "    print(f\"SMAPE against sample_test_out.csv: {final_smape_score:.4f}%\")\n",
    "    \n",
    "    return xgb_model\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    # Load all features and the corresponding dataframe with IDs and prices\n",
    "    X_final, df_final = load_and_combine_all_features()\n",
    "    \n",
    "    # Run the full simulation\n",
    "    final_model = run_full_pipeline(X_final, df_final)\n",
    "    \n",
    "    if final_model:\n",
    "        joblib.dump(final_model, 'final_xgb_model_for_submission.joblib')\n",
    "        print(\"\\nâœ… Final trained model saved as 'final_xgb_model_for_submission.joblib'\")\n",
    "        print(\"You can use this model to predict on the real 'test.csv' for the competition.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, hstack\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb  # Native XGBoost import for train API\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "\n",
    "# --- 1. Re-usable Components ---\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculates the Symmetric Mean Absolute Percentage Error (SMAPE).\"\"\"\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    ratio = np.where(denominator == 0, 0, numerator / denominator)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    \"\"\"A consistent cleaning function for both text sources.\"\"\"\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = re.sub(r'<.*?>|Value:.*|Unit:.*', ' ', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words and len(w) > 2]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# --- 2. Load and Combine All Data Sources ---\n",
    "\n",
    "def load_and_combine_all_features(data_dir='processed_data'):\n",
    "    \"\"\"\n",
    "    Loads all preprocessed features and combines them.\n",
    "    Returns the combined feature matrix and the original DataFrame with prices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"--- Loading All Preprocessed Data ---\")\n",
    "        \n",
    "        X_text_struct = load_npz(f'{data_dir}/X_processed.npz')\n",
    "        y_df = pd.read_csv(f'{data_dir}/y_processed.csv').set_index('sample_id')\n",
    "        \n",
    "        vlm_df = pd.read_csv(f'{data_dir}/smolvlm_extracted_features.csv').set_index('sample_id')\n",
    "        vlm_df = vlm_df.reindex(y_df.index).fillna('')\n",
    "        vlm_df['cleaned_vlm'] = vlm_df['smolvlm_description'].apply(clean_text)\n",
    "        \n",
    "        vlm_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
    "        X_vlm = vlm_vectorizer.fit_transform(vlm_df['cleaned_vlm'])\n",
    "        \n",
    "        X_images = np.load(f'{data_dir}/X_image_features.npy')\n",
    "        all_ids_df = pd.read_csv(f'{data_dir}/all_sample_ids.csv').set_index('sample_id')\n",
    "        image_features_df = pd.DataFrame(X_images, index=all_ids_df.index)\n",
    "        X_images_aligned = image_features_df.reindex(y_df.index).values\n",
    "        \n",
    "        X_final_combined = hstack([X_text_struct, X_vlm, X_images_aligned]).tocsr()\n",
    "\n",
    "        print(f\"âœ… Data loaded and combined successfully! Final shape: {X_final_combined.shape}\")\n",
    "        \n",
    "        # We need the original dataframe with IDs and prices for splitting and scoring\n",
    "        full_df = pd.read_csv(f'{data_dir}/y_processed.csv')\n",
    "        print(\"Vectorizing VLM text...\")\n",
    "        vlm_vectorizer = TfidfVectorizer(max_features=1500, ngram_range=(1, 2))\n",
    "        # This line was changed: we fit_transform on the training data\n",
    "        X_vlm = vlm_vectorizer.fit_transform(vlm_df['cleaned_vlm'])\n",
    "        \n",
    "        # --- ADD THIS LINE ---\n",
    "        joblib.dump(vlm_vectorizer, f'{data_dir}/vlm_vectorizer.joblib')\n",
    "        print(\"Saved VLM TF-IDF vectorizer.\")\n",
    "        return X_final_combined, full_df\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading data: {e}. Please ensure you have run all three preprocessing scripts first.\")\n",
    "        return None, None\n",
    "\n",
    "# --- 3. Full Train, Predict, and Evaluate Pipeline ---\n",
    "\n",
    "def run_full_pipeline(X, df):\n",
    "    \"\"\"\n",
    "    Trains on a subset, predicts on a holdout, saves a submission file, and scores it.\n",
    "    \"\"\"\n",
    "    if X is None or df is None: return\n",
    "\n",
    "    print(\"\\n--- Simulating Competition Workflow ---\")\n",
    "    \n",
    "    # --- Step 1: Split the data into a training set and a \"pretend\" test set ---\n",
    "    # We split based on the dataframe to keep track of IDs\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Get the corresponding rows from the sparse matrix X\n",
    "    X_train = X[train_df.index]\n",
    "    y_train = train_df['price_log']\n",
    "    \n",
    "    X_test = X[test_df.index]\n",
    "    # We will use this later to score our predictions\n",
    "    y_test_ground_truth_log = test_df['price_log'] \n",
    "\n",
    "    print(f\"Training on {len(train_df)} samples, predicting on {len(test_df)} samples.\")\n",
    "\n",
    "    # --- Step 2: Train the model ONLY on the training set ---\n",
    "    print(\"\\nTraining an XGBoost Regressor model...\")\n",
    "    \n",
    "    # Create DMatrix for native XGBoost API (handles sparse data)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test_ground_truth_log)\n",
    "    \n",
    "    # Parameters equivalent to original LightGBM setup\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',  # For regression; use 'reg:linear' if preferred\n",
    "        'eval_metric': 'mae',  # Matches original metric\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 6,  # Approximates num_leaves=31\n",
    "        'random_state': 42,  # Seed for reproducibility\n",
    "        'nthread': -1  # Uses all cores\n",
    "    }\n",
    "    \n",
    "    # Train with native xgb.train and early stopping\n",
    "    evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "    xgb_model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- Step 3: Make predictions on the \"pretend\" test set ---\n",
    "    print(\"Making predictions on the holdout test set...\")\n",
    "    predictions_log = xgb_model.predict(dtest, ntree_limit=xgb_model.best_ntree_limit)\n",
    "    \n",
    "    # Inverse transform to get actual prices\n",
    "    predictions_actual = np.expm1(predictions_log)\n",
    "    predictions_actual[predictions_actual < 0] = 0 # Enforce non-negative constraint\n",
    "\n",
    "    # --- Step 4: Create and save the submission CSV file ---\n",
    "    submission_df = pd.DataFrame({\n",
    "        'sample_id': test_df['sample_id'],\n",
    "        'price': predictions_actual\n",
    "    })\n",
    "    \n",
    "    submission_path = 'sample_submission.csv'\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"âœ… Submission file created at: '{submission_path}'\")\n",
    "\n",
    "    # --- Step 5: Score the submission file against the ground truth ---\n",
    "    print(\"\\n--- Scoring Submission File ---\")\n",
    "    \n",
    "    # Load the ground truth from the original file\n",
    "    ground_truth_df = pd.read_csv('68e8d1d70b66d_student_resource/student_resource/dataset/sample_test_out.csv')\n",
    "    \n",
    "    # Merge our predictions with the ground truth\n",
    "    # This mimics exactly how the competition leaderboard is calculated\n",
    "    merged_score_df = pd.merge(submission_df, ground_truth_df, on='sample_id', suffixes=('_pred', '_true'))\n",
    "    \n",
    "    if len(merged_score_df) != len(test_df):\n",
    "        print(\"Warning: The number of predictions does not match the test set size!\")\n",
    "\n",
    "    # Calculate the final SMAPE score\n",
    "    final_smape_score = smape(merged_score_df['price_true'], merged_score_df['price_pred'])\n",
    "    \n",
    "    print(\"\\n--- FINAL SIMULATED SCORE ---\")\n",
    "    print(f\"SMAPE against sample_test_out.csv: {final_smape_score:.4f}%\")\n",
    "    \n",
    "    return xgb_model\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == '__main__':\n",
    "    # Load all features and the corresponding dataframe with IDs and prices\n",
    "    X_final, df_final = load_and_combine_all_features()\n",
    "    \n",
    "    # Run the full simulation\n",
    "    final_model = run_full_pipeline(X_final, df_final)\n",
    "    \n",
    "    if final_model:\n",
    "        joblib.dump(final_model, 'final_xgb_model_for_submission.joblib')\n",
    "        print(\"\\nâœ… Final trained model saved as 'final_xgb_model_for_submission.joblib'\")\n",
    "        print(\"You can use this model to predict on the real 'test.csv' for the competition.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf7f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47cdfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: train_advanced.py (Fixed for High Dimensionality)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_regression, VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Calculate SMAPE metric.\"\"\"\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def load_and_combine_all_features():\n",
    "    \"\"\"Load all preprocessed features and combine them.\"\"\"\n",
    "    try:\n",
    "        data_dir = 'processed_data'\n",
    "        \n",
    "        print(\"--- Loading All Preprocessed Data ---\")\n",
    "        \n",
    "        # Try to load main processed features (npz file)\n",
    "        try:\n",
    "            npz_data = np.load(f'{data_dir}/X_processed.npz', allow_pickle=True)\n",
    "            print(f\"âœ… X_processed.npz keys: {list(npz_data.keys())}\")\n",
    "            \n",
    "            # Try different possible array names\n",
    "            if 'X' in npz_data:\n",
    "                X_processed = npz_data['X']\n",
    "            elif 'data' in npz_data:\n",
    "                X_processed = npz_data['data']\n",
    "            elif 'arr_0' in npz_data:\n",
    "                X_processed = npz_data['arr_0']\n",
    "            else:\n",
    "                X_processed = npz_data[list(npz_data.keys())[0]]\n",
    "            \n",
    "            print(f\"   Loaded array shape: {X_processed.shape}\")\n",
    "            \n",
    "            # Check if it's the right shape\n",
    "            if X_processed.ndim == 1:\n",
    "                print(f\"   âš ï¸  X_processed is 1D with {X_processed.shape[0]} elements\")\n",
    "                print(f\"   This doesn't divide evenly by 100 samples (10516 Ã· 100 = 105.16)\")\n",
    "                print(f\"   Skipping X_processed.npz - using other features only\")\n",
    "                X_processed = None\n",
    "            elif X_processed.shape[0] != 100:\n",
    "                print(f\"   âš ï¸  X_processed has {X_processed.shape[0]} rows, expected 100\")\n",
    "                print(f\"   Skipping X_processed.npz - using other features only\")\n",
    "                X_processed = None\n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸  Could not load X_processed.npz properly: {e}\")\n",
    "            print(f\"   Continuing with other features...\")\n",
    "            X_processed = None\n",
    "        \n",
    "        # Load image features\n",
    "        X_image = np.load(f'{data_dir}/X_image_features.npy')\n",
    "        print(f\"âœ… X_image_features.npy loaded: {X_image.shape}\")\n",
    "        \n",
    "        # Load text features from smolvlm (use the features_only version if available)\n",
    "        try:\n",
    "            df_smolvlm = pd.read_csv(f'{data_dir}/smolvlm_extracted_features_only.csv')\n",
    "            print(f\"âœ… smolvlm_extracted_features_only.csv loaded: {df_smolvlm.shape}\")\n",
    "        except:\n",
    "            df_smolvlm = pd.read_csv(f'{data_dir}/smolvlm_extracted_features.csv')\n",
    "            print(f\"âœ… smolvlm_extracted_features.csv loaded: {df_smolvlm.shape}\")\n",
    "        \n",
    "        # Extract only numeric features (excluding id/text columns)\n",
    "        smolvlm_features = df_smolvlm.select_dtypes(include=[np.number]).values\n",
    "        print(f\"   Numeric smolvlm features: {smolvlm_features.shape}\")\n",
    "        \n",
    "        # Load OCR text features\n",
    "        df_ocr = pd.read_csv(f'{data_dir}/ocr_extracted_text.csv')\n",
    "        print(f\"âœ… OCR data loaded: {df_ocr.shape}\")\n",
    "        \n",
    "        # OCR has 200 rows but we need 100\n",
    "        ocr_features = df_ocr.select_dtypes(include=[np.number]).values\n",
    "        if ocr_features.shape[0] != X_image.shape[0]:\n",
    "            print(f\"   âš ï¸  OCR shape mismatch: {ocr_features.shape[0]} rows vs {X_image.shape[0]} expected\")\n",
    "            ocr_features = ocr_features[:X_image.shape[0], :]\n",
    "            print(f\"   Adjusted OCR features to: {ocr_features.shape}\")\n",
    "        \n",
    "        # Load target variable\n",
    "        df_y = pd.read_csv(f'{data_dir}/y_processed.csv')\n",
    "        print(f\"âœ… y_processed.csv loaded: {df_y.shape}\")\n",
    "        \n",
    "        # Build feature array list\n",
    "        feature_arrays = [X_image]  # Start with image features\n",
    "        \n",
    "        # Add X_processed if it loaded correctly\n",
    "        if X_processed is not None:\n",
    "            feature_arrays.insert(0, X_processed)\n",
    "            print(f\"   Including X_processed in features\")\n",
    "        \n",
    "        # Add smolvlm features if they exist\n",
    "        if smolvlm_features.shape[1] > 0:\n",
    "            feature_arrays.append(smolvlm_features)\n",
    "        \n",
    "        # Add OCR features if they exist and have features\n",
    "        if ocr_features.shape[1] > 0:\n",
    "            feature_arrays.append(ocr_features)\n",
    "        \n",
    "        # Ensure all arrays have the same number of rows\n",
    "        n_samples = X_image.shape[0]\n",
    "        print(f\"\\n   Combining {len(feature_arrays)} feature sources...\")\n",
    "        for i, arr in enumerate(feature_arrays):\n",
    "            print(f\"   Array {i}: shape {arr.shape}\")\n",
    "            if arr.shape[0] != n_samples:\n",
    "                raise ValueError(f\"Array {i} has {arr.shape[0]} rows, expected {n_samples}\")\n",
    "        \n",
    "        X = np.hstack(feature_arrays)\n",
    "        \n",
    "        # Create dataframe with target\n",
    "        if 'price_log' in df_y.columns:\n",
    "            price_col = 'price_log'\n",
    "        elif 'target' in df_y.columns:\n",
    "            price_col = 'target'\n",
    "        else:\n",
    "            price_col = df_y.columns[0]\n",
    "        \n",
    "        df = pd.DataFrame({'price_log': df_y[price_col].values[:n_samples]})\n",
    "        \n",
    "        print(f\"\\nâœ… Data loaded and combined successfully!\")\n",
    "        print(f\"   Final feature matrix shape: {X.shape}\")\n",
    "        print(f\"   Samples: {X.shape[0]}, Features: {X.shape[1]}\")\n",
    "        print(f\"   Feature-to-sample ratio: {X.shape[1]/X.shape[0]:.1f}:1\")\n",
    "        \n",
    "        if X.shape[1] / X.shape[0] > 10:\n",
    "            print(f\"   âš ï¸  HIGH DIMENSIONALITY - Feature selection will be critical!\")\n",
    "        \n",
    "        return X, df\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"âŒ Error loading files: {e}\")\n",
    "        print(\"Please check that all files exist in the 'processed_data' directory.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "def reduce_features(X, y, n_features=50):\n",
    "    \"\"\"\n",
    "    Reduce feature dimensionality using multiple strategies.\n",
    "    \"\"\"\n",
    "    print(f\"\\nOriginal features: {X.shape[1]}\")\n",
    "    \n",
    "    # Step 1: Remove zero/low variance features\n",
    "    print(\"Removing low variance features...\")\n",
    "    var_threshold = VarianceThreshold(threshold=0.01)\n",
    "    X_var = var_threshold.fit_transform(X)\n",
    "    print(f\"After variance filter: {X_var.shape[1]} features\")\n",
    "    \n",
    "    # Step 2: Select top features by mutual information\n",
    "    print(f\"Selecting top {n_features} features by mutual information...\")\n",
    "    mi_scores = mutual_info_regression(X_var, y, random_state=42, n_jobs=-1)\n",
    "    top_features_idx = np.argsort(mi_scores)[-n_features:]\n",
    "    X_selected = X_var[:, top_features_idx]\n",
    "    print(f\"After MI selection: {X_selected.shape[1]} features\")\n",
    "    \n",
    "    return X_selected, var_threshold, top_features_idx\n",
    "\n",
    "def run_advanced_training(X, df, n_splits=5, n_features=50):\n",
    "    \"\"\"\n",
    "    Trains multiple models using K-Fold cross-validation with proper feature selection.\n",
    "    \"\"\"\n",
    "    if X is None or df is None: \n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- Starting {n_splits}-Fold Cross-Validation Training ---\")\n",
    "    print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    print(f\"âš ï¸  Feature-to-sample ratio: {X.shape[1]/X.shape[0]:.1f}:1 (VERY HIGH!)\")\n",
    "    \n",
    "    y = df['price_log'].values\n",
    "    \n",
    "    # Feature reduction BEFORE cross-validation\n",
    "    X_reduced, var_selector, mi_indices = reduce_features(X, y, n_features=n_features)\n",
    "    print(f\"\\nâœ… Using {X_reduced.shape[1]} features for training\")\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # --- Simplified Models with Strong Regularization ---\n",
    "    lgb_params = {\n",
    "        'objective': 'regression_l1',\n",
    "        'metric': 'mae',\n",
    "        'random_state': 42,\n",
    "        'n_estimators': 500,  # Reduced from 2000\n",
    "        'learning_rate': 0.05,  # Increased from 0.01\n",
    "        'num_leaves': 15,  # Reduced from 40\n",
    "        'max_depth': 4,  # Added depth limit\n",
    "        'min_child_samples': 10,  # Increased from default\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 1.0,  # Increased regularization\n",
    "        'reg_lambda': 1.0,\n",
    "        'min_split_gain': 0.01,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    xgb_params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'mae',\n",
    "        'seed': 42,\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 4,  # Reduced from 7\n",
    "        'min_child_weight': 5,  # Increased\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'reg_lambda': 1.0,\n",
    "        'reg_alpha': 1.0,\n",
    "        'gamma': 0.1,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "\n",
    "    cat_params = {\n",
    "        'loss_function': 'MAE',\n",
    "        'eval_metric': 'MAE',\n",
    "        'random_seed': 42,\n",
    "        'iterations': 500,\n",
    "        'learning_rate': 0.05,\n",
    "        'depth': 4,  # Reduced from 8\n",
    "        'l2_leaf_reg': 5,  # Increased regularization\n",
    "        'verbose': 0,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "\n",
    "    model_configs = {\n",
    "        'lgbm': {'model': lgb.LGBMRegressor(**lgb_params), 'preds': np.zeros(len(df))},\n",
    "        'xgb': {'model': xgb.XGBRegressor(**xgb_params), 'preds': np.zeros(len(df))},\n",
    "        'cat': {'model': cb.CatBoostRegressor(**cat_params), 'preds': np.zeros(len(df))}\n",
    "    }\n",
    "\n",
    "    # --- Cross-Validation Loop ---\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_reduced, y)):\n",
    "        print(f\"\\n--- Fold {fold+1}/{n_splits} ---\")\n",
    "        X_train, X_val = X_reduced[train_idx], X_reduced[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        for name, config in model_configs.items():\n",
    "            print(f\"Training {name}...\", end=\" \")\n",
    "            \n",
    "            if name == 'lgbm':\n",
    "                config['model'].fit(\n",
    "                    X_train, y_train, \n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "                )\n",
    "            \n",
    "            elif name == 'xgb':\n",
    "                config['model'].fit(\n",
    "                    X_train, y_train, \n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    verbose=False\n",
    "                )\n",
    "            \n",
    "            else:  # CatBoost\n",
    "                config['model'].fit(\n",
    "                    X_train, y_train, \n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    early_stopping_rounds=50, \n",
    "                    verbose=False\n",
    "                )\n",
    "            \n",
    "            val_preds = config['model'].predict(X_val)\n",
    "            config['preds'][val_idx] = val_preds\n",
    "            \n",
    "            # Calculate fold SMAPE\n",
    "            fold_smape = smape(np.expm1(y_val), np.expm1(val_preds))\n",
    "            print(f\"Fold SMAPE: {fold_smape:.2f}%\")\n",
    "    \n",
    "    # --- Evaluation ---\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"--- Cross-Validation Results ---\")\n",
    "    print(\"=\"*60)\n",
    "    y_true_actual = np.expm1(y)\n",
    "\n",
    "    for name, config in model_configs.items():\n",
    "        preds_actual = np.expm1(config['preds'])\n",
    "        oof_smape = smape(y_true_actual, preds_actual)\n",
    "        print(f\"{name.upper():8s} SMAPE: {oof_smape:.4f}%\")\n",
    "\n",
    "    # Ensemble with optimized weights\n",
    "    ensemble_preds_log = (\n",
    "        0.4 * model_configs['lgbm']['preds'] + \n",
    "        0.3 * model_configs['xgb']['preds'] + \n",
    "        0.3 * model_configs['cat']['preds']\n",
    "    )\n",
    "    \n",
    "    ensemble_preds_actual = np.expm1(ensemble_preds_log)\n",
    "    ensemble_smape = smape(y_true_actual, ensemble_preds_actual)\n",
    "    print(f\"{'ENSEMBLE':8s} SMAPE: {ensemble_smape:.4f}%\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # --- Find best model ---\n",
    "    smape_scores = {\n",
    "        'lgbm': smape(y_true_actual, np.expm1(model_configs['lgbm']['preds'])),\n",
    "        'xgb': smape(y_true_actual, np.expm1(model_configs['xgb']['preds'])),\n",
    "        'cat': smape(y_true_actual, np.expm1(model_configs['cat']['preds'])),\n",
    "        'ensemble': ensemble_smape\n",
    "    }\n",
    "    \n",
    "    best_model_name = min(smape_scores, key=smape_scores.get)\n",
    "    print(f\"\\nðŸ† Best model: {best_model_name.upper()} (SMAPE: {smape_scores[best_model_name]:.4f}%)\")\n",
    "    \n",
    "    # --- Retrain best model on all data ---\n",
    "    print(f\"\\nRetraining {best_model_name.upper()} on all data for final submission...\")\n",
    "    \n",
    "    if best_model_name == 'lgbm':\n",
    "        final_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    elif best_model_name == 'xgb':\n",
    "        final_params = xgb_params.copy()\n",
    "        final_params.pop('early_stopping_rounds')\n",
    "        final_model = xgb.XGBRegressor(**final_params)\n",
    "    elif best_model_name == 'cat':\n",
    "        final_model = cb.CatBoostRegressor(**cat_params)\n",
    "    else:  # ensemble\n",
    "        final_model = lgb.LGBMRegressor(**lgb_params)\n",
    "    \n",
    "    final_model.fit(X_reduced, y)\n",
    "    \n",
    "    # Save model and feature selectors\n",
    "    model_package = {\n",
    "        'model': final_model,\n",
    "        'var_selector': var_selector,\n",
    "        'mi_indices': mi_indices,\n",
    "        'model_type': best_model_name,\n",
    "        'n_features': n_features\n",
    "    }\n",
    "    \n",
    "    return model_package\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == '__main__':\n",
    "    result = load_and_combine_all_features()\n",
    "    \n",
    "    if result is not None and result[0] is not None:\n",
    "        X_final, df_final = result\n",
    "        \n",
    "        # Try with 50 features first\n",
    "        model_package = run_advanced_training(X_final, df_final, n_features=50)\n",
    "        \n",
    "        if model_package:\n",
    "            joblib.dump(model_package, 'final_model_package.joblib')\n",
    "            print(\"\\nâœ… Final model package saved as 'final_model_package.joblib'\")\n",
    "            print(f\"   Model type: {model_package['model_type']}\")\n",
    "            print(f\"   Features used: {model_package['n_features']}\")\n",
    "            print(\"\\nðŸ’¡ To make predictions, load the package and apply feature selection first!\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Failed to load data. Please check your file paths in load_and_combine_all_features().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8e28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c1bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcac66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
